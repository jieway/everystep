<!DOCTYPE HTML>
<html lang="zh-CN" class="sidebar-visible no-js light">
<head>
    <!-- Book generated using mdBook -->
    <meta charset="UTF-8">
    <title>everystep</title>
    <meta name="robots" content="noindex" />


    <!-- Custom HTML head -->
    
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#ffffff" />

    <link rel="icon" href="favicon.svg">
    <link rel="shortcut icon" href="favicon.png">
    <link rel="stylesheet" href="css/variables.css">
    <link rel="stylesheet" href="css/general.css">
    <link rel="stylesheet" href="css/chrome.css">
    <link rel="stylesheet" href="css/print.css" media="print">

    <!-- Fonts -->
    <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
    <link rel="stylesheet" href="fonts/fonts.css">

    <!-- Highlight.js Stylesheets -->
    <link rel="stylesheet" href="highlight.css">
    <link rel="stylesheet" href="tomorrow-night.css">
    <link rel="stylesheet" href="ayu-highlight.css">

    <!-- Custom theme stylesheets -->
    <link rel="stylesheet" href="theme/style.css">


</head>
<body>
    <!-- Provide site root to javascript -->
    <script type="text/javascript">
        var path_to_root = "";
        var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
    </script>

    <!-- Work around some values being stored in localStorage wrapped in quotes -->
    <script type="text/javascript">
        try {
            var theme = localStorage.getItem('mdbook-theme');
            var sidebar = localStorage.getItem('mdbook-sidebar');
            if (theme.startsWith('"') && theme.endsWith('"')) {
                localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
            }
            if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
            }
        } catch (e) { }
    </script>

    <!-- Set the theme before any content is loaded, prevents flash -->
    <script type="text/javascript">
        var theme;
        try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
        if (theme === null || theme === undefined) { theme = default_theme; }
        var html = document.querySelector('html');
        html.classList.remove('no-js')
        html.classList.remove('light')
        html.classList.add(theme);
        html.classList.add('js');
    </script>

    <!-- Hide / unhide sidebar before it is displayed -->
    <script type="text/javascript">
        var html = document.querySelector('html');
        var sidebar = 'hidden';
        if (document.body.clientWidth >= 1080) {
            try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
            sidebar = sidebar || 'visible';
        }
        html.classList.remove('sidebar-visible');
        html.classList.add("sidebar-" + sidebar);
    </script>

    <nav id="sidebar" class="sidebar" aria-label="Table of contents">
        <div class="sidebar-scrollbox">
            <ol class="chapter"><li class="chapter-item affix "><a href="index.html">简介</a></li><li class="chapter-item affix "><li class="part-title">🐷 造轮子</li><li class="spacer"></li><li class="chapter-item "><a href="bitcask/index.html"><strong aria-hidden="true">1.</strong> 从零实现 Bitcask 存储引擎</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="bitcask/p1.html"><strong aria-hidden="true">1.1.</strong> Bitcask 简介</a></li><li class="chapter-item "><a href="bitcask/p2.html"><strong aria-hidden="true">1.2.</strong> 创建 C++ 项目</a></li><li class="chapter-item "><a href="bitcask/p3.html"><strong aria-hidden="true">1.3.</strong> 数据在内存中</a></li><li class="chapter-item "><a href="bitcask/p1.html"><strong aria-hidden="true">1.4.</strong> 数据在磁盘上</a></li><li class="chapter-item "><a href="bitcask/p1.html"><strong aria-hidden="true">1.5.</strong> BenchMark</a></li><li class="chapter-item "><a href="bitcask/p1.html"><strong aria-hidden="true">1.6.</strong> 实现合并</a></li><li class="chapter-item "><a href="bitcask/p1.html"><strong aria-hidden="true">1.7.</strong> 实现垃圾回收</a></li><li class="chapter-item "><a href="bitcask/p1.html"><strong aria-hidden="true">1.8.</strong> hintfile 实现</a></li><li class="chapter-item "><a href="bitcask/p1.html"><strong aria-hidden="true">1.9.</strong> 哈希表优化为多线程</a></li><li class="chapter-item "><a href="bitcask/ch1.html"><strong aria-hidden="true">1.10.</strong> 数据在磁盘上如何存放？</a></li><li class="chapter-item "><a href="bitcask/ch2.html"><strong aria-hidden="true">1.11.</strong> 存储引擎的接口设计</a></li><li class="chapter-item "><a href="bitcask/ch3.html"><strong aria-hidden="true">1.12.</strong> 实现 Set、Get</a></li><li class="chapter-item "><a href="bitcask/ch4.html"><strong aria-hidden="true">1.13.</strong> 删除逻辑和 Compact </a></li></ol></li><li class="chapter-item "><li class="part-title">🍭 操作系统</li><li class="spacer"></li><li class="chapter-item "><a href="6.S081/0-summary.html"><strong aria-hidden="true">2.</strong> 6.S081</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="6.S081/1-lab1.html"><strong aria-hidden="true">2.1.</strong> Lab 1</a></li><li class="chapter-item "><a href="6.S081/2-lab2.html"><strong aria-hidden="true">2.2.</strong> Lab 2</a></li><li class="chapter-item "><a href="6.S081/3-lab3.html"><strong aria-hidden="true">2.3.</strong> Lab 3</a></li><li class="chapter-item "><a href="6.S081/4-lab4.html"><strong aria-hidden="true">2.4.</strong> Lab 4</a></li><li class="chapter-item "><a href="6.S081/5-lab5.html"><strong aria-hidden="true">2.5.</strong> Lab 5</a></li><li class="chapter-item "><a href="6.S081/6-lab6.html"><strong aria-hidden="true">2.6.</strong> Lab 6</a></li><li class="chapter-item "><a href="6.S081/7-lab7.html"><strong aria-hidden="true">2.7.</strong> Lab 7</a></li><li class="chapter-item "><a href="6.S081/8-lab8.html"><strong aria-hidden="true">2.8.</strong> Lab 8</a></li><li class="chapter-item "><a href="6.S081/9-lab9.html"><strong aria-hidden="true">2.9.</strong> Lab 9</a></li><li class="chapter-item "><a href="6.S081/10-lab10.html"><strong aria-hidden="true">2.10.</strong> Lab 10</a></li><li class="chapter-item "><a href="6.S081/11-lab11.html"><strong aria-hidden="true">2.11.</strong> Lab 11</a></li></ol></li><li class="chapter-item "><li class="part-title">🚀 数据库</li><li class="chapter-item "><a href="abyssdb/p0.html"><strong aria-hidden="true">3.</strong> 从零实现关系型数据库</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="abyssdb/p1.html"><strong aria-hidden="true">3.1.</strong> 从 Table 开始</a></li><li class="chapter-item "><a href="abyssdb/p2.html"><strong aria-hidden="true">3.2.</strong> Part 2. 实现 Tuple</a></li><li class="chapter-item "><a href="abyssdb/p3.html"><strong aria-hidden="true">3.3.</strong> Part 3. 实现 Page</a></li><li class="chapter-item "><a href="abyssdb/p4.html"><strong aria-hidden="true">3.4.</strong> Part 4. 实现 HeapFile</a></li><li class="chapter-item "><a href="abyssdb/p5.html"><strong aria-hidden="true">3.5.</strong> Part 5. 实现 BufferPool</a></li><li class="chapter-item "><a href="abyssdb/p6.html"><strong aria-hidden="true">3.6.</strong> Part 6. 支持 int 和 string 等数据类型。</a></li><li class="chapter-item "><a href="abyssdb/p7.html"><strong aria-hidden="true">3.7.</strong> Part 7. 实现 Catalog</a></li></ol></li><li class="chapter-item "><a href="6.830/1-lab0.html"><strong aria-hidden="true">4.</strong> 6.830</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="6.830/ans/2-lab1-ans.html"><strong aria-hidden="true">4.1.</strong> Lab 1 Answers</a></li><li class="chapter-item "><a href="6.830/ans/3-lab2-ans.html"><strong aria-hidden="true">4.2.</strong> Lab 2 Answers</a></li><li class="chapter-item "><a href="6.830/ans/4-lab3-ans.html"><strong aria-hidden="true">4.3.</strong> Lab 3 Answers</a></li><li class="chapter-item "><a href="6.830/ans/5-lab4-ans.html"><strong aria-hidden="true">4.4.</strong> Lab 4 Answers</a></li><li class="chapter-item "><a href="6.830/ans/6-lab5-ans.html"><strong aria-hidden="true">4.5.</strong> Lab 5 Answers</a></li><li class="chapter-item "><a href="6.830/ans/7-lab6-ans.html"><strong aria-hidden="true">4.6.</strong> Lab 6 Answers</a></li><li class="chapter-item "><a href="6.830/cn/2-lab1.html"><strong aria-hidden="true">4.7.</strong> Lab 1 (Chinese)</a></li><li class="chapter-item "><a href="6.830/cn/3-lab2.html"><strong aria-hidden="true">4.8.</strong> Lab 2 (Chinese)</a></li><li class="chapter-item "><a href="6.830/cn/4-lab3.html"><strong aria-hidden="true">4.9.</strong> Lab 3 (Chinese)</a></li><li class="chapter-item "><a href="6.830/cn/5-lab4.html"><strong aria-hidden="true">4.10.</strong> Lab 4 (Chinese)</a></li><li class="chapter-item "><a href="6.830/cn/6-lab5.html"><strong aria-hidden="true">4.11.</strong> Lab 5 (Chinese)</a></li><li class="chapter-item "><a href="6.830/cn/7-lab6.html"><strong aria-hidden="true">4.12.</strong> Lab 6 (Chinese)</a></li></ol></li><li class="chapter-item "><li class="part-title">🧊 分布式</li><li class="spacer"></li><li class="chapter-item "><a href="6.824/0-lab0.html"><strong aria-hidden="true">5.</strong> 6.824</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="6.824/1-lab1-cn.html"><strong aria-hidden="true">5.1.</strong> Lab 1 (Chinese)</a></li><li class="chapter-item "><a href="6.824/1-lab1.html"><strong aria-hidden="true">5.2.</strong> Lab 1</a></li><li class="chapter-item "><a href="6.824/2-lab2-cn.html"><strong aria-hidden="true">5.3.</strong> Lab 2 (Chinese)</a></li><li class="chapter-item "><a href="6.824/2-lab2.html"><strong aria-hidden="true">5.4.</strong> Lab 2</a></li></ol></li></ol>
        </div>
        <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
    </nav>

    <div id="page-wrapper" class="page-wrapper">

        <div class="page">
                        <div id="menu-bar-hover-placeholder"></div>
            <div id="menu-bar" class="menu-bar sticky bordered">
                <div class="left-buttons">
                    <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                        <i class="fa fa-bars"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                        <i class="fa fa-paint-brush"></i>
                    </button>
                    <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                        <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                    </ul>
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                </div>

                <h1 class="menu-title">everystep</h1>

                <div class="right-buttons">
                    <a href="print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>
                    <a href="https://github.com/weijiew/everystep" title="Git repository" aria-label="Git repository">
                        <i id="git-repository-button" class="fa fa-github"></i>
                    </a>

                </div>
            </div>

            <div id="search-wrapper" class="hidden">
                <form id="searchbar-outer" class="searchbar-outer">
                    <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                </form>
                <div id="searchresults-outer" class="searchresults-outer hidden">
                    <div id="searchresults-header" class="searchresults-header"></div>
                    <ul id="searchresults">
                    </ul>
                </div>
            </div>

            <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
            <script type="text/javascript">
                document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');

                // Get viewed page store
                var viewed_key = 'mdbook-viewed';
                var viewed_map = {};
                try {
                    var viewed_storage = localStorage.getItem(viewed_key);
                    if (viewed_storage) {
                        viewed_map = JSON.parse(viewed_storage)
                    }
                } catch (e) { }

                Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                    link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);

                    // Apply viewed style
                    if (viewed_map[link.pathname]) {
                        link.classList.add('md-viewed')
                    }
                }); 

                // Mark viewed after 30s
                setTimeout(function() {
                    viewed_map[location.pathname] = 1;
                    localStorage.setItem(viewed_key, JSON.stringify(viewed_map));
                }, 30000)
            </script>

            <div id="content" class="content">
                <!-- Page table of contents -->
                <div class="sidetoc"><nav class="pagetoc"></nav></div>
                <main>
                    <h1 id="everystep"><a class="header" href="#everystep">everystep</a></h1>
<div align="center">
  <a href="https://github.com/weijiew/everystep">
    <img src="assets/logo.jpg" alt="logo" width="200" height="180">
  </a>
<p><a href="https://weijiew.github.io/everystep"><img src="https://img.shields.io/badge/%E9%98%85%E8%AF%BB-read-brightgreen.svg" alt="阅读" /></a>
<img src="https://img.shields.io/github/stars/weijiew/everystep" alt="Stars" />
<img src="https://img.shields.io/github/forks/weijiew/everystep" alt="forks" />
<img src="https://img.shields.io/github/issues/weijiew/everystep" alt="issues" /></p>
<img src='assets/background-cover_.png' width='800'>
</div>
<p>该项目最初为写名校 lab 过程中留下了的记录，但是因为<a href="http://integrity.mit.edu/">学术诚信</a>的缘故，公开解决方案甚至代码是不合适的。但是直接删了有点可惜，后来想尝试换一门语言重写 lab/proj/hw 等内容，所以逐渐演化为用其他语言重写，造轮子过程中的笔记。例如从零实现 OS/Compiler/DB/ld 等，此外和课程答案相关的内容确实会逐渐删去。</p>
<h2 id="思考"><a class="header" href="#思考">思考</a></h2>
<p>写代码时要紧紧抓住 “我当前所面临的问题是什么？”否则很容易浪费时间。其次是要不断的去问为什么，思考背后的原理，动机，搞清楚对哪部分内容认识不到位。总之个人知识库，记录所学，如有错误还请指正。</p>
<p>为降低复杂度，便于理解旨在提供最简单的实现。整个项目以问题为导向，紧紧围绕着当前所面临的问题是什么？如何解决？解决后产生的新问题是什么？记录了实现系统过程中所遇到的问题，以书籍的形式组织起来更合适，故没有将其放到blog中。</p>
<h2 id="本地运行"><a class="header" href="#本地运行">本地运行</a></h2>
<pre><code>git clone https://github.com/weijiew/everystep.git
cd everystep &amp;&amp; mdbook serve --open
</code></pre>
<h2 id="贡献"><a class="header" href="#贡献">贡献</a></h2>
<p>大部分项目已经将问题拆解为努努力就能实现的地步了。但是因为时间不多没有仔细润色，文字一定程度存在割裂感，故欢迎任何意义上能够优化项目的贡献。</p>
<h2 id="star-历史"><a class="header" href="#star-历史">Star 历史</a></h2>
<p><a href="https://star-history.com/#weijiew/everystep&amp;Date"><img src="https://api.star-history.com/svg?repos=weijiew/everystep&amp;type=Date" alt="Star History Chart" /></a></p>
<h2 id="协议"><a class="header" href="#协议">协议</a></h2>
<p>版权声明：本项目中的所有文章均为我（weijiew）原创作品。如需引用，请务必明确标明来源。若发现有恶意剽窃或未经授权的转载行为，我将采取法律措施保护我的权利。让我们共同努力，营造一个健康的技术创作氛围。</p>
<p>2019 - 2023 ©weijiew. Released under the CC BY-NC-SA 4.0 International License.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="从零实现-bitcask-存储引擎"><a class="header" href="#从零实现-bitcask-存储引擎">从零实现 Bitcask 存储引擎</a></h1>
<p>Bitcask 是一个用于键值存储的持久化数据结构，旨在高效地支持键值对的读写操作。它的发展历史可以简要描述如下：</p>
<ol>
<li>
<p><strong>起源</strong>：Bitcask 最早由 Justin Sheehy 在 2007 年创建，作为 Basho Technologies 的开源数据库项目 Riak 的一部分。Riak 是一个高可用、分布式的键值存储数据库，Bitcask 被设计为其底层数据存储引擎。</p>
</li>
<li>
<p><strong>问题</strong>：在分布式系统中，要求高并发和低延迟的读写操作是常见的需求。传统的磁盘文件系统在这方面可能不够高效，因为它们可能会导致随机磁盘访问，从而降低了性能。Bitcask 的目标是解决这一问题，提供高性能的键值存储引擎。</p>
</li>
<li>
<p><strong>设计特点</strong>：Bitcask 的核心思想是将数据分为小的文件片段（segment），每个片段都包含一个持久化的哈希表（hash table）。所有新写入的数据都追加到最后一个片段，而旧数据则仍然存在于旧片段中。这种追加写入的方式减少了随机磁盘访问，提高了写入性能。此外，Bitcask 使用内存索引，以快速定位数据位置，从而加速读取操作。</p>
</li>
<li>
<p><strong>优点</strong>：Bitcask 的设计使其在写入操作和读取操作上都具有出色的性能。它也易于维护和备份，因为数据文件是追加写入的，且可以通过合并来进行压缩和维护。</p>
</li>
<li>
<p><strong>应用</strong>：Bitcask 最初是 Riak 的底层存储引擎，但后来也被其他项目广泛采用。它的设计理念也影响了其他键值存储引擎的开发，成为了一种常见的数据结构选择。</p>
</li>
</ol>
<p>总之，Bitcask 是为了解决高并发、低延迟的键值存储需求而创建的数据结构，通过追加写入和内存索引等特点，提供了高性能的解决方案，并在分布式数据库系统中得到了广泛的应用。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bitcask-简介"><a class="header" href="#bitcask-简介">Bitcask 简介</a></h1>
<p>Bitcask 是一种简单的存储引擎，存储引擎是数据库的核心组件，负责存储和管理数据，即数据在内存，磁盘上是如何组织的，设计一个合理的存储引擎是为了实现高效的存取数据。</p>
<p>存储引擎以插件的形式存在，每个数据库可以支持多个存储引擎，不同的存储引擎具有不同的特性和性能，适用于不同的应用场景。例如，InnoDB 存储引擎支持事务处理，适用于在线事务处理（OLTP）应用；MyISAM 存储引擎不支持事务处理，但具有较高的性能，适用于数据库备份和报表等应用。</p>
<h2 id="bitcask-发展历史"><a class="header" href="#bitcask-发展历史">Bitcask 发展历史</a></h2>
<p>Bitcask 的起源和发展历史可以简要地概述如下：</p>
<ol>
<li>
<p><strong>起源</strong>：Bitcask 最初是由 Basho Technologies 为其开发的分布式数据库 Riak 设计的。这是一个 Erlang 应用程序，目的是提供一种高效的方式来存储和检索键/值对数据。</p>
</li>
<li>
<p><strong>设计灵感</strong>：Bitcask 的设计部分受到了日志结构化文件系统和日志文件合并技术的启发。它的主要特点是使用日志结构化哈希表，为键/值对存储提供快速访问。</p>
</li>
<li>
<p><strong>发展</strong>：Bitcask 随着 Riak 的普及而逐渐发展。它因其高性能写入和有效的读取性能而受到关注，特别适用于写入密集型的应用场景。</p>
</li>
<li>
<p><strong>相关产品</strong>：虽然 Bitcask 最初是为 Riak 设计的，但它的应用并不局限于此。由于其开源性质和高效的性能特点，Bitcask 也被用于其他项目和应用中，尤其是在需要高速数据写入和检索的场景。</p>
</li>
</ol>
<p>总的来说，Bitcask 以其高效的数据写入和检索能力，在分布式数据库和存储系统领域占有一席之地，特别是在需要处理大量写入操作的应用中表现出色。</p>
<p><a href="https://riak.com/assets/bitcask-intro.pdf">bitcask-intro</a> 是对应的论文，可以进一步阅读。</p>
<h2 id="bitcask-原理"><a class="header" href="#bitcask-原理">Bitcask 原理</a></h2>
<p>Bitcask <strong>在内存中</strong>用一张哈希表来组织 Key 和 Value ，<strong>在磁盘上</strong>则是直接将数据追加到文件末尾。</p>
<ol>
<li>
<p><strong>日志结构化存储</strong>：Bitcask 所有的写入操作都是追加到文件末尾，而不是在文件中的特定位置，从而大大提高了写入性能。</p>
</li>
<li>
<p><strong>键/值对访问</strong>：在 Bitcask 中，数据以键/值对的形式存储。</p>
</li>
<li>
<p><strong>快速键查找</strong>：Bitcask 维护了一个内存中的哈希表，用于快速定位键对应的数据在文件中的位置，从而实现快速的数据检索。</p>
</li>
<li>
<p><strong>文件合并</strong>：随着时间的推移，日志文件会变得越来越大。Bitcask 通过定期合并这些文件来优化存储空间的使用，同时去除过期或被删除的数据。</p>
</li>
<li>
<p><strong>高效恢复机制</strong>：在系统崩溃或其他故障情况下，Bitcask 能够通过其日志文件快速恢复数据。</p>
</li>
</ol>
<p>简而言之，Bitcask 通过其日志结构化存储、快速键查找和高效的文件合并机制，提供了一种高效的方式来处理大量的写入操作，同时保持了良好的读取性能。</p>
<h2 id="bitcask-在内存中"><a class="header" href="#bitcask-在内存中">Bitcask 在内存中</a></h2>
<p>Bitcask 使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</p>
<p>当需要查找数据时，会先在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<p>Bitcask 存储引擎的架构可以分为以下几个部分：</p>
<ul>
<li><strong>数据存储</strong>：Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</li>
<li><strong>数据索引</strong>：Bitcask 存储引擎使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</li>
<li><strong>数据操作</strong>：Bitcask 存储引擎支持插入、删除和更新等数据操作。</li>
</ul>
<p><strong>数据存储</strong></p>
<p>Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</p>
<p>数据写入 Bitcask 存储引擎时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>当日志文件达到一定大小时，会被切分为一个段。段会被追加到一个段列表中。</p>
<p><strong>数据操作</strong></p>
<p>Bitcask 存储引擎支持插入、删除和更新等数据操作。</p>
<p>插入操作：将数据写入日志文件。</p>
<p>删除操作：将数据从段中删除，并更新哈希索引。</p>
<p>更新操作：将数据从段中删除，然后插入新的数据。</p>
<p><strong>Bitcask 的优势</strong></p>
<p>Bitcask 具有以下优势：</p>
<ul>
<li>高性能：Bitcask 采用了简单的设计，因此具有较高的性能。</li>
<li>高可靠性：Bitcask 使用了多种技术来保证数据的可靠性，包括日志记录、数据复制和数据校验。</li>
<li>低成本：Bitcask 使用了固定大小的文件存储数据，因此成本较低。</li>
</ul>
<p><strong>Bitcask 的劣势</strong></p>
<p>Bitcask 具有以下劣势：</p>
<ul>
<li>不支持事务处理：Bitcask 不支持事务处理。</li>
<li>不支持复杂查询：Bitcask 只支持简单的查询，不支持复杂查询。</li>
</ul>
<h2 id="写操作流程"><a class="header" href="#写操作流程">写操作流程</a></h2>
<p>在 Bitcask 中，写操作涉及到以下几个步骤：</p>
<ol>
<li><strong>将数据写入日志文件</strong></li>
</ol>
<p>数据写入 Bitcask 时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>日志文件的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<p>其中，键是数据的键，值是数据的值，时间戳是数据写入的时间戳。</p>
<ol start="2">
<li><strong>将日志文件切分为段</strong></li>
</ol>
<p>当日志文件达到一定大小时，会被切分为一个段。段的大小可以根据实际需要进行调整。</p>
<p>段的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<ol start="3">
<li><strong>将段追加到段列表中</strong></li>
</ol>
<p>段会被追加到一个段列表中。段列表用于记录所有已创建的段。</p>
<ol start="4">
<li><strong>更新哈希索引</strong></li>
</ol>
<p>哈希索引将键映射到段和位置。在将数据写入段后，需要更新哈希索引，以便快速查找数据。</p>
<p>更新哈希索引的步骤如下：</p>
<pre><code>1. 计算键的哈希值。
2. 查找哈希索引，找到对应的段和位置。
3. 如果段和位置不存在，则将段和位置添加到哈希索引中。
4. 如果段和位置存在，则更新哈希索引中的值。
</code></pre>
<p>需要注意的是，Bitcask 不支持事务处理。如果写操作失败，则数据可能丢失。</p>
<p>当读取数据时，根据 key 直接从哈希表中获取相应的 value 。</p>
<p>当写入数据时，将 key 和 value 打包以追加的方式写入日志文件中，与此同时还要将 kv 插入哈希表中。</p>
<h2 id="读操作流程"><a class="header" href="#读操作流程">读操作流程</a></h2>
<p>Bitcask 读操作涉及到以下几个步骤：</p>
<ol>
<li><strong>在哈希索引中查找键</strong></li>
</ol>
<p>读操作首先会在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<ol start="2">
<li><strong>读取数据</strong></li>
</ol>
<p>根据索引信息，读取数据所在的段和位置。</p>
<ol start="3">
<li><strong>返回数据</strong></li>
</ol>
<p>将数据返回给客户端。
当更新数据时，</p>
<h2 id="api-设计"><a class="header" href="#api-设计">API 设计</a></h2>
<p>Bitcask 的 API 非常简单，只有以下几种操作：</p>
<ul>
<li><strong>打开数据库</strong>：<code>bitcask:open(DirectoryName)</code> 用于打开一个新的或现有的数据库。如果指定了 <code>read write</code> 选项，则表示该进程可以进行写操作。如果指定了 <code>sync on put</code> 选项，则表示每次写操作后会将数据同步到磁盘。</li>
<li><strong>读取数据</strong>：<code>bitcask:get(BitcaskHandle, Key)</code> 用于读取数据库中指定键的数据。如果数据存在，则返回 <code>{ok, Value}</code>；如果数据不存在，则返回 <code>not found</code>。</li>
<li><strong>写入数据</strong>：<code>bitcask:put(BitcaskHandle, Key, Value)</code> 用于写入数据库中指定键的数据。如果写入成功，则返回 <code>ok</code>；如果写入失败，则返回错误信息。</li>
<li><strong>删除数据</strong>：<code>bitcask:delete(BitcaskHandle, Key)</code> 用于删除数据库中指定键的数据。如果删除成功，则返回 <code>ok</code>；如果删除失败，则返回错误信息。</li>
<li><strong>列出所有键</strong>：<code>bitcask:list keys(BitcaskHandle)</code> 用于列出数据库中的所有键。</li>
<li><strong>遍历数据库</strong>：<code>bitcask:fold(BitcaskHandle,Fun,Acc0)</code> 用于遍历数据库中的所有键值对。<code>Fun</code> 是一个函数，用于处理每个键值对。<code>Acc0</code> 是初始状态。</li>
<li><strong>合并数据库</strong>：<code>bitcask:merge(DirectoryName)</code> 用于合并数据库中的多个数据文件。</li>
<li><strong>强制同步数据</strong>：<code>bitcask:sync(BitcaskHandle)</code> 用于强制将数据同步到磁盘。</li>
<li><strong>关闭数据库</strong>：<code>bitcask:close(BitcaskHandle)</code> 用于关闭数据库。</li>
</ul>
<p>总体而言，Bitcask 的 API 非常简单易用。</p>
<pre class="mermaid">graph TD

  subgraph Memory
    A[Hash Table]
  end

  subgraph Disk
    style Disk fill:#99ccff,stroke:#6699cc
    B[Log File 1]
    C[Log File 2]
    D[...]
    E[Log File N]
  end

  I[Write Operation] --&gt;|Append to Log| C
  I --&gt;|Update Hash Table| A

  J[Read Operation] --&gt;|Lookup Hash Table| A

  A --&gt;|Lookup| B
  A --&gt;|Lookup| C
  A --&gt;|Lookup| D
  A --&gt;|Lookup| E

  F[Merge Process] --&gt;|Merge| E
  G[Garbage Collection] --&gt;|Collect| B
  G --&gt;|Collect| C
  G --&gt;|Collect| D
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="创建-c-项目"><a class="header" href="#创建-c-项目">创建 C++ 项目</a></h1>
<p>下面开始创建项目</p>
<h2 id="1-创建项目"><a class="header" href="#1-创建项目">1. 创建项目</a></h2>
<pre><code class="language-shell">$ mkdir aryadb &amp;&amp; cd aryadb
</code></pre>
<p>创建 main.cpp 并输入下面的内容</p>
<pre><code class="language-c++">#include &lt;iostream&gt;

int main()
{
    std::cout &lt;&lt; &quot;Hello, World!&quot; &lt;&lt; std::endl;
    return 0;
}
</code></pre>
<p>创建 CMakeLists.txt 并输入下面的内容：</p>
<pre><code class="language-cmake">cmake_minimum_required(VERSION 3.27)
project(aryadb)

set(CMAKE_CXX_STANDARD 23)

add_executable(aryadb main.cpp)
</code></pre>
<p>这段代码是一个 CMake 配置文件的一部分，用于设置和构建名为 &quot;aryadb&quot; 的项目。以下是对其主要内容的简要总结：</p>
<ol>
<li>
<p><strong>指定 CMake 最低版本</strong>：<code>cmake_minimum_required(VERSION 3.27)</code> 指定了构建此项目所需的最低 CMake 版本为 3.27。</p>
</li>
<li>
<p><strong>项目名称</strong>：<code>project(aryadb)</code> 设置了项目的名称为 &quot;aryadb&quot;。</p>
</li>
<li>
<p><strong>设置 C++ 标准</strong>：<code>set(CMAKE_CXX_STANDARD 23)</code> 指定了项目使用的 C++ 标准为 C++23。</p>
</li>
<li>
<p><strong>添加可执行文件</strong>：<code>add_executable(aryadb main.cpp)</code> 指示 CMake 为项目创建一个名为 &quot;aryadb&quot; 的可执行文件，源文件是 &quot;main.cpp&quot;。</p>
</li>
</ol>
<p>总的来说，这段 CMake 配置文件为名为 &quot;aryadb&quot; 的项目设置了基本的构建参数，包括 CMake 的最低版本要求、项目名称、使用的 C++ 标准以及主要的源文件。</p>
<p>在整个 <code>CMakeLists.txt</code> 文件中，定义了项目的基本属性和构建规则。CMake 是一个构建系统生成器，根据 <code>CMakeLists.txt</code> 文件中的指令，生成适用于编译器的实际构建文件（如 Makefile 或项目文件）。这样可以在多种不同的系统和环境中以一致的方式构建您的项目。</p>
<h2 id="2-执行"><a class="header" href="#2-执行">2. 执行</a></h2>
<p>接下来创建 build 编译并运行代码。</p>
<pre><code class="language-shell">mkdir -p build &amp;&amp; cd build
cmake .. &amp;&amp; make -j $(nproc) 
./aryadb
</code></pre>
<ol>
<li>
<p><code>mkdir -p build &amp;&amp; cd build</code></p>
<ul>
<li><code>mkdir -p build</code>: 这个命令创建一个名为 <code>build</code> 的新目录。如果这个目录已经存在，<code>-p</code>（代表“父级”）参数确保命令不会失败。这通常用于创建一个用于存放构建输出的目录，以保持项目根目录的整洁。</li>
<li><code>&amp;&amp;</code>: 这是一个命令连接符，它确保只有在左侧的命令（<code>mkdir -p build</code>）成功执行后，才会执行右侧的命令（<code>cd build</code>）。</li>
<li><code>cd build</code>: 这个命令切换当前目录到刚刚创建的 <code>build</code> 目录中。</li>
</ul>
</li>
<li>
<p><code>cmake .. &amp;&amp; make -j $(nproc)</code></p>
<ul>
<li><code>cmake ..</code>: 这个命令运行 CMake，指导它配置项目。<code>..</code> 是一个相对路径，指向当前目录的上一级目录，也就是您的项目根目录（这里假设您的 <code>CMakeLists.txt</code> 文件在那里）。CMake 会读取 <code>CMakeLists.txt</code> 文件，并生成相应的构建系统文件（如 Makefile）。</li>
<li><code>make -j $(nproc)</code>: 这个命令实际上开始构建过程。
<ul>
<li><code>make</code> 是一个构建工具，用于实际编译代码和链接二进制文件。</li>
<li><code>-j $(nproc)</code> 是一个加速编译过程的技巧。<code>-j</code> 参数允许 <code>make</code> 并行执行多个任务，而 <code>$(nproc)</code> 会被替换为当前系统可用的处理器核心数，从而使构建过程尽可能快地运行。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><code>./aryadb</code></p>
<ul>
<li>这个命令运行编译后生成的可执行文件 <code>aryadb</code>。<code>./</code> 指示终端在当前目录下查找名为 <code>aryadb</code> 的可执行文件并运行它。</li>
</ul>
</li>
</ol>
<p>综上所述，这些命令组合用于创建一个构建目录，使用 CMake 配置项目，编译项目，并最终运行编译后的程序。这是 C++ 项目通常的构建和运行流程。</p>
<h2 id="3-google-test"><a class="header" href="#3-google-test">3. Google Test</a></h2>
<p>接下来引入 Google Test 。Google Test 是一个由 Google 开发的 C++ 测试框架，专门用于编写单元测试。它提供了丰富的特性和工具，以支持开发者编写有效的单元测试。</p>
<p>注意在项目根目录下执行后续操作，不要在 build 目录下执行。</p>
<p>要以 Git 子模块（Git Submodule）的方式引入 Google Test（gtest）到项目中，需要执行以下步骤：</p>
<ol>
<li>
<p><strong>初始化 Git 子模块</strong>：
在您的 Git 项目根目录下，运行以下命令来初始化子模块系统。这一步只需要执行一次。</p>
<pre><code class="language-bash">git submodule init
</code></pre>
</li>
<li>
<p><strong>添加 gtest 作为子模块</strong>：
添加 Google Test 仓库作为子模块到您的项目中。您可以将子模块放置在您希望的任何目录下，这里以 <code>third_party/googletest</code> 为例。</p>
<pre><code class="language-bash">git submodule add https://github.com/google/googletest.git third_party/googletest
</code></pre>
</li>
<li>
<p><strong>更新子模块</strong>：
更新子模块，以确保您的项目包含了 Google Test 的最新代码。</p>
<pre><code class="language-bash">git submodule update --init --recursive
</code></pre>
</li>
<li>
<p><strong>集成到构建系统中</strong>：
根据项目的构建系统，需要在构建脚本中添加对 Google Test 子模块的引用。以 CMake 为例，可以在 CMakeLists.txt 中添加类似以下内容：</p>
<pre><code class="language-cmake"> enable_testing()
 add_subdirectory(&quot;third_party/googletest&quot;)

 add_executable(
     g_test
     g_test.cc
 )

 target_link_libraries(
     g_test
     GTest::gtest_main
 )

 include(GoogleTest)
 gtest_discover_tests(g_test)
</code></pre>
</li>
<li>
<p><strong>创建 <code>g_test.cc</code> 文件并输入下述内容，用于验证 gtest 能否正常使用。</strong></p>
<pre><code class="language-c++">#include &quot;gtest/gtest.h&quot;

TEST(HelloTest, BasicAssertions) {
    EXPECT_STRNE(&quot;hello&quot;, &quot;world&quot;);
    EXPECT_EQ(7 * 6, 42);
}
</code></pre>
</li>
<li>
<p><strong>验证是否成功</strong></p>
<pre><code>cd build &amp;&amp; cmake .. &amp;&amp; make -j $(nproc) &amp;&amp; ./g_test
...
[==========] Running 1 test from 1 test suite.
[----------] Global test environment set-up.
[----------] 1 test from HelloTest
[ RUN      ] HelloTest.BasicAssertions
[       OK ] HelloTest.BasicAssertions (0 ms)
[----------] 1 test from HelloTest (0 ms total)

[----------] Global test environment tear-down
[==========] 1 test from 1 test suite ran. (0 ms total)
[  PASSED  ] 1 test.
</code></pre>
</li>
</ol>
<p>这些步骤将 Google Test 作为一个子模块添加到 aryadb 项目中，使得可以方便地共享和更新测试框架。使用子模块还有助于保持项目的整洁和组织，同时确保依赖项的版本一致性。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据在磁盘上如何存放"><a class="header" href="#数据在磁盘上如何存放">数据在磁盘上如何存放？</a></h1>
<p>这一章节主要研究数据在磁盘上是如何组织的。先从自底向上的方式来描述所需的组件。</p>
<h2 id="1-如何组织一行数据"><a class="header" href="#1-如何组织一行数据">1. 如何组织一行数据？</a></h2>
<p>当在 Bitcask 数据库中存储一行数据时，它由数据头部和数据部分组成。下面是对这两部分各自包含的字段进行详细的解释：</p>
<p><strong>数据头部（Header）：</strong></p>
<p>数据头部包含了关于这一行数据的一些基本信息，如时间戳、键的大小和值的大小。它由三个字段组成：</p>
<ol>
<li>
<p><strong>时间戳（timestamp）</strong>：占据 4 个字节，表示数据创建的时间。</p>
</li>
<li>
<p><strong>键的大小（key_size）</strong>：占据 4 个字节，表示键的长度，即键有多少个字节。</p>
</li>
<li>
<p><strong>值的大小（value_size）</strong>：占据 4 个字节，表示值的长度，即值有多少个字节。</p>
</li>
</ol>
<p><strong>数据部分（Data）：</strong></p>
<p>数据部分是实际存储键值对的内容。它由两个字段组成：</p>
<ol>
<li>
<p><strong>键（key）</strong>：变长，根据键的大小确定，是实际存储的键值对的键部分。</p>
</li>
<li>
<p><strong>值（value）</strong>：变长，根据值的大小确定，是实际存储的键值对的值部分。</p>
</li>
</ol>
<pre><code>+----------------+----------------+----------------+------------+-------------+
| Timestamp (4B) | Key Size (4B)  | Value Size (4B)|   Key (?)  |   Value (?) |
+----------------+----------------+----------------+------------+-------------+
</code></pre>
<p>这种结构允许 Bitcask 数据库以高效且一致的方式存储各种大小的键值对，同时能够在读取时准确地解析和定位每个字段的信息。这为高效的数据存储和检索提供了基础。</p>
<p>根据上述内容，现在需要将数据编码为二进制的形式存入磁盘，然后再从磁盘中读取数据。所以可以继续拆分为头部数据和数据部分编码解码四部分内容。</p>
<h2 id="2-如何编码头部数据"><a class="header" href="#2-如何编码头部数据">2. 如何编码头部数据？</a></h2>
<p>当我们要将一个数据行的头部信息编码成字节流，使得数据库能够正确地存储和解析这些信息时，我们可以使用这段代码来完成这个任务。让我一步步地解释这段代码的每一部分，让你更好地理解它的工作原理。</p>
<pre><code class="language-go">func EncodeHeader(timestamp, keySize, valueSize uint32) ([]byte, error) {
    buf := new(bytes.Buffer)
    
    // 将时间戳按照小端字节序写入 buf 中
    if err := binary.Write(buf, binary.LittleEndian, timestamp); err != nil {
        return nil, err
    }
    
    // 将键的大小按照小端字节序写入 buf 中
    if err := binary.Write(buf, binary.LittleEndian, keySize); err != nil {
        return nil, err
    }
    
    // 将值的大小按照小端字节序写入 buf 中
    if err := binary.Write(buf, binary.LittleEndian, valueSize); err != nil {
        return nil, err
    }
    
    // 返回编码后的头部数据字节切片和 nil 错误
    return buf.Bytes(), nil
}
</code></pre>
<p>总结：</p>
<ol>
<li>
<p><strong>函数声明：</strong></p>
<pre><code class="language-go">func EncodeHeader(timestamp, keySize, valueSize uint32) ([]byte, error)
</code></pre>
<p>这行代码定义了一个名为 <code>EncodeHeader</code> 的函数，它接受三个参数：时间戳 <code>timestamp</code>、键的大小 <code>keySize</code> 和值的大小 <code>valueSize</code>。这个函数会返回两个值：编码后的头部数据字节切片和一个错误（如果有的话）。</p>
</li>
<li>
<p><strong>字节缓冲区的创建：</strong></p>
<pre><code class="language-go">buf := new(bytes.Buffer)
</code></pre>
<p>这里创建了一个新的字节缓冲区 <code>buf</code>，它会用于存储编码后的字节数据。</p>
</li>
<li>
<p><strong>编码时间戳、键的大小和值的大小：</strong></p>
<pre><code class="language-go">if err := binary.Write(buf, binary.LittleEndian, timestamp); err != nil {
    return nil, err
}
if err := binary.Write(buf, binary.LittleEndian, keySize); err != nil {
    return nil, err
}
if err := binary.Write(buf, binary.LittleEndian, valueSize); err != nil {
    return nil, err
}
</code></pre>
<p>这部分使用 <code>binary.Write</code> 函数将时间戳、键的大小和值的大小按照小端字节序写入字节缓冲区 <code>buf</code>。如果在写入过程中出现错误，函数会返回错误信息。</p>
</li>
<li>
<p><strong>返回编码后的头部数据：</strong></p>
<pre><code class="language-go">return buf.Bytes(), nil
</code></pre>
<p>最后，函数返回编码后的头部数据字节切片，以及一个 <code>nil</code> 错误。这个字节切片包含了编码后的时间戳、键的大小和值的大小信息。</p>
</li>
</ol>
<p>通过这段代码，我们能够将数据行的头部信息按照一定的格式编码成字节流，以便于数据库正确地存储和读取。这个过程就像是为头部信息做了一个标记，告诉数据库如何正确地保存它们。</p>
<h2 id="3-如何编码一条数据"><a class="header" href="#3-如何编码一条数据">3. 如何编码一条数据？</a></h2>
<p>这段代码帮助我们把这个键值对编码成一种数据库可以理解的格式，从而能够正确地存储和读取。我会逐步解释这段代码的每一部分，让你更好地理解它的工作原理。</p>
<ol>
<li>
<p><strong>函数声明：</strong></p>
<pre><code class="language-go">func EncodeKV(timestamp uint32, key, value string) (uint32, []byte, error) {
</code></pre>
<p>这行代码定义了一个函数 <code>EncodeKV</code>，它接受三个参数：时间戳 <code>timestamp</code>、键 <code>key</code> 和值 <code>value</code>。这个函数会返回三个值：总大小、编码后的数据行以及一个错误（如果出现错误）。</p>
</li>
<li>
<p><strong>编码头部：</strong></p>
<pre><code class="language-go">header, err := EncodeHeader(timestamp, uint32(len(key)), uint32(len(value)))
if err != nil {
    return 0, nil, err
}
</code></pre>
<p>在这一部分，我们调用了之前编写的 <code>EncodeHeader</code> 函数来编码时间戳、键的大小和值的大小。这样就得到了头部数据 <code>header</code>。如果在编码的过程中出现了错误，我们会返回一个错误信息。</p>
</li>
<li>
<p><strong>拼接数据：</strong></p>
<pre><code class="language-go">data := append(header, append([]byte(key), []byte(value)...)...)
</code></pre>
<p>这里，我们把头部数据 <code>header</code> 和键 <code>key</code> 以及值 <code>value</code> 的字节内容都连接在一起，形成了一个完整的数据行 <code>data</code>。</p>
</li>
<li>
<p><strong>计算总大小：</strong></p>
<pre><code class="language-go">return HeaderSize + uint32(len(key)) + uint32(len(value)), data, nil
</code></pre>
<p>最后，我们计算整个数据行的总大小。总大小由三部分组成：头部大小 <code>HeaderSize</code>、键的大小和值的大小之和。然后，我们把总大小、完整的数据行 <code>data</code> 以及一个 <code>nil</code> 错误一起返回。</p>
</li>
</ol>
<p>这段代码的目标是将一个键值对编码成 Bitcask 数据库能够理解的格式。它分为三个步骤：编码头部、拼接数据和计算总大小。通过这些步骤，我们能够将键值对以一种特定的方式存储在数据库中，使得在读取时能够准确地解析和处理它们。这个过程就像是在为数据做了一个标记，告诉数据库如何正确地保存它们。</p>
<p>下面的完整的结构</p>
<pre><code class="language-go">func EncodeKV(timestamp uint32, key, value string) (uint32, []byte, error) {
    // 使用 EncodeHeader 函数编码头部信息，得到头部数据
    header, err := EncodeHeader(timestamp, uint32(len(key)), uint32(len(value)))
    if err != nil {
        return 0, nil, err
    }

    // 将键和值的字节数据拼接在一起，形成完整的数据行
    data := append(header, append([]byte(key), []byte(value)...)...)

    // 计算整个数据行的总大小（包括头部、键和值）
    totalSize := HeaderSize + uint32(len(key)) + uint32(len(value))
        
    // 返回总大小、完整数据行的字节切片和 nil 错误
    return totalSize, data, nil
}
</code></pre>
<h2 id="4-如何解码头部数据"><a class="header" href="#4-如何解码头部数据">4. 如何解码头部数据？</a></h2>
<p>当我们需要从一个编码后的头部数据字节切片中解码出时间戳、键的大小和值的大小时，以便于理解数据行的结构和内容，我们可以使用这段代码来实现。我将逐步解释这段代码的每一部分，以便你更好地理解它的工作原理。</p>
<pre><code class="language-go">func DecodeHeader(data []byte) (uint32, uint32, uint32, error) {
	// 检查数据字节切片是否足够长，至少需要 HeaderSize 长度
	if len(data) &lt; HeaderSize {
		return 0, 0, 0, errors.New(&quot;data too short&quot;)
	}

	// 声明变量用于存储解码后的时间戳、键的大小和值的大小
	var timestamp, keySize, valueSize uint32

	// 创建一个字节读取器，并按照小端字节序从数据字节切片中依次读取时间戳、键的大小和值的大小
	buf := bytes.NewReader(data)
	if err := binary.Read(buf, binary.LittleEndian, &amp;timestamp); err != nil {
		return 0, 0, 0, err
	}
	if err := binary.Read(buf, binary.LittleEndian, &amp;keySize); err != nil {
		return 0, 0, 0, err
	}
	if err := binary.Read(buf, binary.LittleEndian, &amp;valueSize); err != nil {
		return 0, 0, 0, err
	}

	// 返回解码后的时间戳、键的大小、值的大小和 nil 错误
	return timestamp, keySize, valueSize, nil
}
</code></pre>
<p>总结：</p>
<ol>
<li>
<p><strong>函数声明：</strong></p>
<pre><code class="language-go">func DecodeHeader(data []byte) (uint32, uint32, uint32, error) {
</code></pre>
<p>这行代码定义了一个名为 <code>DecodeHeader</code> 的函数，它接受一个数据字节切片 <code>data</code> 作为参数。函数会返回三个解码后的值：时间戳、键的大小和值的大小，以及一个错误（如果有的话）。</p>
</li>
<li>
<p><strong>检查数据长度：</strong></p>
<pre><code class="language-go">if len(data) &lt; HeaderSize {
    return 0, 0, 0, errors.New(&quot;data too short&quot;)
}
</code></pre>
<p>这部分代码首先检查传入的数据字节切片 <code>data</code> 是否至少包含了头部的大小，如果不足够长，就返回一个错误。</p>
</li>
<li>
<p><strong>解码数据：</strong></p>
<pre><code class="language-go">var timestamp, keySize, valueSize uint32

buf := bytes.NewReader(data)
if err := binary.Read(buf, binary.LittleEndian, &amp;timestamp); err != nil {
    return 0, 0, 0, err
}
if err := binary.Read(buf, binary.LittleEndian, &amp;keySize); err != nil {
    return 0, 0, 0, err
}
if err := binary.Read(buf, binary.LittleEndian, &amp;valueSize); err != nil {
    return 0, 0, 0, err
}
</code></pre>
<p>这里我们使用 <code>binary.Read</code> 函数按照小端字节序从数据字节切片中依次解码时间戳、键的大小和值的大小。如果在解码过程中出现错误，函数会返回错误信息。</p>
</li>
<li>
<p><strong>返回解码结果：</strong></p>
<pre><code class="language-go">return timestamp, keySize, valueSize, nil
</code></pre>
<p>最后，函数返回解码后的时间戳、键的大小、值的大小和一个 <code>nil</code> 错误。这样的解码方式能够从头部数据中提取出时间戳、键的大小和值的大小，以便于理解数据行的结构和内容。</p>
</li>
</ol>
<h2 id="5-如何解码一条数据"><a class="header" href="#5-如何解码一条数据">5. 如何解码一条数据？</a></h2>
<p>当我们需要从一个编码后的数据行字节切片中解码出时间戳、键和值时，以便于理解数据行的内容和信息，我们可以使用这段代码来实现。我将逐步解释这段代码的每一部分，以便你更好地理解它的工作原理。</p>
<pre><code class="language-go">func DecodeKV(data []byte) (uint32, string, string, error) {
    // 检查数据字节切片是否足够长，至少需要 HeaderSize 长度
    if len(data) &lt; HeaderSize {
        return 0, &quot;&quot;, &quot;&quot;, errors.New(&quot;data too short&quot;)
    }

    // 解码数据行的头部，获取时间戳、键的大小和值的大小
    timestamp, keySize, valueSize, err := DecodeHeader(data[:HeaderSize])
    if err != nil {
        return 0, &quot;&quot;, &quot;&quot;, err
    }

    // 检查数据字节切片是否足够长，以保证可以解码键和值的内容
    if len(data) &lt; int(HeaderSize+keySize+valueSize) {
        return 0, &quot;&quot;, &quot;&quot;, errors.New(&quot;key/value data too short&quot;)
    }

    // 解码键和值的内容
    key := string(data[HeaderSize : HeaderSize+keySize])
    value := string(data[HeaderSize+keySize : HeaderSize+keySize+valueSize])

    // 返回解码后的时间戳、键、值和 nil 错误
    return timestamp, key, value, nil
}
</code></pre>
<p>总结：</p>
<ol>
<li>
<p><strong>函数声明：</strong></p>
<pre><code class="language-go">func DecodeKV(data []byte) (uint32, string, string, error) {
</code></pre>
<p>这行代码定义了一个名为 <code>DecodeKV</code> 的函数，它接受一个数据字节切片 <code>data</code> 作为参数。函数会返回四个解码后的值：时间戳、键、值以及一个错误（如果有的话）。</p>
</li>
<li>
<p><strong>检查数据长度：</strong></p>
<pre><code class="language-go">if len(data) &lt; HeaderSize {
    return 0, &quot;&quot;, &quot;&quot;, errors.New(&quot;data too short&quot;)
}
</code></pre>
<p>这部分代码首先检查传入的数据字节切片 <code>data</code> 是否至少包含了头部的大小，如果不足够长，就返回一个错误。</p>
</li>
<li>
<p><strong>解码数据行头部：</strong></p>
<pre><code class="language-go">timestamp, keySize, valueSize, err := DecodeHeader(data[:HeaderSize])
if err != nil {
    return 0, &quot;&quot;, &quot;&quot;, err
}
</code></pre>
<p>这里我们调用 <code>DecodeHeader</code> 函数来解码数据行的头部，以获取时间戳、键的大小和值的大小。如果在解码头部时出现错误，函数会返回错误信息。</p>
</li>
<li>
<p><strong>检查数据长度再次：</strong></p>
<pre><code class="language-go">if len(data) &lt; int(HeaderSize+keySize+valueSize) {
    return 0, &quot;&quot;, &quot;&quot;, errors.New(&quot;key/value data too short&quot;)
}
</code></pre>
<p>这部分代码再次检查传入的数据字节切片 <code>data</code> 是否足够长，以保证可以解码出键和值的内容。</p>
</li>
<li>
<p><strong>解码键和值的内容：</strong></p>
<pre><code class="language-go">key := string(data[HeaderSize : HeaderSize+keySize])
value := string(data[HeaderSize+keySize : HeaderSize+keySize+valueSize])
</code></pre>
<p>这部分将根据解码得到的键的大小和值的大小，从数据字节切片 <code>data</code> 中提取出键和值的内容，并将它们转换成字符串。</p>
</li>
<li>
<p><strong>返回解码结果：</strong></p>
<pre><code class="language-go">return timestamp, key, value, nil
</code></pre>
<p>最后，函数返回解码后的时间戳、键、值以及一个 <code>nil</code> 错误。这样的解码方式能够从数据行中提取出时间戳、键和值的内容，以便于理解数据行的信息和内容。</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bitcask-简介-1"><a class="header" href="#bitcask-简介-1">Bitcask 简介</a></h1>
<p>Bitcask 是一种简单的存储引擎，存储引擎是数据库的核心组件，负责存储和管理数据，即数据在内存，磁盘上是如何组织的，设计一个合理的存储引擎是为了实现高效的存取数据。</p>
<p>存储引擎以插件的形式存在，每个数据库可以支持多个存储引擎，不同的存储引擎具有不同的特性和性能，适用于不同的应用场景。例如，InnoDB 存储引擎支持事务处理，适用于在线事务处理（OLTP）应用；MyISAM 存储引擎不支持事务处理，但具有较高的性能，适用于数据库备份和报表等应用。</p>
<h2 id="bitcask-发展历史-1"><a class="header" href="#bitcask-发展历史-1">Bitcask 发展历史</a></h2>
<p>Bitcask 的起源和发展历史可以简要地概述如下：</p>
<ol>
<li>
<p><strong>起源</strong>：Bitcask 最初是由 Basho Technologies 为其开发的分布式数据库 Riak 设计的。这是一个 Erlang 应用程序，目的是提供一种高效的方式来存储和检索键/值对数据。</p>
</li>
<li>
<p><strong>设计灵感</strong>：Bitcask 的设计部分受到了日志结构化文件系统和日志文件合并技术的启发。它的主要特点是使用日志结构化哈希表，为键/值对存储提供快速访问。</p>
</li>
<li>
<p><strong>发展</strong>：Bitcask 随着 Riak 的普及而逐渐发展。它因其高性能写入和有效的读取性能而受到关注，特别适用于写入密集型的应用场景。</p>
</li>
<li>
<p><strong>相关产品</strong>：虽然 Bitcask 最初是为 Riak 设计的，但它的应用并不局限于此。由于其开源性质和高效的性能特点，Bitcask 也被用于其他项目和应用中，尤其是在需要高速数据写入和检索的场景。</p>
</li>
</ol>
<p>总的来说，Bitcask 以其高效的数据写入和检索能力，在分布式数据库和存储系统领域占有一席之地，特别是在需要处理大量写入操作的应用中表现出色。</p>
<p><a href="https://riak.com/assets/bitcask-intro.pdf">bitcask-intro</a> 是对应的论文，可以进一步阅读。</p>
<h2 id="bitcask-原理-1"><a class="header" href="#bitcask-原理-1">Bitcask 原理</a></h2>
<p>Bitcask <strong>在内存中</strong>用一张哈希表来组织 Key 和 Value ，<strong>在磁盘上</strong>则是直接将数据追加到文件末尾。</p>
<ol>
<li>
<p><strong>日志结构化存储</strong>：Bitcask 所有的写入操作都是追加到文件末尾，而不是在文件中的特定位置，从而大大提高了写入性能。</p>
</li>
<li>
<p><strong>键/值对访问</strong>：在 Bitcask 中，数据以键/值对的形式存储。</p>
</li>
<li>
<p><strong>快速键查找</strong>：Bitcask 维护了一个内存中的哈希表，用于快速定位键对应的数据在文件中的位置，从而实现快速的数据检索。</p>
</li>
<li>
<p><strong>文件合并</strong>：随着时间的推移，日志文件会变得越来越大。Bitcask 通过定期合并这些文件来优化存储空间的使用，同时去除过期或被删除的数据。</p>
</li>
<li>
<p><strong>高效恢复机制</strong>：在系统崩溃或其他故障情况下，Bitcask 能够通过其日志文件快速恢复数据。</p>
</li>
</ol>
<p>简而言之，Bitcask 通过其日志结构化存储、快速键查找和高效的文件合并机制，提供了一种高效的方式来处理大量的写入操作，同时保持了良好的读取性能。</p>
<h2 id="bitcask-在内存中-1"><a class="header" href="#bitcask-在内存中-1">Bitcask 在内存中</a></h2>
<p>Bitcask 使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</p>
<p>当需要查找数据时，会先在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<p>Bitcask 存储引擎的架构可以分为以下几个部分：</p>
<ul>
<li><strong>数据存储</strong>：Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</li>
<li><strong>数据索引</strong>：Bitcask 存储引擎使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</li>
<li><strong>数据操作</strong>：Bitcask 存储引擎支持插入、删除和更新等数据操作。</li>
</ul>
<p><strong>数据存储</strong></p>
<p>Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</p>
<p>数据写入 Bitcask 存储引擎时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>当日志文件达到一定大小时，会被切分为一个段。段会被追加到一个段列表中。</p>
<p><strong>数据操作</strong></p>
<p>Bitcask 存储引擎支持插入、删除和更新等数据操作。</p>
<p>插入操作：将数据写入日志文件。</p>
<p>删除操作：将数据从段中删除，并更新哈希索引。</p>
<p>更新操作：将数据从段中删除，然后插入新的数据。</p>
<p><strong>Bitcask 的优势</strong></p>
<p>Bitcask 具有以下优势：</p>
<ul>
<li>高性能：Bitcask 采用了简单的设计，因此具有较高的性能。</li>
<li>高可靠性：Bitcask 使用了多种技术来保证数据的可靠性，包括日志记录、数据复制和数据校验。</li>
<li>低成本：Bitcask 使用了固定大小的文件存储数据，因此成本较低。</li>
</ul>
<p><strong>Bitcask 的劣势</strong></p>
<p>Bitcask 具有以下劣势：</p>
<ul>
<li>不支持事务处理：Bitcask 不支持事务处理。</li>
<li>不支持复杂查询：Bitcask 只支持简单的查询，不支持复杂查询。</li>
</ul>
<h2 id="写操作流程-1"><a class="header" href="#写操作流程-1">写操作流程</a></h2>
<p>在 Bitcask 中，写操作涉及到以下几个步骤：</p>
<ol>
<li><strong>将数据写入日志文件</strong></li>
</ol>
<p>数据写入 Bitcask 时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>日志文件的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<p>其中，键是数据的键，值是数据的值，时间戳是数据写入的时间戳。</p>
<ol start="2">
<li><strong>将日志文件切分为段</strong></li>
</ol>
<p>当日志文件达到一定大小时，会被切分为一个段。段的大小可以根据实际需要进行调整。</p>
<p>段的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<ol start="3">
<li><strong>将段追加到段列表中</strong></li>
</ol>
<p>段会被追加到一个段列表中。段列表用于记录所有已创建的段。</p>
<ol start="4">
<li><strong>更新哈希索引</strong></li>
</ol>
<p>哈希索引将键映射到段和位置。在将数据写入段后，需要更新哈希索引，以便快速查找数据。</p>
<p>更新哈希索引的步骤如下：</p>
<pre><code>1. 计算键的哈希值。
2. 查找哈希索引，找到对应的段和位置。
3. 如果段和位置不存在，则将段和位置添加到哈希索引中。
4. 如果段和位置存在，则更新哈希索引中的值。
</code></pre>
<p>需要注意的是，Bitcask 不支持事务处理。如果写操作失败，则数据可能丢失。</p>
<p>当读取数据时，根据 key 直接从哈希表中获取相应的 value 。</p>
<p>当写入数据时，将 key 和 value 打包以追加的方式写入日志文件中，与此同时还要将 kv 插入哈希表中。</p>
<h2 id="读操作流程-1"><a class="header" href="#读操作流程-1">读操作流程</a></h2>
<p>Bitcask 读操作涉及到以下几个步骤：</p>
<ol>
<li><strong>在哈希索引中查找键</strong></li>
</ol>
<p>读操作首先会在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<ol start="2">
<li><strong>读取数据</strong></li>
</ol>
<p>根据索引信息，读取数据所在的段和位置。</p>
<ol start="3">
<li><strong>返回数据</strong></li>
</ol>
<p>将数据返回给客户端。
当更新数据时，</p>
<h2 id="api-设计-1"><a class="header" href="#api-设计-1">API 设计</a></h2>
<p>Bitcask 的 API 非常简单，只有以下几种操作：</p>
<ul>
<li><strong>打开数据库</strong>：<code>bitcask:open(DirectoryName)</code> 用于打开一个新的或现有的数据库。如果指定了 <code>read write</code> 选项，则表示该进程可以进行写操作。如果指定了 <code>sync on put</code> 选项，则表示每次写操作后会将数据同步到磁盘。</li>
<li><strong>读取数据</strong>：<code>bitcask:get(BitcaskHandle, Key)</code> 用于读取数据库中指定键的数据。如果数据存在，则返回 <code>{ok, Value}</code>；如果数据不存在，则返回 <code>not found</code>。</li>
<li><strong>写入数据</strong>：<code>bitcask:put(BitcaskHandle, Key, Value)</code> 用于写入数据库中指定键的数据。如果写入成功，则返回 <code>ok</code>；如果写入失败，则返回错误信息。</li>
<li><strong>删除数据</strong>：<code>bitcask:delete(BitcaskHandle, Key)</code> 用于删除数据库中指定键的数据。如果删除成功，则返回 <code>ok</code>；如果删除失败，则返回错误信息。</li>
<li><strong>列出所有键</strong>：<code>bitcask:list keys(BitcaskHandle)</code> 用于列出数据库中的所有键。</li>
<li><strong>遍历数据库</strong>：<code>bitcask:fold(BitcaskHandle,Fun,Acc0)</code> 用于遍历数据库中的所有键值对。<code>Fun</code> 是一个函数，用于处理每个键值对。<code>Acc0</code> 是初始状态。</li>
<li><strong>合并数据库</strong>：<code>bitcask:merge(DirectoryName)</code> 用于合并数据库中的多个数据文件。</li>
<li><strong>强制同步数据</strong>：<code>bitcask:sync(BitcaskHandle)</code> 用于强制将数据同步到磁盘。</li>
<li><strong>关闭数据库</strong>：<code>bitcask:close(BitcaskHandle)</code> 用于关闭数据库。</li>
</ul>
<p>总体而言，Bitcask 的 API 非常简单易用。</p>
<pre class="mermaid">graph TD

  subgraph Memory
    A[Hash Table]
  end

  subgraph Disk
    style Disk fill:#99ccff,stroke:#6699cc
    B[Log File 1]
    C[Log File 2]
    D[...]
    E[Log File N]
  end

  I[Write Operation] --&gt;|Append to Log| C
  I --&gt;|Update Hash Table| A

  J[Read Operation] --&gt;|Lookup Hash Table| A

  A --&gt;|Lookup| B
  A --&gt;|Lookup| C
  A --&gt;|Lookup| D
  A --&gt;|Lookup| E

  F[Merge Process] --&gt;|Merge| E
  G[Garbage Collection] --&gt;|Collect| B
  G --&gt;|Collect| C
  G --&gt;|Collect| D
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bitcask-简介-2"><a class="header" href="#bitcask-简介-2">Bitcask 简介</a></h1>
<p>Bitcask 是一种简单的存储引擎，存储引擎是数据库的核心组件，负责存储和管理数据，即数据在内存，磁盘上是如何组织的，设计一个合理的存储引擎是为了实现高效的存取数据。</p>
<p>存储引擎以插件的形式存在，每个数据库可以支持多个存储引擎，不同的存储引擎具有不同的特性和性能，适用于不同的应用场景。例如，InnoDB 存储引擎支持事务处理，适用于在线事务处理（OLTP）应用；MyISAM 存储引擎不支持事务处理，但具有较高的性能，适用于数据库备份和报表等应用。</p>
<h2 id="bitcask-发展历史-2"><a class="header" href="#bitcask-发展历史-2">Bitcask 发展历史</a></h2>
<p>Bitcask 的起源和发展历史可以简要地概述如下：</p>
<ol>
<li>
<p><strong>起源</strong>：Bitcask 最初是由 Basho Technologies 为其开发的分布式数据库 Riak 设计的。这是一个 Erlang 应用程序，目的是提供一种高效的方式来存储和检索键/值对数据。</p>
</li>
<li>
<p><strong>设计灵感</strong>：Bitcask 的设计部分受到了日志结构化文件系统和日志文件合并技术的启发。它的主要特点是使用日志结构化哈希表，为键/值对存储提供快速访问。</p>
</li>
<li>
<p><strong>发展</strong>：Bitcask 随着 Riak 的普及而逐渐发展。它因其高性能写入和有效的读取性能而受到关注，特别适用于写入密集型的应用场景。</p>
</li>
<li>
<p><strong>相关产品</strong>：虽然 Bitcask 最初是为 Riak 设计的，但它的应用并不局限于此。由于其开源性质和高效的性能特点，Bitcask 也被用于其他项目和应用中，尤其是在需要高速数据写入和检索的场景。</p>
</li>
</ol>
<p>总的来说，Bitcask 以其高效的数据写入和检索能力，在分布式数据库和存储系统领域占有一席之地，特别是在需要处理大量写入操作的应用中表现出色。</p>
<p><a href="https://riak.com/assets/bitcask-intro.pdf">bitcask-intro</a> 是对应的论文，可以进一步阅读。</p>
<h2 id="bitcask-原理-2"><a class="header" href="#bitcask-原理-2">Bitcask 原理</a></h2>
<p>Bitcask <strong>在内存中</strong>用一张哈希表来组织 Key 和 Value ，<strong>在磁盘上</strong>则是直接将数据追加到文件末尾。</p>
<ol>
<li>
<p><strong>日志结构化存储</strong>：Bitcask 所有的写入操作都是追加到文件末尾，而不是在文件中的特定位置，从而大大提高了写入性能。</p>
</li>
<li>
<p><strong>键/值对访问</strong>：在 Bitcask 中，数据以键/值对的形式存储。</p>
</li>
<li>
<p><strong>快速键查找</strong>：Bitcask 维护了一个内存中的哈希表，用于快速定位键对应的数据在文件中的位置，从而实现快速的数据检索。</p>
</li>
<li>
<p><strong>文件合并</strong>：随着时间的推移，日志文件会变得越来越大。Bitcask 通过定期合并这些文件来优化存储空间的使用，同时去除过期或被删除的数据。</p>
</li>
<li>
<p><strong>高效恢复机制</strong>：在系统崩溃或其他故障情况下，Bitcask 能够通过其日志文件快速恢复数据。</p>
</li>
</ol>
<p>简而言之，Bitcask 通过其日志结构化存储、快速键查找和高效的文件合并机制，提供了一种高效的方式来处理大量的写入操作，同时保持了良好的读取性能。</p>
<h2 id="bitcask-在内存中-2"><a class="header" href="#bitcask-在内存中-2">Bitcask 在内存中</a></h2>
<p>Bitcask 使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</p>
<p>当需要查找数据时，会先在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<p>Bitcask 存储引擎的架构可以分为以下几个部分：</p>
<ul>
<li><strong>数据存储</strong>：Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</li>
<li><strong>数据索引</strong>：Bitcask 存储引擎使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</li>
<li><strong>数据操作</strong>：Bitcask 存储引擎支持插入、删除和更新等数据操作。</li>
</ul>
<p><strong>数据存储</strong></p>
<p>Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</p>
<p>数据写入 Bitcask 存储引擎时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>当日志文件达到一定大小时，会被切分为一个段。段会被追加到一个段列表中。</p>
<p><strong>数据操作</strong></p>
<p>Bitcask 存储引擎支持插入、删除和更新等数据操作。</p>
<p>插入操作：将数据写入日志文件。</p>
<p>删除操作：将数据从段中删除，并更新哈希索引。</p>
<p>更新操作：将数据从段中删除，然后插入新的数据。</p>
<p><strong>Bitcask 的优势</strong></p>
<p>Bitcask 具有以下优势：</p>
<ul>
<li>高性能：Bitcask 采用了简单的设计，因此具有较高的性能。</li>
<li>高可靠性：Bitcask 使用了多种技术来保证数据的可靠性，包括日志记录、数据复制和数据校验。</li>
<li>低成本：Bitcask 使用了固定大小的文件存储数据，因此成本较低。</li>
</ul>
<p><strong>Bitcask 的劣势</strong></p>
<p>Bitcask 具有以下劣势：</p>
<ul>
<li>不支持事务处理：Bitcask 不支持事务处理。</li>
<li>不支持复杂查询：Bitcask 只支持简单的查询，不支持复杂查询。</li>
</ul>
<h2 id="写操作流程-2"><a class="header" href="#写操作流程-2">写操作流程</a></h2>
<p>在 Bitcask 中，写操作涉及到以下几个步骤：</p>
<ol>
<li><strong>将数据写入日志文件</strong></li>
</ol>
<p>数据写入 Bitcask 时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>日志文件的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<p>其中，键是数据的键，值是数据的值，时间戳是数据写入的时间戳。</p>
<ol start="2">
<li><strong>将日志文件切分为段</strong></li>
</ol>
<p>当日志文件达到一定大小时，会被切分为一个段。段的大小可以根据实际需要进行调整。</p>
<p>段的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<ol start="3">
<li><strong>将段追加到段列表中</strong></li>
</ol>
<p>段会被追加到一个段列表中。段列表用于记录所有已创建的段。</p>
<ol start="4">
<li><strong>更新哈希索引</strong></li>
</ol>
<p>哈希索引将键映射到段和位置。在将数据写入段后，需要更新哈希索引，以便快速查找数据。</p>
<p>更新哈希索引的步骤如下：</p>
<pre><code>1. 计算键的哈希值。
2. 查找哈希索引，找到对应的段和位置。
3. 如果段和位置不存在，则将段和位置添加到哈希索引中。
4. 如果段和位置存在，则更新哈希索引中的值。
</code></pre>
<p>需要注意的是，Bitcask 不支持事务处理。如果写操作失败，则数据可能丢失。</p>
<p>当读取数据时，根据 key 直接从哈希表中获取相应的 value 。</p>
<p>当写入数据时，将 key 和 value 打包以追加的方式写入日志文件中，与此同时还要将 kv 插入哈希表中。</p>
<h2 id="读操作流程-2"><a class="header" href="#读操作流程-2">读操作流程</a></h2>
<p>Bitcask 读操作涉及到以下几个步骤：</p>
<ol>
<li><strong>在哈希索引中查找键</strong></li>
</ol>
<p>读操作首先会在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<ol start="2">
<li><strong>读取数据</strong></li>
</ol>
<p>根据索引信息，读取数据所在的段和位置。</p>
<ol start="3">
<li><strong>返回数据</strong></li>
</ol>
<p>将数据返回给客户端。
当更新数据时，</p>
<h2 id="api-设计-2"><a class="header" href="#api-设计-2">API 设计</a></h2>
<p>Bitcask 的 API 非常简单，只有以下几种操作：</p>
<ul>
<li><strong>打开数据库</strong>：<code>bitcask:open(DirectoryName)</code> 用于打开一个新的或现有的数据库。如果指定了 <code>read write</code> 选项，则表示该进程可以进行写操作。如果指定了 <code>sync on put</code> 选项，则表示每次写操作后会将数据同步到磁盘。</li>
<li><strong>读取数据</strong>：<code>bitcask:get(BitcaskHandle, Key)</code> 用于读取数据库中指定键的数据。如果数据存在，则返回 <code>{ok, Value}</code>；如果数据不存在，则返回 <code>not found</code>。</li>
<li><strong>写入数据</strong>：<code>bitcask:put(BitcaskHandle, Key, Value)</code> 用于写入数据库中指定键的数据。如果写入成功，则返回 <code>ok</code>；如果写入失败，则返回错误信息。</li>
<li><strong>删除数据</strong>：<code>bitcask:delete(BitcaskHandle, Key)</code> 用于删除数据库中指定键的数据。如果删除成功，则返回 <code>ok</code>；如果删除失败，则返回错误信息。</li>
<li><strong>列出所有键</strong>：<code>bitcask:list keys(BitcaskHandle)</code> 用于列出数据库中的所有键。</li>
<li><strong>遍历数据库</strong>：<code>bitcask:fold(BitcaskHandle,Fun,Acc0)</code> 用于遍历数据库中的所有键值对。<code>Fun</code> 是一个函数，用于处理每个键值对。<code>Acc0</code> 是初始状态。</li>
<li><strong>合并数据库</strong>：<code>bitcask:merge(DirectoryName)</code> 用于合并数据库中的多个数据文件。</li>
<li><strong>强制同步数据</strong>：<code>bitcask:sync(BitcaskHandle)</code> 用于强制将数据同步到磁盘。</li>
<li><strong>关闭数据库</strong>：<code>bitcask:close(BitcaskHandle)</code> 用于关闭数据库。</li>
</ul>
<p>总体而言，Bitcask 的 API 非常简单易用。</p>
<pre class="mermaid">graph TD

  subgraph Memory
    A[Hash Table]
  end

  subgraph Disk
    style Disk fill:#99ccff,stroke:#6699cc
    B[Log File 1]
    C[Log File 2]
    D[...]
    E[Log File N]
  end

  I[Write Operation] --&gt;|Append to Log| C
  I --&gt;|Update Hash Table| A

  J[Read Operation] --&gt;|Lookup Hash Table| A

  A --&gt;|Lookup| B
  A --&gt;|Lookup| C
  A --&gt;|Lookup| D
  A --&gt;|Lookup| E

  F[Merge Process] --&gt;|Merge| E
  G[Garbage Collection] --&gt;|Collect| B
  G --&gt;|Collect| C
  G --&gt;|Collect| D
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bitcask-简介-3"><a class="header" href="#bitcask-简介-3">Bitcask 简介</a></h1>
<p>Bitcask 是一种简单的存储引擎，存储引擎是数据库的核心组件，负责存储和管理数据，即数据在内存，磁盘上是如何组织的，设计一个合理的存储引擎是为了实现高效的存取数据。</p>
<p>存储引擎以插件的形式存在，每个数据库可以支持多个存储引擎，不同的存储引擎具有不同的特性和性能，适用于不同的应用场景。例如，InnoDB 存储引擎支持事务处理，适用于在线事务处理（OLTP）应用；MyISAM 存储引擎不支持事务处理，但具有较高的性能，适用于数据库备份和报表等应用。</p>
<h2 id="bitcask-发展历史-3"><a class="header" href="#bitcask-发展历史-3">Bitcask 发展历史</a></h2>
<p>Bitcask 的起源和发展历史可以简要地概述如下：</p>
<ol>
<li>
<p><strong>起源</strong>：Bitcask 最初是由 Basho Technologies 为其开发的分布式数据库 Riak 设计的。这是一个 Erlang 应用程序，目的是提供一种高效的方式来存储和检索键/值对数据。</p>
</li>
<li>
<p><strong>设计灵感</strong>：Bitcask 的设计部分受到了日志结构化文件系统和日志文件合并技术的启发。它的主要特点是使用日志结构化哈希表，为键/值对存储提供快速访问。</p>
</li>
<li>
<p><strong>发展</strong>：Bitcask 随着 Riak 的普及而逐渐发展。它因其高性能写入和有效的读取性能而受到关注，特别适用于写入密集型的应用场景。</p>
</li>
<li>
<p><strong>相关产品</strong>：虽然 Bitcask 最初是为 Riak 设计的，但它的应用并不局限于此。由于其开源性质和高效的性能特点，Bitcask 也被用于其他项目和应用中，尤其是在需要高速数据写入和检索的场景。</p>
</li>
</ol>
<p>总的来说，Bitcask 以其高效的数据写入和检索能力，在分布式数据库和存储系统领域占有一席之地，特别是在需要处理大量写入操作的应用中表现出色。</p>
<p><a href="https://riak.com/assets/bitcask-intro.pdf">bitcask-intro</a> 是对应的论文，可以进一步阅读。</p>
<h2 id="bitcask-原理-3"><a class="header" href="#bitcask-原理-3">Bitcask 原理</a></h2>
<p>Bitcask <strong>在内存中</strong>用一张哈希表来组织 Key 和 Value ，<strong>在磁盘上</strong>则是直接将数据追加到文件末尾。</p>
<ol>
<li>
<p><strong>日志结构化存储</strong>：Bitcask 所有的写入操作都是追加到文件末尾，而不是在文件中的特定位置，从而大大提高了写入性能。</p>
</li>
<li>
<p><strong>键/值对访问</strong>：在 Bitcask 中，数据以键/值对的形式存储。</p>
</li>
<li>
<p><strong>快速键查找</strong>：Bitcask 维护了一个内存中的哈希表，用于快速定位键对应的数据在文件中的位置，从而实现快速的数据检索。</p>
</li>
<li>
<p><strong>文件合并</strong>：随着时间的推移，日志文件会变得越来越大。Bitcask 通过定期合并这些文件来优化存储空间的使用，同时去除过期或被删除的数据。</p>
</li>
<li>
<p><strong>高效恢复机制</strong>：在系统崩溃或其他故障情况下，Bitcask 能够通过其日志文件快速恢复数据。</p>
</li>
</ol>
<p>简而言之，Bitcask 通过其日志结构化存储、快速键查找和高效的文件合并机制，提供了一种高效的方式来处理大量的写入操作，同时保持了良好的读取性能。</p>
<h2 id="bitcask-在内存中-3"><a class="header" href="#bitcask-在内存中-3">Bitcask 在内存中</a></h2>
<p>Bitcask 使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</p>
<p>当需要查找数据时，会先在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<p>Bitcask 存储引擎的架构可以分为以下几个部分：</p>
<ul>
<li><strong>数据存储</strong>：Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</li>
<li><strong>数据索引</strong>：Bitcask 存储引擎使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</li>
<li><strong>数据操作</strong>：Bitcask 存储引擎支持插入、删除和更新等数据操作。</li>
</ul>
<p><strong>数据存储</strong></p>
<p>Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</p>
<p>数据写入 Bitcask 存储引擎时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>当日志文件达到一定大小时，会被切分为一个段。段会被追加到一个段列表中。</p>
<p><strong>数据操作</strong></p>
<p>Bitcask 存储引擎支持插入、删除和更新等数据操作。</p>
<p>插入操作：将数据写入日志文件。</p>
<p>删除操作：将数据从段中删除，并更新哈希索引。</p>
<p>更新操作：将数据从段中删除，然后插入新的数据。</p>
<p><strong>Bitcask 的优势</strong></p>
<p>Bitcask 具有以下优势：</p>
<ul>
<li>高性能：Bitcask 采用了简单的设计，因此具有较高的性能。</li>
<li>高可靠性：Bitcask 使用了多种技术来保证数据的可靠性，包括日志记录、数据复制和数据校验。</li>
<li>低成本：Bitcask 使用了固定大小的文件存储数据，因此成本较低。</li>
</ul>
<p><strong>Bitcask 的劣势</strong></p>
<p>Bitcask 具有以下劣势：</p>
<ul>
<li>不支持事务处理：Bitcask 不支持事务处理。</li>
<li>不支持复杂查询：Bitcask 只支持简单的查询，不支持复杂查询。</li>
</ul>
<h2 id="写操作流程-3"><a class="header" href="#写操作流程-3">写操作流程</a></h2>
<p>在 Bitcask 中，写操作涉及到以下几个步骤：</p>
<ol>
<li><strong>将数据写入日志文件</strong></li>
</ol>
<p>数据写入 Bitcask 时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>日志文件的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<p>其中，键是数据的键，值是数据的值，时间戳是数据写入的时间戳。</p>
<ol start="2">
<li><strong>将日志文件切分为段</strong></li>
</ol>
<p>当日志文件达到一定大小时，会被切分为一个段。段的大小可以根据实际需要进行调整。</p>
<p>段的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<ol start="3">
<li><strong>将段追加到段列表中</strong></li>
</ol>
<p>段会被追加到一个段列表中。段列表用于记录所有已创建的段。</p>
<ol start="4">
<li><strong>更新哈希索引</strong></li>
</ol>
<p>哈希索引将键映射到段和位置。在将数据写入段后，需要更新哈希索引，以便快速查找数据。</p>
<p>更新哈希索引的步骤如下：</p>
<pre><code>1. 计算键的哈希值。
2. 查找哈希索引，找到对应的段和位置。
3. 如果段和位置不存在，则将段和位置添加到哈希索引中。
4. 如果段和位置存在，则更新哈希索引中的值。
</code></pre>
<p>需要注意的是，Bitcask 不支持事务处理。如果写操作失败，则数据可能丢失。</p>
<p>当读取数据时，根据 key 直接从哈希表中获取相应的 value 。</p>
<p>当写入数据时，将 key 和 value 打包以追加的方式写入日志文件中，与此同时还要将 kv 插入哈希表中。</p>
<h2 id="读操作流程-3"><a class="header" href="#读操作流程-3">读操作流程</a></h2>
<p>Bitcask 读操作涉及到以下几个步骤：</p>
<ol>
<li><strong>在哈希索引中查找键</strong></li>
</ol>
<p>读操作首先会在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<ol start="2">
<li><strong>读取数据</strong></li>
</ol>
<p>根据索引信息，读取数据所在的段和位置。</p>
<ol start="3">
<li><strong>返回数据</strong></li>
</ol>
<p>将数据返回给客户端。
当更新数据时，</p>
<h2 id="api-设计-3"><a class="header" href="#api-设计-3">API 设计</a></h2>
<p>Bitcask 的 API 非常简单，只有以下几种操作：</p>
<ul>
<li><strong>打开数据库</strong>：<code>bitcask:open(DirectoryName)</code> 用于打开一个新的或现有的数据库。如果指定了 <code>read write</code> 选项，则表示该进程可以进行写操作。如果指定了 <code>sync on put</code> 选项，则表示每次写操作后会将数据同步到磁盘。</li>
<li><strong>读取数据</strong>：<code>bitcask:get(BitcaskHandle, Key)</code> 用于读取数据库中指定键的数据。如果数据存在，则返回 <code>{ok, Value}</code>；如果数据不存在，则返回 <code>not found</code>。</li>
<li><strong>写入数据</strong>：<code>bitcask:put(BitcaskHandle, Key, Value)</code> 用于写入数据库中指定键的数据。如果写入成功，则返回 <code>ok</code>；如果写入失败，则返回错误信息。</li>
<li><strong>删除数据</strong>：<code>bitcask:delete(BitcaskHandle, Key)</code> 用于删除数据库中指定键的数据。如果删除成功，则返回 <code>ok</code>；如果删除失败，则返回错误信息。</li>
<li><strong>列出所有键</strong>：<code>bitcask:list keys(BitcaskHandle)</code> 用于列出数据库中的所有键。</li>
<li><strong>遍历数据库</strong>：<code>bitcask:fold(BitcaskHandle,Fun,Acc0)</code> 用于遍历数据库中的所有键值对。<code>Fun</code> 是一个函数，用于处理每个键值对。<code>Acc0</code> 是初始状态。</li>
<li><strong>合并数据库</strong>：<code>bitcask:merge(DirectoryName)</code> 用于合并数据库中的多个数据文件。</li>
<li><strong>强制同步数据</strong>：<code>bitcask:sync(BitcaskHandle)</code> 用于强制将数据同步到磁盘。</li>
<li><strong>关闭数据库</strong>：<code>bitcask:close(BitcaskHandle)</code> 用于关闭数据库。</li>
</ul>
<p>总体而言，Bitcask 的 API 非常简单易用。</p>
<pre class="mermaid">graph TD

  subgraph Memory
    A[Hash Table]
  end

  subgraph Disk
    style Disk fill:#99ccff,stroke:#6699cc
    B[Log File 1]
    C[Log File 2]
    D[...]
    E[Log File N]
  end

  I[Write Operation] --&gt;|Append to Log| C
  I --&gt;|Update Hash Table| A

  J[Read Operation] --&gt;|Lookup Hash Table| A

  A --&gt;|Lookup| B
  A --&gt;|Lookup| C
  A --&gt;|Lookup| D
  A --&gt;|Lookup| E

  F[Merge Process] --&gt;|Merge| E
  G[Garbage Collection] --&gt;|Collect| B
  G --&gt;|Collect| C
  G --&gt;|Collect| D
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bitcask-简介-4"><a class="header" href="#bitcask-简介-4">Bitcask 简介</a></h1>
<p>Bitcask 是一种简单的存储引擎，存储引擎是数据库的核心组件，负责存储和管理数据，即数据在内存，磁盘上是如何组织的，设计一个合理的存储引擎是为了实现高效的存取数据。</p>
<p>存储引擎以插件的形式存在，每个数据库可以支持多个存储引擎，不同的存储引擎具有不同的特性和性能，适用于不同的应用场景。例如，InnoDB 存储引擎支持事务处理，适用于在线事务处理（OLTP）应用；MyISAM 存储引擎不支持事务处理，但具有较高的性能，适用于数据库备份和报表等应用。</p>
<h2 id="bitcask-发展历史-4"><a class="header" href="#bitcask-发展历史-4">Bitcask 发展历史</a></h2>
<p>Bitcask 的起源和发展历史可以简要地概述如下：</p>
<ol>
<li>
<p><strong>起源</strong>：Bitcask 最初是由 Basho Technologies 为其开发的分布式数据库 Riak 设计的。这是一个 Erlang 应用程序，目的是提供一种高效的方式来存储和检索键/值对数据。</p>
</li>
<li>
<p><strong>设计灵感</strong>：Bitcask 的设计部分受到了日志结构化文件系统和日志文件合并技术的启发。它的主要特点是使用日志结构化哈希表，为键/值对存储提供快速访问。</p>
</li>
<li>
<p><strong>发展</strong>：Bitcask 随着 Riak 的普及而逐渐发展。它因其高性能写入和有效的读取性能而受到关注，特别适用于写入密集型的应用场景。</p>
</li>
<li>
<p><strong>相关产品</strong>：虽然 Bitcask 最初是为 Riak 设计的，但它的应用并不局限于此。由于其开源性质和高效的性能特点，Bitcask 也被用于其他项目和应用中，尤其是在需要高速数据写入和检索的场景。</p>
</li>
</ol>
<p>总的来说，Bitcask 以其高效的数据写入和检索能力，在分布式数据库和存储系统领域占有一席之地，特别是在需要处理大量写入操作的应用中表现出色。</p>
<p><a href="https://riak.com/assets/bitcask-intro.pdf">bitcask-intro</a> 是对应的论文，可以进一步阅读。</p>
<h2 id="bitcask-原理-4"><a class="header" href="#bitcask-原理-4">Bitcask 原理</a></h2>
<p>Bitcask <strong>在内存中</strong>用一张哈希表来组织 Key 和 Value ，<strong>在磁盘上</strong>则是直接将数据追加到文件末尾。</p>
<ol>
<li>
<p><strong>日志结构化存储</strong>：Bitcask 所有的写入操作都是追加到文件末尾，而不是在文件中的特定位置，从而大大提高了写入性能。</p>
</li>
<li>
<p><strong>键/值对访问</strong>：在 Bitcask 中，数据以键/值对的形式存储。</p>
</li>
<li>
<p><strong>快速键查找</strong>：Bitcask 维护了一个内存中的哈希表，用于快速定位键对应的数据在文件中的位置，从而实现快速的数据检索。</p>
</li>
<li>
<p><strong>文件合并</strong>：随着时间的推移，日志文件会变得越来越大。Bitcask 通过定期合并这些文件来优化存储空间的使用，同时去除过期或被删除的数据。</p>
</li>
<li>
<p><strong>高效恢复机制</strong>：在系统崩溃或其他故障情况下，Bitcask 能够通过其日志文件快速恢复数据。</p>
</li>
</ol>
<p>简而言之，Bitcask 通过其日志结构化存储、快速键查找和高效的文件合并机制，提供了一种高效的方式来处理大量的写入操作，同时保持了良好的读取性能。</p>
<h2 id="bitcask-在内存中-4"><a class="header" href="#bitcask-在内存中-4">Bitcask 在内存中</a></h2>
<p>Bitcask 使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</p>
<p>当需要查找数据时，会先在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<p>Bitcask 存储引擎的架构可以分为以下几个部分：</p>
<ul>
<li><strong>数据存储</strong>：Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</li>
<li><strong>数据索引</strong>：Bitcask 存储引擎使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</li>
<li><strong>数据操作</strong>：Bitcask 存储引擎支持插入、删除和更新等数据操作。</li>
</ul>
<p><strong>数据存储</strong></p>
<p>Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</p>
<p>数据写入 Bitcask 存储引擎时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>当日志文件达到一定大小时，会被切分为一个段。段会被追加到一个段列表中。</p>
<p><strong>数据操作</strong></p>
<p>Bitcask 存储引擎支持插入、删除和更新等数据操作。</p>
<p>插入操作：将数据写入日志文件。</p>
<p>删除操作：将数据从段中删除，并更新哈希索引。</p>
<p>更新操作：将数据从段中删除，然后插入新的数据。</p>
<p><strong>Bitcask 的优势</strong></p>
<p>Bitcask 具有以下优势：</p>
<ul>
<li>高性能：Bitcask 采用了简单的设计，因此具有较高的性能。</li>
<li>高可靠性：Bitcask 使用了多种技术来保证数据的可靠性，包括日志记录、数据复制和数据校验。</li>
<li>低成本：Bitcask 使用了固定大小的文件存储数据，因此成本较低。</li>
</ul>
<p><strong>Bitcask 的劣势</strong></p>
<p>Bitcask 具有以下劣势：</p>
<ul>
<li>不支持事务处理：Bitcask 不支持事务处理。</li>
<li>不支持复杂查询：Bitcask 只支持简单的查询，不支持复杂查询。</li>
</ul>
<h2 id="写操作流程-4"><a class="header" href="#写操作流程-4">写操作流程</a></h2>
<p>在 Bitcask 中，写操作涉及到以下几个步骤：</p>
<ol>
<li><strong>将数据写入日志文件</strong></li>
</ol>
<p>数据写入 Bitcask 时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>日志文件的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<p>其中，键是数据的键，值是数据的值，时间戳是数据写入的时间戳。</p>
<ol start="2">
<li><strong>将日志文件切分为段</strong></li>
</ol>
<p>当日志文件达到一定大小时，会被切分为一个段。段的大小可以根据实际需要进行调整。</p>
<p>段的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<ol start="3">
<li><strong>将段追加到段列表中</strong></li>
</ol>
<p>段会被追加到一个段列表中。段列表用于记录所有已创建的段。</p>
<ol start="4">
<li><strong>更新哈希索引</strong></li>
</ol>
<p>哈希索引将键映射到段和位置。在将数据写入段后，需要更新哈希索引，以便快速查找数据。</p>
<p>更新哈希索引的步骤如下：</p>
<pre><code>1. 计算键的哈希值。
2. 查找哈希索引，找到对应的段和位置。
3. 如果段和位置不存在，则将段和位置添加到哈希索引中。
4. 如果段和位置存在，则更新哈希索引中的值。
</code></pre>
<p>需要注意的是，Bitcask 不支持事务处理。如果写操作失败，则数据可能丢失。</p>
<p>当读取数据时，根据 key 直接从哈希表中获取相应的 value 。</p>
<p>当写入数据时，将 key 和 value 打包以追加的方式写入日志文件中，与此同时还要将 kv 插入哈希表中。</p>
<h2 id="读操作流程-4"><a class="header" href="#读操作流程-4">读操作流程</a></h2>
<p>Bitcask 读操作涉及到以下几个步骤：</p>
<ol>
<li><strong>在哈希索引中查找键</strong></li>
</ol>
<p>读操作首先会在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<ol start="2">
<li><strong>读取数据</strong></li>
</ol>
<p>根据索引信息，读取数据所在的段和位置。</p>
<ol start="3">
<li><strong>返回数据</strong></li>
</ol>
<p>将数据返回给客户端。
当更新数据时，</p>
<h2 id="api-设计-4"><a class="header" href="#api-设计-4">API 设计</a></h2>
<p>Bitcask 的 API 非常简单，只有以下几种操作：</p>
<ul>
<li><strong>打开数据库</strong>：<code>bitcask:open(DirectoryName)</code> 用于打开一个新的或现有的数据库。如果指定了 <code>read write</code> 选项，则表示该进程可以进行写操作。如果指定了 <code>sync on put</code> 选项，则表示每次写操作后会将数据同步到磁盘。</li>
<li><strong>读取数据</strong>：<code>bitcask:get(BitcaskHandle, Key)</code> 用于读取数据库中指定键的数据。如果数据存在，则返回 <code>{ok, Value}</code>；如果数据不存在，则返回 <code>not found</code>。</li>
<li><strong>写入数据</strong>：<code>bitcask:put(BitcaskHandle, Key, Value)</code> 用于写入数据库中指定键的数据。如果写入成功，则返回 <code>ok</code>；如果写入失败，则返回错误信息。</li>
<li><strong>删除数据</strong>：<code>bitcask:delete(BitcaskHandle, Key)</code> 用于删除数据库中指定键的数据。如果删除成功，则返回 <code>ok</code>；如果删除失败，则返回错误信息。</li>
<li><strong>列出所有键</strong>：<code>bitcask:list keys(BitcaskHandle)</code> 用于列出数据库中的所有键。</li>
<li><strong>遍历数据库</strong>：<code>bitcask:fold(BitcaskHandle,Fun,Acc0)</code> 用于遍历数据库中的所有键值对。<code>Fun</code> 是一个函数，用于处理每个键值对。<code>Acc0</code> 是初始状态。</li>
<li><strong>合并数据库</strong>：<code>bitcask:merge(DirectoryName)</code> 用于合并数据库中的多个数据文件。</li>
<li><strong>强制同步数据</strong>：<code>bitcask:sync(BitcaskHandle)</code> 用于强制将数据同步到磁盘。</li>
<li><strong>关闭数据库</strong>：<code>bitcask:close(BitcaskHandle)</code> 用于关闭数据库。</li>
</ul>
<p>总体而言，Bitcask 的 API 非常简单易用。</p>
<pre class="mermaid">graph TD

  subgraph Memory
    A[Hash Table]
  end

  subgraph Disk
    style Disk fill:#99ccff,stroke:#6699cc
    B[Log File 1]
    C[Log File 2]
    D[...]
    E[Log File N]
  end

  I[Write Operation] --&gt;|Append to Log| C
  I --&gt;|Update Hash Table| A

  J[Read Operation] --&gt;|Lookup Hash Table| A

  A --&gt;|Lookup| B
  A --&gt;|Lookup| C
  A --&gt;|Lookup| D
  A --&gt;|Lookup| E

  F[Merge Process] --&gt;|Merge| E
  G[Garbage Collection] --&gt;|Collect| B
  G --&gt;|Collect| C
  G --&gt;|Collect| D
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bitcask-简介-5"><a class="header" href="#bitcask-简介-5">Bitcask 简介</a></h1>
<p>Bitcask 是一种简单的存储引擎，存储引擎是数据库的核心组件，负责存储和管理数据，即数据在内存，磁盘上是如何组织的，设计一个合理的存储引擎是为了实现高效的存取数据。</p>
<p>存储引擎以插件的形式存在，每个数据库可以支持多个存储引擎，不同的存储引擎具有不同的特性和性能，适用于不同的应用场景。例如，InnoDB 存储引擎支持事务处理，适用于在线事务处理（OLTP）应用；MyISAM 存储引擎不支持事务处理，但具有较高的性能，适用于数据库备份和报表等应用。</p>
<h2 id="bitcask-发展历史-5"><a class="header" href="#bitcask-发展历史-5">Bitcask 发展历史</a></h2>
<p>Bitcask 的起源和发展历史可以简要地概述如下：</p>
<ol>
<li>
<p><strong>起源</strong>：Bitcask 最初是由 Basho Technologies 为其开发的分布式数据库 Riak 设计的。这是一个 Erlang 应用程序，目的是提供一种高效的方式来存储和检索键/值对数据。</p>
</li>
<li>
<p><strong>设计灵感</strong>：Bitcask 的设计部分受到了日志结构化文件系统和日志文件合并技术的启发。它的主要特点是使用日志结构化哈希表，为键/值对存储提供快速访问。</p>
</li>
<li>
<p><strong>发展</strong>：Bitcask 随着 Riak 的普及而逐渐发展。它因其高性能写入和有效的读取性能而受到关注，特别适用于写入密集型的应用场景。</p>
</li>
<li>
<p><strong>相关产品</strong>：虽然 Bitcask 最初是为 Riak 设计的，但它的应用并不局限于此。由于其开源性质和高效的性能特点，Bitcask 也被用于其他项目和应用中，尤其是在需要高速数据写入和检索的场景。</p>
</li>
</ol>
<p>总的来说，Bitcask 以其高效的数据写入和检索能力，在分布式数据库和存储系统领域占有一席之地，特别是在需要处理大量写入操作的应用中表现出色。</p>
<p><a href="https://riak.com/assets/bitcask-intro.pdf">bitcask-intro</a> 是对应的论文，可以进一步阅读。</p>
<h2 id="bitcask-原理-5"><a class="header" href="#bitcask-原理-5">Bitcask 原理</a></h2>
<p>Bitcask <strong>在内存中</strong>用一张哈希表来组织 Key 和 Value ，<strong>在磁盘上</strong>则是直接将数据追加到文件末尾。</p>
<ol>
<li>
<p><strong>日志结构化存储</strong>：Bitcask 所有的写入操作都是追加到文件末尾，而不是在文件中的特定位置，从而大大提高了写入性能。</p>
</li>
<li>
<p><strong>键/值对访问</strong>：在 Bitcask 中，数据以键/值对的形式存储。</p>
</li>
<li>
<p><strong>快速键查找</strong>：Bitcask 维护了一个内存中的哈希表，用于快速定位键对应的数据在文件中的位置，从而实现快速的数据检索。</p>
</li>
<li>
<p><strong>文件合并</strong>：随着时间的推移，日志文件会变得越来越大。Bitcask 通过定期合并这些文件来优化存储空间的使用，同时去除过期或被删除的数据。</p>
</li>
<li>
<p><strong>高效恢复机制</strong>：在系统崩溃或其他故障情况下，Bitcask 能够通过其日志文件快速恢复数据。</p>
</li>
</ol>
<p>简而言之，Bitcask 通过其日志结构化存储、快速键查找和高效的文件合并机制，提供了一种高效的方式来处理大量的写入操作，同时保持了良好的读取性能。</p>
<h2 id="bitcask-在内存中-5"><a class="header" href="#bitcask-在内存中-5">Bitcask 在内存中</a></h2>
<p>Bitcask 使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</p>
<p>当需要查找数据时，会先在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<p>Bitcask 存储引擎的架构可以分为以下几个部分：</p>
<ul>
<li><strong>数据存储</strong>：Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</li>
<li><strong>数据索引</strong>：Bitcask 存储引擎使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</li>
<li><strong>数据操作</strong>：Bitcask 存储引擎支持插入、删除和更新等数据操作。</li>
</ul>
<p><strong>数据存储</strong></p>
<p>Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</p>
<p>数据写入 Bitcask 存储引擎时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>当日志文件达到一定大小时，会被切分为一个段。段会被追加到一个段列表中。</p>
<p><strong>数据操作</strong></p>
<p>Bitcask 存储引擎支持插入、删除和更新等数据操作。</p>
<p>插入操作：将数据写入日志文件。</p>
<p>删除操作：将数据从段中删除，并更新哈希索引。</p>
<p>更新操作：将数据从段中删除，然后插入新的数据。</p>
<p><strong>Bitcask 的优势</strong></p>
<p>Bitcask 具有以下优势：</p>
<ul>
<li>高性能：Bitcask 采用了简单的设计，因此具有较高的性能。</li>
<li>高可靠性：Bitcask 使用了多种技术来保证数据的可靠性，包括日志记录、数据复制和数据校验。</li>
<li>低成本：Bitcask 使用了固定大小的文件存储数据，因此成本较低。</li>
</ul>
<p><strong>Bitcask 的劣势</strong></p>
<p>Bitcask 具有以下劣势：</p>
<ul>
<li>不支持事务处理：Bitcask 不支持事务处理。</li>
<li>不支持复杂查询：Bitcask 只支持简单的查询，不支持复杂查询。</li>
</ul>
<h2 id="写操作流程-5"><a class="header" href="#写操作流程-5">写操作流程</a></h2>
<p>在 Bitcask 中，写操作涉及到以下几个步骤：</p>
<ol>
<li><strong>将数据写入日志文件</strong></li>
</ol>
<p>数据写入 Bitcask 时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>日志文件的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<p>其中，键是数据的键，值是数据的值，时间戳是数据写入的时间戳。</p>
<ol start="2">
<li><strong>将日志文件切分为段</strong></li>
</ol>
<p>当日志文件达到一定大小时，会被切分为一个段。段的大小可以根据实际需要进行调整。</p>
<p>段的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<ol start="3">
<li><strong>将段追加到段列表中</strong></li>
</ol>
<p>段会被追加到一个段列表中。段列表用于记录所有已创建的段。</p>
<ol start="4">
<li><strong>更新哈希索引</strong></li>
</ol>
<p>哈希索引将键映射到段和位置。在将数据写入段后，需要更新哈希索引，以便快速查找数据。</p>
<p>更新哈希索引的步骤如下：</p>
<pre><code>1. 计算键的哈希值。
2. 查找哈希索引，找到对应的段和位置。
3. 如果段和位置不存在，则将段和位置添加到哈希索引中。
4. 如果段和位置存在，则更新哈希索引中的值。
</code></pre>
<p>需要注意的是，Bitcask 不支持事务处理。如果写操作失败，则数据可能丢失。</p>
<p>当读取数据时，根据 key 直接从哈希表中获取相应的 value 。</p>
<p>当写入数据时，将 key 和 value 打包以追加的方式写入日志文件中，与此同时还要将 kv 插入哈希表中。</p>
<h2 id="读操作流程-5"><a class="header" href="#读操作流程-5">读操作流程</a></h2>
<p>Bitcask 读操作涉及到以下几个步骤：</p>
<ol>
<li><strong>在哈希索引中查找键</strong></li>
</ol>
<p>读操作首先会在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<ol start="2">
<li><strong>读取数据</strong></li>
</ol>
<p>根据索引信息，读取数据所在的段和位置。</p>
<ol start="3">
<li><strong>返回数据</strong></li>
</ol>
<p>将数据返回给客户端。
当更新数据时，</p>
<h2 id="api-设计-5"><a class="header" href="#api-设计-5">API 设计</a></h2>
<p>Bitcask 的 API 非常简单，只有以下几种操作：</p>
<ul>
<li><strong>打开数据库</strong>：<code>bitcask:open(DirectoryName)</code> 用于打开一个新的或现有的数据库。如果指定了 <code>read write</code> 选项，则表示该进程可以进行写操作。如果指定了 <code>sync on put</code> 选项，则表示每次写操作后会将数据同步到磁盘。</li>
<li><strong>读取数据</strong>：<code>bitcask:get(BitcaskHandle, Key)</code> 用于读取数据库中指定键的数据。如果数据存在，则返回 <code>{ok, Value}</code>；如果数据不存在，则返回 <code>not found</code>。</li>
<li><strong>写入数据</strong>：<code>bitcask:put(BitcaskHandle, Key, Value)</code> 用于写入数据库中指定键的数据。如果写入成功，则返回 <code>ok</code>；如果写入失败，则返回错误信息。</li>
<li><strong>删除数据</strong>：<code>bitcask:delete(BitcaskHandle, Key)</code> 用于删除数据库中指定键的数据。如果删除成功，则返回 <code>ok</code>；如果删除失败，则返回错误信息。</li>
<li><strong>列出所有键</strong>：<code>bitcask:list keys(BitcaskHandle)</code> 用于列出数据库中的所有键。</li>
<li><strong>遍历数据库</strong>：<code>bitcask:fold(BitcaskHandle,Fun,Acc0)</code> 用于遍历数据库中的所有键值对。<code>Fun</code> 是一个函数，用于处理每个键值对。<code>Acc0</code> 是初始状态。</li>
<li><strong>合并数据库</strong>：<code>bitcask:merge(DirectoryName)</code> 用于合并数据库中的多个数据文件。</li>
<li><strong>强制同步数据</strong>：<code>bitcask:sync(BitcaskHandle)</code> 用于强制将数据同步到磁盘。</li>
<li><strong>关闭数据库</strong>：<code>bitcask:close(BitcaskHandle)</code> 用于关闭数据库。</li>
</ul>
<p>总体而言，Bitcask 的 API 非常简单易用。</p>
<pre class="mermaid">graph TD

  subgraph Memory
    A[Hash Table]
  end

  subgraph Disk
    style Disk fill:#99ccff,stroke:#6699cc
    B[Log File 1]
    C[Log File 2]
    D[...]
    E[Log File N]
  end

  I[Write Operation] --&gt;|Append to Log| C
  I --&gt;|Update Hash Table| A

  J[Read Operation] --&gt;|Lookup Hash Table| A

  A --&gt;|Lookup| B
  A --&gt;|Lookup| C
  A --&gt;|Lookup| D
  A --&gt;|Lookup| E

  F[Merge Process] --&gt;|Merge| E
  G[Garbage Collection] --&gt;|Collect| B
  G --&gt;|Collect| C
  G --&gt;|Collect| D
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bitcask-简介-6"><a class="header" href="#bitcask-简介-6">Bitcask 简介</a></h1>
<p>Bitcask 是一种简单的存储引擎，存储引擎是数据库的核心组件，负责存储和管理数据，即数据在内存，磁盘上是如何组织的，设计一个合理的存储引擎是为了实现高效的存取数据。</p>
<p>存储引擎以插件的形式存在，每个数据库可以支持多个存储引擎，不同的存储引擎具有不同的特性和性能，适用于不同的应用场景。例如，InnoDB 存储引擎支持事务处理，适用于在线事务处理（OLTP）应用；MyISAM 存储引擎不支持事务处理，但具有较高的性能，适用于数据库备份和报表等应用。</p>
<h2 id="bitcask-发展历史-6"><a class="header" href="#bitcask-发展历史-6">Bitcask 发展历史</a></h2>
<p>Bitcask 的起源和发展历史可以简要地概述如下：</p>
<ol>
<li>
<p><strong>起源</strong>：Bitcask 最初是由 Basho Technologies 为其开发的分布式数据库 Riak 设计的。这是一个 Erlang 应用程序，目的是提供一种高效的方式来存储和检索键/值对数据。</p>
</li>
<li>
<p><strong>设计灵感</strong>：Bitcask 的设计部分受到了日志结构化文件系统和日志文件合并技术的启发。它的主要特点是使用日志结构化哈希表，为键/值对存储提供快速访问。</p>
</li>
<li>
<p><strong>发展</strong>：Bitcask 随着 Riak 的普及而逐渐发展。它因其高性能写入和有效的读取性能而受到关注，特别适用于写入密集型的应用场景。</p>
</li>
<li>
<p><strong>相关产品</strong>：虽然 Bitcask 最初是为 Riak 设计的，但它的应用并不局限于此。由于其开源性质和高效的性能特点，Bitcask 也被用于其他项目和应用中，尤其是在需要高速数据写入和检索的场景。</p>
</li>
</ol>
<p>总的来说，Bitcask 以其高效的数据写入和检索能力，在分布式数据库和存储系统领域占有一席之地，特别是在需要处理大量写入操作的应用中表现出色。</p>
<p><a href="https://riak.com/assets/bitcask-intro.pdf">bitcask-intro</a> 是对应的论文，可以进一步阅读。</p>
<h2 id="bitcask-原理-6"><a class="header" href="#bitcask-原理-6">Bitcask 原理</a></h2>
<p>Bitcask <strong>在内存中</strong>用一张哈希表来组织 Key 和 Value ，<strong>在磁盘上</strong>则是直接将数据追加到文件末尾。</p>
<ol>
<li>
<p><strong>日志结构化存储</strong>：Bitcask 所有的写入操作都是追加到文件末尾，而不是在文件中的特定位置，从而大大提高了写入性能。</p>
</li>
<li>
<p><strong>键/值对访问</strong>：在 Bitcask 中，数据以键/值对的形式存储。</p>
</li>
<li>
<p><strong>快速键查找</strong>：Bitcask 维护了一个内存中的哈希表，用于快速定位键对应的数据在文件中的位置，从而实现快速的数据检索。</p>
</li>
<li>
<p><strong>文件合并</strong>：随着时间的推移，日志文件会变得越来越大。Bitcask 通过定期合并这些文件来优化存储空间的使用，同时去除过期或被删除的数据。</p>
</li>
<li>
<p><strong>高效恢复机制</strong>：在系统崩溃或其他故障情况下，Bitcask 能够通过其日志文件快速恢复数据。</p>
</li>
</ol>
<p>简而言之，Bitcask 通过其日志结构化存储、快速键查找和高效的文件合并机制，提供了一种高效的方式来处理大量的写入操作，同时保持了良好的读取性能。</p>
<h2 id="bitcask-在内存中-6"><a class="header" href="#bitcask-在内存中-6">Bitcask 在内存中</a></h2>
<p>Bitcask 使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</p>
<p>当需要查找数据时，会先在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<p>Bitcask 存储引擎的架构可以分为以下几个部分：</p>
<ul>
<li><strong>数据存储</strong>：Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</li>
<li><strong>数据索引</strong>：Bitcask 存储引擎使用哈希索引来快速查找数据。哈希索引将键映射到段和位置。</li>
<li><strong>数据操作</strong>：Bitcask 存储引擎支持插入、删除和更新等数据操作。</li>
</ul>
<p><strong>数据存储</strong></p>
<p>Bitcask 存储引擎使用固定大小的文件存储数据，每个文件称为一个段（segment）。段的大小可以根据实际需要进行调整。</p>
<p>数据写入 Bitcask 存储引擎时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>当日志文件达到一定大小时，会被切分为一个段。段会被追加到一个段列表中。</p>
<p><strong>数据操作</strong></p>
<p>Bitcask 存储引擎支持插入、删除和更新等数据操作。</p>
<p>插入操作：将数据写入日志文件。</p>
<p>删除操作：将数据从段中删除，并更新哈希索引。</p>
<p>更新操作：将数据从段中删除，然后插入新的数据。</p>
<p><strong>Bitcask 的优势</strong></p>
<p>Bitcask 具有以下优势：</p>
<ul>
<li>高性能：Bitcask 采用了简单的设计，因此具有较高的性能。</li>
<li>高可靠性：Bitcask 使用了多种技术来保证数据的可靠性，包括日志记录、数据复制和数据校验。</li>
<li>低成本：Bitcask 使用了固定大小的文件存储数据，因此成本较低。</li>
</ul>
<p><strong>Bitcask 的劣势</strong></p>
<p>Bitcask 具有以下劣势：</p>
<ul>
<li>不支持事务处理：Bitcask 不支持事务处理。</li>
<li>不支持复杂查询：Bitcask 只支持简单的查询，不支持复杂查询。</li>
</ul>
<h2 id="写操作流程-6"><a class="header" href="#写操作流程-6">写操作流程</a></h2>
<p>在 Bitcask 中，写操作涉及到以下几个步骤：</p>
<ol>
<li><strong>将数据写入日志文件</strong></li>
</ol>
<p>数据写入 Bitcask 时，首先会将数据写入一个日志文件中。日志文件是一个追加写文件，因此可以保证数据的顺序性。</p>
<p>日志文件的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<p>其中，键是数据的键，值是数据的值，时间戳是数据写入的时间戳。</p>
<ol start="2">
<li><strong>将日志文件切分为段</strong></li>
</ol>
<p>当日志文件达到一定大小时，会被切分为一个段。段的大小可以根据实际需要进行调整。</p>
<p>段的格式如下：</p>
<pre><code>&lt;键&gt; &lt;值&gt; &lt;时间戳&gt;
</code></pre>
<ol start="3">
<li><strong>将段追加到段列表中</strong></li>
</ol>
<p>段会被追加到一个段列表中。段列表用于记录所有已创建的段。</p>
<ol start="4">
<li><strong>更新哈希索引</strong></li>
</ol>
<p>哈希索引将键映射到段和位置。在将数据写入段后，需要更新哈希索引，以便快速查找数据。</p>
<p>更新哈希索引的步骤如下：</p>
<pre><code>1. 计算键的哈希值。
2. 查找哈希索引，找到对应的段和位置。
3. 如果段和位置不存在，则将段和位置添加到哈希索引中。
4. 如果段和位置存在，则更新哈希索引中的值。
</code></pre>
<p>需要注意的是，Bitcask 不支持事务处理。如果写操作失败，则数据可能丢失。</p>
<p>当读取数据时，根据 key 直接从哈希表中获取相应的 value 。</p>
<p>当写入数据时，将 key 和 value 打包以追加的方式写入日志文件中，与此同时还要将 kv 插入哈希表中。</p>
<h2 id="读操作流程-6"><a class="header" href="#读操作流程-6">读操作流程</a></h2>
<p>Bitcask 读操作涉及到以下几个步骤：</p>
<ol>
<li><strong>在哈希索引中查找键</strong></li>
</ol>
<p>读操作首先会在哈希索引中查找键。如果找到了键，则可以根据索引信息直接定位到段和位置。</p>
<ol start="2">
<li><strong>读取数据</strong></li>
</ol>
<p>根据索引信息，读取数据所在的段和位置。</p>
<ol start="3">
<li><strong>返回数据</strong></li>
</ol>
<p>将数据返回给客户端。
当更新数据时，</p>
<h2 id="api-设计-6"><a class="header" href="#api-设计-6">API 设计</a></h2>
<p>Bitcask 的 API 非常简单，只有以下几种操作：</p>
<ul>
<li><strong>打开数据库</strong>：<code>bitcask:open(DirectoryName)</code> 用于打开一个新的或现有的数据库。如果指定了 <code>read write</code> 选项，则表示该进程可以进行写操作。如果指定了 <code>sync on put</code> 选项，则表示每次写操作后会将数据同步到磁盘。</li>
<li><strong>读取数据</strong>：<code>bitcask:get(BitcaskHandle, Key)</code> 用于读取数据库中指定键的数据。如果数据存在，则返回 <code>{ok, Value}</code>；如果数据不存在，则返回 <code>not found</code>。</li>
<li><strong>写入数据</strong>：<code>bitcask:put(BitcaskHandle, Key, Value)</code> 用于写入数据库中指定键的数据。如果写入成功，则返回 <code>ok</code>；如果写入失败，则返回错误信息。</li>
<li><strong>删除数据</strong>：<code>bitcask:delete(BitcaskHandle, Key)</code> 用于删除数据库中指定键的数据。如果删除成功，则返回 <code>ok</code>；如果删除失败，则返回错误信息。</li>
<li><strong>列出所有键</strong>：<code>bitcask:list keys(BitcaskHandle)</code> 用于列出数据库中的所有键。</li>
<li><strong>遍历数据库</strong>：<code>bitcask:fold(BitcaskHandle,Fun,Acc0)</code> 用于遍历数据库中的所有键值对。<code>Fun</code> 是一个函数，用于处理每个键值对。<code>Acc0</code> 是初始状态。</li>
<li><strong>合并数据库</strong>：<code>bitcask:merge(DirectoryName)</code> 用于合并数据库中的多个数据文件。</li>
<li><strong>强制同步数据</strong>：<code>bitcask:sync(BitcaskHandle)</code> 用于强制将数据同步到磁盘。</li>
<li><strong>关闭数据库</strong>：<code>bitcask:close(BitcaskHandle)</code> 用于关闭数据库。</li>
</ul>
<p>总体而言，Bitcask 的 API 非常简单易用。</p>
<pre class="mermaid">graph TD

  subgraph Memory
    A[Hash Table]
  end

  subgraph Disk
    style Disk fill:#99ccff,stroke:#6699cc
    B[Log File 1]
    C[Log File 2]
    D[...]
    E[Log File N]
  end

  I[Write Operation] --&gt;|Append to Log| C
  I --&gt;|Update Hash Table| A

  J[Read Operation] --&gt;|Lookup Hash Table| A

  A --&gt;|Lookup| B
  A --&gt;|Lookup| C
  A --&gt;|Lookup| D
  A --&gt;|Lookup| E

  F[Merge Process] --&gt;|Merge| E
  G[Garbage Collection] --&gt;|Collect| B
  G --&gt;|Collect| C
  G --&gt;|Collect| D
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据在磁盘上如何存放-1"><a class="header" href="#数据在磁盘上如何存放-1">数据在磁盘上如何存放？</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-2-存储引擎的接口设计"><a class="header" href="#part-2-存储引擎的接口设计">Part 2. 存储引擎的接口设计</a></h1>
<p>这一章以自顶向下的方式来描述，将要实现一个什么样的东西，以及如何使用。</p>
<h2 id="如何使用-diskstorage-"><a class="header" href="#如何使用-diskstorage-">如何使用 DiskStorage ？</a></h2>
<p>下面讲了该怎么使用这个存储引擎，首先就是如何实例化。要实例化 <code>DiskStorage</code>，可以使用提供的构造函数 <code>NewDiskStorage</code>。这个构造函数接受一个文件名作为参数，并返回一个 <code>DiskStorage</code> 实例的指针，同时会进行初始化操作，包括初始化 <code>KeyDir</code> 索引映射和打开文件。</p>
<p>下面是一个实例化 <code>DiskStorage</code> 的示例代码：</p>
<pre><code class="language-go">func main() {
    // 调用 NewDiskStorage 构造函数来实例化 DiskStorage
    storage, err := NewDiskStorage(&quot;data.db&quot;)
    if err != nil {
        fmt.Println(&quot;Error creating DiskStorage:&quot;, err)
        return
    }
    defer storage.Close() // 最后关闭存储实例

    // 使用实例进行操作
    err = storage.Set(&quot;key1&quot;, &quot;value1&quot;)
    if err != nil {
        fmt.Println(&quot;Error setting value:&quot;, err)
        return
    }

    value, err := storage.Get(&quot;key1&quot;)
    if err != nil {
        fmt.Println(&quot;Error getting value:&quot;, err)
        return
    }

    fmt.Println(&quot;Value for key1:&quot;, value)
}
</code></pre>
<p>在上面的示例中，<code>NewDiskStorage(&quot;data.db&quot;)</code> 调用实例化了一个名为 &quot;data.db&quot; 的磁盘存储。然后，通过实例进行了 <code>Set</code> 和 <code>Get</code> 操作。最后，在程序结束时，通过 <code>defer storage.Close()</code> 来确保存储实例关闭，以便数据被正确地刷新到磁盘。</p>
<p>通过实例化 <code>DiskStorage</code>，您可以使用其提供的方法来操作键值对数据，并在磁盘和内存中进行数据存储和检索。</p>
<h2 id="newdiskstorage"><a class="header" href="#newdiskstorage">NewDiskStorage</a></h2>
<p><code>NewDiskStorage</code> 是一个构造函数，用于创建 <code>DiskStorage</code> 实例，并在创建过程中执行初始化操作。以下是 <code>NewDiskStorage</code> 函数的功能和流程解释：</p>
<pre><code class="language-go">func NewDiskStorage(fileName string) (*DiskStorage, error) {
    ds := &amp;DiskStorage{
        FileName: fileName,
        KeyDir:   make(map[string]KeyEntry),
    }

    // 检查文件是否存在
    _, err := os.Stat(fileName)
    if err == nil {
        ds.initKeyDir() // 如果文件存在，初始化 KeyDir 映射
    }

    // 打开或创建文件
    ds.File, err = os.OpenFile(fileName, os.O_APPEND|os.O_RDWR|os.O_CREATE, 0644)
    return ds, err
}
</code></pre>
<p>解释 <code>NewDiskStorage</code> 的步骤：</p>
<ol>
<li>
<p><strong>创建 DiskStorage 实例</strong>：首先，创建一个 <code>DiskStorage</code> 实例 <code>ds</code>，并设置其 <code>FileName</code> 字段为传入的文件名。同时，创建一个空的 <code>KeyDir</code> 映射，用于存储键索引。</p>
</li>
<li>
<p><strong>检查文件是否存在</strong>：使用 <code>os.Stat(fileName)</code> 来检查指定的文件是否存在。如果文件存在（即没有返回错误），则说明存储系统中可能已经有数据。在这种情况下，调用 <code>initKeyDir</code> 方法以初始化 <code>KeyDir</code> 映射。</p>
</li>
<li>
<p><strong>打开或创建文件</strong>：使用 <code>os.OpenFile</code> 打开指定的文件。如果文件不存在，将会被创建。打开文件时使用了 <code>os.O_APPEND</code>、<code>os.O_RDWR</code> 和 <code>os.O_CREATE</code> 标志，以允许文件追加、读写和创建。</p>
</li>
<li>
<p><strong>返回实例和错误</strong>：返回创建的 <code>DiskStorage</code> 实例和可能的错误。如果发生错误，可能是因为文件打开或初始化过程中出现了问题。</p>
</li>
</ol>
<p>通过调用 <code>NewDiskStorage</code>，您可以创建一个经过初始化的 <code>DiskStorage</code> 实例，准备好用于存储和检索键值对数据。</p>
<p>首先实现 DiskStorage ，用来管理一些元信息，例如数据在内存中的索引，用 map 来存。</p>
<h2 id="diskstorage"><a class="header" href="#diskstorage">DiskStorage</a></h2>
<p><code>DiskStorage</code> 是在提供的代码中定义的一个结构体，表示了一个基于磁盘的键值存储系统。它包含了管理和操作键值对存储的方法和数据。</p>
<pre><code class="language-go">type DiskStorage struct {
	FileName      string
	WritePosition uint32
	KeyDir        map[string]KeyEntry
	File          *os.File
}
</code></pre>
<p>以下是 <code>DiskStorage</code> 结构体的重要成员和功能的解释：</p>
<ol>
<li>
<p><strong>FileName</strong>: 一个字符串字段，表示用于存储数据的磁盘文件的名称。</p>
</li>
<li>
<p><strong>WritePosition</strong>: 一个无符号整数字段，表示当前写入新数据的文件位置。在执行 <code>Set</code> 操作时，新的键值对数据将被追加到该位置之后。</p>
</li>
<li>
<p><strong>KeyDir</strong>: 一个映射（map）字段，用于在内存中维护键值对的索引。它将键映射到 <code>KeyEntry</code> 结构体，以记录键值对的位置、时间戳和总大小等信息。</p>
</li>
<li>
<p><strong>File</strong>: 一个指向磁盘文件的指针（*os.File）。该文件用于实际存储键值对的数据。</p>
</li>
<li>
<p><strong>NewDiskStorage(fileName string) (*DiskStorage, error)</strong>: 一个构造函数，用于创建新的 <code>DiskStorage</code> 实例。它接受一个文件名作为参数，如果该文件存在，则会初始化 <code>KeyDir</code> 映射以加载文件中的现有数据。</p>
</li>
<li>
<p><strong>Set(key, value string) error</strong>: 用于将键值对添加到存储中的方法。它接受键和值作为参数，生成时间戳并将数据编码后写入磁盘文件。同时，它还更新了 <code>KeyDir</code> 映射和 <code>WritePosition</code>，以反映新键值对的位置和信息。</p>
</li>
<li>
<p><strong>Get(key string) (string, error)</strong>: 用于根据键检索值的方法。它会根据提供的键查找 <code>KeyDir</code> 映射，找到对应的 <code>KeyEntry</code>，然后根据位置信息从磁盘文件中读取数据并进行解码。</p>
</li>
<li>
<p><strong>write(data []byte) error</strong>: 一个辅助方法，用于将数据写入磁盘文件。它会将提供的字节数据写入文件，并执行文件同步以确保数据被写入磁盘。</p>
</li>
<li>
<p><strong>initKeyDir()</strong>: 初始化 <code>KeyDir</code> 映射的方法。它会读取现有的磁盘文件，解码其中存储的键值对，并在内存中构建 <code>KeyDir</code> 映射以加速后续操作。</p>
</li>
<li>
<p><strong>Close()</strong>: 用于关闭存储系统的方法。它会执行文件同步操作，将数据刷新到磁盘，并关闭文件。</p>
</li>
</ol>
<p>总之，<code>DiskStorage</code> 结构体是一个将键值对数据存储到磁盘并允许通过键进行检索的简单实现。它通过在内存中维护索引映射和在磁盘文件中存储实际数据来实现这一功能。</p>
<h2 id="keyentry"><a class="header" href="#keyentry">KeyEntry</a></h2>
<p>然后是 KeyEntry ，用来组织数据在内存中的存储方式。<code>KeyEntry</code> 在这个代码中扮演着关键的角色，用于管理和跟踪每个键值对在磁盘文件中的位置和元数据。具体来说，<code>KeyEntry</code> 有以下用途：</p>
<ol>
<li>
<p><strong>位置追踪</strong>：<code>KeyEntry</code> 中的 <code>Position</code> 字段表示键值对在磁盘文件中的位置。这允许系统知道在文件中的哪个位置存储了特定的键值对。在进行 <code>Get</code> 操作时，可以根据 <code>KeyEntry</code> 中的位置信息迅速定位和读取相应的数据。</p>
</li>
<li>
<p><strong>时间戳记录</strong>：<code>KeyEntry</code> 的 <code>Timestamp</code> 字段记录了键值对添加的时间戳。这在需要了解特定键值对何时被添加的情况下非常有用，例如用于数据审计或其他需要时间相关信息的场景。</p>
</li>
<li>
<p><strong>总大小信息</strong>：<code>KeyEntry</code> 中的 <code>TotalSize</code> 字段记录了键值对数据的总大小。这对于确定下一个键值对的写入位置很重要，因为在文件中的位置是逐个递增的。通过总大小，可以在文件中为下一个键值对分配合适的位置。</p>
</li>
<li>
<p><strong>内存中的索引</strong>：<code>KeyEntry</code> 用作在内存中的索引，以便在执行 <code>Get</code> 操作时，可以通过键快速查找到对应的键值对位置和元数据。这避免了需要扫描整个文件以查找特定键的开销。</p>
</li>
</ol>
<p>总之，<code>KeyEntry</code> 的存在使得系统能够高效地定位和管理存储在磁盘文件中的键值对。它提供了键值对的位置、时间戳和大小等关键信息，使存储和检索操作更加快速和可靠。</p>
<h2 id="initkeydir"><a class="header" href="#initkeydir">initKeyDir</a></h2>
<p><code>initKeyDir</code> 函数在创建 <code>DiskStorage</code> 实例时，当检测到指定的磁盘文件已经存在时被调用。这是为了在初始化存储系统时，从已有的数据文件中读取并加载现有的键值对信息。</p>
<p>具体来说，以下情况会触发调用 <code>initKeyDir</code> 函数：</p>
<ol>
<li>
<p><strong>创建新的 <code>DiskStorage</code> 实例</strong>：当调用 <code>NewDiskStorage</code> 构造函数创建新的 <code>DiskStorage</code> 实例时，会首先检查指定的文件是否已经存在。</p>
</li>
<li>
<p><strong>已有的数据文件</strong>：如果文件已经存在，说明存储系统之前可能已经存储了一些键值对数据。为了确保新创建的 <code>DiskStorage</code> 实例能够恢复已有的数据，它会调用 <code>initKeyDir</code> 函数来加载这些现有的键值对信息。</p>
</li>
<li>
<p><strong>内存中的索引构建</strong>：<code>initKeyDir</code> 函数的主要目的是在内存中构建键索引映射 <code>KeyDir</code>。这个映射可以用来在内存中快速访问键值对的位置和元数据，以加速后续的读取、写入和查询操作。</p>
</li>
</ol>
<p>总之，<code>initKeyDir</code> 函数在创建 <code>DiskStorage</code> 实例时被调用，用于加载已有的键值对数据，并在内存中构建键索引映射，以便在之后的操作中能够高效地访问存储的数据。</p>
<p><code>initKeyDir</code> 是一个在 <code>DiskStorage</code> 结构体中定义的方法，用于初始化内存中的键索引映射 <code>KeyDir</code>，以便在创建 <code>DiskStorage</code> 实例时能够快速访问存储在磁盘文件中的键值对的位置和元数据。以下是 <code>initKeyDir</code> 方法的功能和流程解释：</p>
<pre><code class="language-go">func (ds *DiskStorage) initKeyDir() {
    file, err := os.Open(ds.FileName)
    if err != nil {
        fmt.Println(&quot;Error initializing KeyDir:&quot;, err)
        return
    }
    defer file.Close()

    for {
        headerBytes := make([]byte, HeaderSize)
        _, err := file.Read(headerBytes)
        if err != nil {
            break
        }

        timestamp, keySize, valueSize, _ := DecodeHeader(headerBytes)
        keyBytes := make([]byte, keySize)
        file.Read(keyBytes)

        valueBytes := make([]byte, valueSize)
        file.Read(valueBytes)

        key := string(keyBytes)
        value := string(valueBytes)

        totalSize := HeaderSize + uint32(keySize+valueSize)
        ds.KeyDir[key] = NewKeyEntry(timestamp, ds.WritePosition, totalSize)
        ds.WritePosition += totalSize

        fmt.Printf(&quot;loaded k=%s, v=%s\n&quot;, key, value)
    }
}
</code></pre>
<p>解释 <code>initKeyDir</code> 的步骤：</p>
<ol>
<li>
<p>打开文件：使用 <code>os.Open</code> 方法打开指定的磁盘文件以读取数据。如果打开文件时发生错误，方法会输出错误信息并返回。</p>
</li>
<li>
<p>循环读取：通过一个循环，从文件中连续读取每个键值对的数据。循环会一直运行，直到无法读取到更多数据（<code>file.Read</code> 返回错误）。</p>
</li>
<li>
<p>读取头部信息：首先，从文件中读取一个固定大小的字节序列，该序列包含了键值对头部的信息。这些信息包括时间戳、键的大小和值的大小。</p>
</li>
<li>
<p>解码头部：使用 <code>DecodeHeader</code> 函数解码头部信息，以获取时间戳、键的大小和值的大小。</p>
</li>
<li>
<p>读取键和值数据：根据键和值的大小信息，从文件中分别读取键和值的字节数据。</p>
</li>
<li>
<p>构建 <code>KeyEntry</code>：使用解码的信息和从文件中读取的数据，创建一个新的 <code>KeyEntry</code> 实例，其中包含时间戳、位置和总大小信息。</p>
</li>
<li>
<p>更新位置和索引：将新的 <code>KeyEntry</code> 添加到 <code>KeyDir</code> 映射中，然后更新 <code>WritePosition</code>，以便为下一个键值对的写入位置做好准备。</p>
</li>
<li>
<p>输出加载信息：将加载的键和值信息打印出来，以便查看初始化过程。</p>
</li>
</ol>
<p>通过这个流程，<code>initKeyDir</code> 方法会逐个读取磁盘文件中的键值对，并在内存中构建 <code>KeyDir</code> 映射，以便之后的操作可以快速定位和访问键值对的位置和元数据。这在创建 <code>DiskStorage</code> 实例时非常有用。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-3-实现-setget"><a class="header" href="#part-3-实现-setget">Part 3 实现 Set、Get</a></h1>
<p>这一章节主要研究数据在内存中是如何组织的。通过 Set 和 Get 方法的具体实现将前两章串起来。</p>
<h2 id="set"><a class="header" href="#set">Set</a></h2>
<p>当调用 <code>Set(key, value string) error</code> 方法时，将执行以下步骤来向存储中添加新的键值对：</p>
<ol>
<li>
<p>获取当前时间戳：通过 <code>time.Now().Unix()</code> 获取当前时间戳，以便记录键值对添加的时间。</p>
</li>
<li>
<p>编码键值对：将键、值和时间戳传递给 <code>EncodeKV</code> 函数，该函数会将它们编码成字节序列。这个字节序列包括一个头部，其中包含时间戳、键的长度和值的长度。</p>
</li>
<li>
<p>写入数据：调用 <code>ds.write(data)</code>，这会将编码后的键值对数据写入磁盘文件中。<code>ds.write(data)</code> 函数将数据写入文件，并在写入后执行 <code>ds.File.Sync()</code> 同步操作，确保数据被实际写入磁盘。</p>
</li>
<li>
<p>更新 KeyDir 映射：创建一个新的 <code>KeyEntry</code> 实例，其中包含时间戳、写入位置和键值对数据的总大小。然后，将这个 <code>KeyEntry</code> 添加到 <code>KeyDir</code> 映射中，以便稍后能够通过键查找数据的位置和元数据。</p>
</li>
<li>
<p>更新写入位置：增加 <code>ds.WritePosition</code> 的值，以便为下一个键值对的写入位置做好准备。</p>
</li>
</ol>
<p>整个 <code>Set</code> 的流程如下：</p>
<pre><code class="language-go">func (ds *DiskStorage) Set(key, value string) error {
    timestamp := uint32(time.Now().Unix())
    totalSize, data, _ := EncodeKV(timestamp, key, value) // 编码键值对为字节序列
    ds.write(data) // 写入数据到磁盘文件
    ds.KeyDir[key] = NewKeyEntry(timestamp, ds.WritePosition, totalSize) // 更新 KeyDir 映射
    ds.WritePosition += totalSize // 更新写入位置
    return nil
}
</code></pre>
<p>通过这个流程，新的键值对被编码并写入磁盘文件，同时也在内存中维护了键值对的索引，以便后续的检索和操作。</p>
<h2 id="get"><a class="header" href="#get">Get</a></h2>
<p>当调用 <code>Get(key string) (string, error)</code> 方法时，将执行以下步骤来获取特定键的值：</p>
<ol>
<li>
<p>从 <code>KeyDir</code> 映射中查找键：首先，会检查 <code>KeyDir</code> 映射，看是否存在给定的键。如果存在，可以通过 <code>KeyEntry</code> 得知该键值对的位置和大小信息，从而可以在磁盘文件中找到对应的数据。</p>
</li>
<li>
<p>定位到文件位置：使用 <code>KeyEntry</code> 中的 <code>Position</code> 信息，将文件指针定位到存储特定键值对的位置。这通过调用 <code>ds.File.Seek()</code> 来实现。</p>
</li>
<li>
<p>读取数据：从定位的文件位置开始，读取键值对数据的字节序列。首先，会创建一个足够大的字节切片来容纳数据，然后使用 <code>ds.File.Read()</code> 从文件中读取数据到切片中。</p>
</li>
<li>
<p>解码数据：解码从文件中读取的数据，以从字节序列中提取键和值。这涉及到调用 <code>DecodeKV</code> 函数，它会将字节序列解码为键和值。</p>
</li>
<li>
<p>返回值：从解码后的数据中获取值部分，并作为结果返回。</p>
</li>
</ol>
<p>整个 <code>Get</code> 的流程如下：</p>
<pre><code class="language-go">func (ds *DiskStorage) Get(key string) (string, error) {
    kv, ok := ds.KeyDir[key]
    if !ok {
        return &quot;&quot;, fmt.Errorf(&quot;key not found&quot;)
    }

    ds.File.Seek(int64(kv.Position), 0) // 将文件指针定位到键值对位置
    data := make([]byte, kv.TotalSize) // 创建足够大的字节切片
    _, err := ds.File.Read(data) // 从文件读取数据到切片
    if err != nil {
        return &quot;&quot;, err
    }

    // 解码数据，获取值部分
    _, _, value, err := DecodeKV(data)
    if err != nil {
        return &quot;&quot;, err
    }

    return value, nil // 返回值
}
</code></pre>
<p>通过这个流程，<code>Get</code> 方法可以根据键查找存储在磁盘文件中的相应值，并将其解码后返回。这种方式避免了需要扫描整个文件以查找特定键的情况，从而实现了高效的键值对检索。</p>
<h2 id="总结"><a class="header" href="#总结">总结</a></h2>
<p>综上一个简单的 Bitcask 存储引擎就写好了，目前还非常简陋，只提供了 Set 和 Get 方法，还有很多可以做的事情。</p>
<p>如果仅仅是粘贴没有任何成就感，可以尝试修改之前的代码，例如增加一个 CRC 字段来进一步加深理解。通过 CRC 可以确保数据存取过程中是否一致。编码数据的时候直接将 CRC 附加到字段中即可，解码的时候要根据读取的数据重新生成 CRC 并和之前存的 CRC 比对数据是否一致。</p>
<p>这个很简单，可以尝试自己能否实现。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-4-删除逻辑和-compact"><a class="header" href="#part-4-删除逻辑和-compact">Part 4 删除逻辑和 Compact</a></h1>
<h2 id="实现删除逻辑"><a class="header" href="#实现删除逻辑">实现删除逻辑</a></h2>
<p>删除逻辑也分为两部分，一部分是内存中，一部分是磁盘上。如果只是删除内存中，这个叫做逻辑删除，将磁盘上的也删掉才真正的物理删除。</p>
<p>删除采用的时逻辑删除，可以简单粗暴的在内存中把 key 对应的 value 抹掉，这样无法从磁盘中查数据了。但是磁盘中依旧有需要被删除的数据该怎么办？接下来是合并操作，通常称为 compaction ，在 LSM Tree 中也有这个东西。首先从头开始读取磁盘文件，根据拿到的数据去哈希表中查找，判断是否被逻辑删除，若被删了则跳过，若没有则创建一张新的哈希表建立新的索引，并把数据写入新的文件中。这样把所有的旧数据都遍历一遍，该删的数据就都删干净了。</p>
<p>这是一个逻辑删除的实现，并没有实现物理删除 <a href="https://github.com/weijiew/abyssdb/commit/243d884c45d5eae3eb1d8fd9bbf573b6f4e85703">[feat] add delete and test.</a> </p>
<p>实现物理删除要进一步研究 Compact 机制，这个也很简单。</p>
<h2 id="compact-机制"><a class="header" href="#compact-机制">Compact 机制</a></h2>
<p>因为删除导致文件中存在旧数据，所以该如何处理呢？什么时候处理呢？重新构建索引时应该要略过吧？以上种种问题都是需要考虑的，而下面是一些常见的 Compact 策略。</p>
<p><code>Compact</code> 机制是指在存储过程中对数据进行整理和清理的操作。Bitcask 的 <code>Compact</code> 目标是减少存储文件的碎片化，提高读取性能，并释放未使用的磁盘空间。以下是 Bitcask 的 <code>Compact</code> 机制的一般概述：</p>
<ol>
<li>
<p><strong>合并段文件（Merge Segment Files）</strong>：Bitcask 使用段（segment）文件来存储键值对数据。每个段文件包含一组键值对，按照键的顺序排列。在 <code>Compact</code> 期间，Bitcask 可能会合并多个段文件，将它们的数据整合到一个或多个新的段文件中。这有助于减少碎片化，提高读取效率，并优化存储。</p>
</li>
<li>
<p><strong>过期数据删除（Expiration-based Deletion）</strong>：Bitcask 存储引擎通常会设置键值对的过期时间。在 <code>Compact</code> 过程中，过期的键值对会被检测并删除，以释放存储空间。</p>
</li>
<li>
<p><strong>数据合并和排序</strong>：合并过程中，Bitcask 会将多个段文件中的键值对合并到新的段文件中。这有助于减少查找和读取操作时的磁盘访问，从而提高性能。同时，合并也可以使数据按照键的顺序排列，加速范围查询操作。</p>
</li>
<li>
<p><strong>标记删除（Tombstone）</strong>：Bitcask 在合并过程中，可能会遇到已被删除的键。为了保持一致性，Bitcask 使用 &quot;tombstone&quot; 记录来标记已被删除的键。这些 &quot;tombstone&quot; 记录指示某个键已被删除，从而确保在合并过程中不会错误地复制已删除的数据。</p>
</li>
<li>
<p><strong>资源回收</strong>：合并过程中，Bitcask 可能会删除不再需要的段文件，从而释放磁盘空间。这可以帮助减少存储系统占用的磁盘空间。</p>
</li>
</ol>
<p>需要注意的是，Bitcask 的 <code>Compact</code> 机制是为了优化性能和存储空间使用，但也会增加一定的系统开销。合并操作可能需要较长的时间，可能会占用一定的 CPU 和磁盘资源。因此，在执行 <code>Compact</code> 操作时，需要权衡操作的频率和性能开销。</p>
<p>总之，Bitcask 的 <code>Compact</code> 机制旨在通过合并、清理和整理操作，优化存储引擎的性能和存储空间利用。这有助于维持存储系统的高效性能，并减少存储资源的浪费。</p>
<h2 id="其他"><a class="header" href="#其他">其他</a></h2>
<p>下面是一些简单且容易实现任务，并且可以加深代码理解。后续有时间的话会挨个实现并讲解。</p>
<ol>
<li>如何支持 TTL ？</li>
<li>文件如何拆分为多个？</li>
<li>hint file 加快启动速度如何实现？</li>
</ol>
<h3 id="级别-1"><a class="header" href="#级别-1">级别 1：</a></h3>
<ul>
<li>崩溃安全性：Bitcask 论文中在每行存储了 CRC，并在获取数据时验证数据的完整性。</li>
<li>键删除：CaskDB 没有删除 API。请阅读论文并实现这一功能。</li>
<li>使用类似红黑树的数据结构代替哈希表来支持范围扫描。</li>
<li>只接受字符串作为键和值。使其泛化，可以接受像整型或字节等其他数据结构。</li>
</ul>
<h3 id="级别-2"><a class="header" href="#级别-2">级别 2：</a></h3>
<ul>
<li>提示文件来改进启动时间。论文中有更多细节。</li>
<li>实现一个内部缓存来存储一些键值对。你可以探索和实验不同的缓存淘汰策略，如 LRU（最近最少使用）、LFU（最不常用）、FIFO（先进先出）等。</li>
<li>当文件达到特定容量时，将数据分割到多个文件中。</li>
</ul>
<h3 id="级别-3"><a class="header" href="#级别-3">级别 3：</a></h3>
<ul>
<li>支持多进程。</li>
<li>垃圾回收：更新和删除的键仍然留在文件中占用空间。编写一个垃圾回收器来移除这类陈旧数据。</li>
<li>添加 SQL 查询引擎层。</li>
<li>在值中存储 JSON，并探索使 CaskDB 成为类似于 MongoDB 的文档数据库。</li>
<li>通过探索 Raft、Paxos 或一致性哈希等算法，使 CaskDB 分布式化。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="6s081-operation-system-2020"><a class="header" href="#6s081-operation-system-2020">6.S081 Operation System 2020</a></h1>
<p>schedule 页面：https://pdos.csail.mit.edu/6.828/2020/schedule.html</p>
<ul>
<li><a href="https://www.bilibili.com/video/BV19k4y1C7kA">视频中文翻译</a></li>
<li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/">视频中文文字版</a></li>
<li><a href="https://github.com/duguosheng/6.S081-All-in-one">lab 文档的中文翻译</a></li>
</ul>
<h1 id="环境配置-tools"><a class="header" href="#环境配置-tools">环境配置 Tools</a></h1>
<p>我采用的是虚拟机，宿主机是 win10 ，虚拟机采用的是 VMware 。</p>
<p>首先安装 Ubuntu20.04 ，注意建议不要安装别的版本，这个版本省事，因为有一些特定的包在这个版本上，而其他版本上需要重新编译。</p>
<p>接下来就说配置环境，参照信息均来源于此页面： https://pdos.csail.mit.edu/6.828/2020/tools.html 。</p>
<h2 id="1-安装包"><a class="header" href="#1-安装包">1. 安装包</a></h2>
<p>安装 <code>sudo apt-get install git build-essential gdb-multiarch qemu-system-misc gcc-riscv64-linux-gnu binutils-riscv64-linux-gnu</code> </p>
<p>该版本的包存在一个问题 <code>sudo apt-get remove qemu-system-misc</code> 需要卸载安装指定版本。</p>
<p>安装指定版本 <code>sudo apt-get install qemu-system-misc=1:4.2-3ubuntu6</code> 。</p>
<h2 id="2-测试环境是否配置成功"><a class="header" href="#2-测试环境是否配置成功">2. 测试环境是否配置成功</a></h2>
<p>据此命令 <code>riscv64-unknown-elf-gcc --version</code> 出现如下内容：</p>
<pre><code>@ubuntu:~$ riscv64-unknown-elf-gcc --version

Command 'riscv64-unknown-elf-gcc' not found, but can be installed with:

sudo apt install gcc-riscv64-unknown-elf
</code></pre>
<p>意思是缺少该包，按照提示安装即可：<code>sudo apt install gcc-riscv64-unknown-elf</code></p>
<p>安装后输入下面的两条命令判断 <code>riscv64-unknown-elf-gcc --version</code></p>
<pre><code>@ubuntu:~$ riscv64-unknown-elf-gcc --version
riscv64-unknown-elf-gcc () 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
</code></pre>
<p><code>qemu-system-riscv64 --version</code></p>
<pre><code>@ubuntu:~$ qemu-system-riscv64 --version
QEMU emulator version 4.2.0 (Debian 1:4.2-3ubuntu6)
Copyright (c) 2003-2019 Fabrice Bellard and the QEMU Project developers
</code></pre>
<p>到此处本实验其实已经结束了。</p>
<h2 id="最后"><a class="header" href="#最后">最后</a></h2>
<p>下面的内容其实是下一个实验的，当然来本实验的最后其实也提到了。目的是将 xv6 的代码拉取下来看能否编译成功，据此判断环境是否搭建成功。</p>
<p>我将代码放到了共享文件夹中，关于共享文件夹的设置方法可以参照<a href="https://zhuanlan.zhihu.com/p/42203768">此处</a>。</p>
<p>下载 xv6 代码并编译判断</p>
<pre><code>git clone git://g.csail.mit.edu/xv6-labs-2020
cd xv6-labs-2020
git checkout util
</code></pre>
<p>然后输入 <code>sudo make qemu</code> 编译代码。</p>
<p>当出现 xv6 kernel is booting 表示着源码编译搭建成功。</p>
<p>进入 qemu 后可以输入一些命令来查看，例如 <code>ls</code> 等。</p>
<p>退出 qemu ： 先输入 ctrl + a 抬起后再输入 x 。</p>
<h2 id="注意"><a class="header" href="#注意">注意</a></h2>
<ul>
<li>全局搜索很方便，不用挨个翻文件查找。</li>
</ul>
<p>VSCode 全局搜索快捷键 ctrl + p 加上 <code># 加内容</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318135133.png" alt="20220318135133" /></p>
<ul>
<li>如果出现 make grade 时出现 <code>/usr/bin/env: ‘python3\r’: No such file or directory</code> </li>
</ul>
<p>用 vim 打开测试文件输入如下内容：</p>
<p>:set  ff=unix 
:wq</p>
<ul>
<li>如果想从头再来，可以回退到上一个版本重新开始(<code>git reset --hard HEAD^</code>) 。</li>
</ul>
<p>或者删除分支，</p>
<h1 id="参考"><a class="header" href="#参考">参考</a></h1>
<p><a href="https://blog.csdn.net/z2876563/article/details/117023126">0. WSL 安装</a>
<a href="https://zhuanlan.zhihu.com/p/343655412">1. MIT 6.S081: Lab 0 搭建环境</a>
<a href="https://blog.csdn.net/zsj1126/article/details/104054913">2. qemu 的退出方法</a></p>
<h2 id="参考-1"><a class="header" href="#参考-1">参考</a></h2>
<ol>
<li><a href="https://blog.miigon.net/posts/s081-ending/">MIT6.S081 Operating System Engineering 课程总结 &amp; Lab 指北</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-util"><a class="header" href="#lab-util">Lab util</a></h1>
<p>熟悉 xv6 及其系统调用。</p>
<p>https://pdos.csail.mit.edu/6.828/2020/labs/util.html</p>
<p>需要阅读 xv6 book 第一章，下面是一些总结及部分翻译。</p>
<h2 id="1-前置阅读内容总结"><a class="header" href="#1-前置阅读内容总结">1. 前置阅读内容总结</a></h2>
<ul>
<li>第一章：操作系统接口
<ul>
<li>OS 需要实现多个程序运行在同一台计算机上。OS 对硬件进程抽象，为上层应用程序提供服务。例如一个文字处理程序不需要关心正在使用哪种类型的磁盘硬件。</li>
<li>OS 为程序共享数据，相互交互提供了基础。OS 以接口的形式向用户程序提供服务，一方面希望接口简单，另一方面希望接口提供强大功能。可以通过减少依赖的方式实现，将功能组合进而提高通用性。</li>
<li>本书使用 xv6 来说明 OS 的具体概念。xv6 模仿了Unix的内部设计， Unix 接口设计的很好，精准且与其机制结合得很好，此外提供了很好的通用性。现代操作系统--BSD、Linux、macOS、Solaris，Windows 都和Unix的接口类似。</li>
<li>xv6 采用了传统的内核形式，为运行中的程序提供服务的特殊程序。每一个运行中的程序被称之为进程，拥有指令，数据和栈。指令实现了程序的计算。数据是计算作用的变量。堆栈组织了程序的过程调用。进程可以有多个，但通常只有一个内核。</li>
<li>当一个进程需要调用内核服务时，首先调用一个系统调用，即操作系统接口中的一个接口。此后系统调用进入内核，内核执行完成后返回。因此，一个进程在用户空间和内核空间中交替执行。</li>
<li>内核使用 CPU 提供的硬件保护机制来确保每个进程在用户空间执行只能访问自己的内存。内核实现了上述保护硬件权限保护功能。相较于用户程序而言，内核程序拥有更多的权限。用户程序调用系统调用时，内核会提高权限级别并执行内核中预设的功能。</li>
<li>用户态下所看到的接口是内核提供的系统调用。xv6 内核提供了Unix内核传统上提供的服务和系统调用的一个子集。下面列出了xv6的所有系统调用。
<ul>
<li><code>int fork()</code> 创建一个进程，返回子进程的  PID. </li>
<li><code>int exit(int status)</code>  终止当前进程，将状态报告给 wait ，没有返回值。</li>
<li><code>int wait(int *status)</code> 等待子进程退出，<code>*status</code> 表示退出状态，返回子进程的 PID 。 </li>
<li><code>int kill(int pid)</code> 终止进程PID。返回0，或-1为错误。</li>
<li><code>int getpid()</code> 返回当前进程的PID。</li>
<li><code>int sleep(int n)</code> 暂停n个时钟。</li>
<li><code>int exec(char *file, char *argv[])</code> 加载一个文件并带着参数执行，仅在出错时返回。 </li>
<li><code>char *sbrk(int n)</code> 为进程内存扩大 n 个字节，返回新内存的起点。</li>
<li><code>int open(char *file, int flags)</code> 打开一个文件；flags 表示读/写；返回一个fd（文件描述符）。</li>
<li><code>int write(int fd, char *buf, int n)</code>  从buf写n个字节到文件描述符fd；返回n。</li>
<li><code>int read(int fd, char *buf, int n)</code>  向 buf 中读取n个字节；返回读取的数量；如果文件结束则返回 0 。</li>
<li><code>int close(int fd)</code> 释放打开的文件fd。</li>
<li><code>int dup(int fd)</code> 返回一个新的文件描述符，指的是与 fd 相同的文件。</li>
<li><code>int pipe(int p[])</code> 创建一个管道，把读/写文件描述符放在p[0]和p[1]中。</li>
<li><code>int chdir(char *dir)</code> 改变当前目录。</li>
<li><code>int mkdir(char *dir)</code> 创建一个新的目录。</li>
<li><code>int mknod(char *file, int, int)</code>  创建一个设备文件。</li>
<li><code>int fstat(int fd, struct stat *st)</code> 将打开的文件的信息放入<code>*st</code>。 </li>
<li><code>int stat(char *file, struct stat *st)</code> 将一个命名的文件的信息放入<code>*st</code>。 </li>
<li><code>int link(char *file1, char *file2)</code> 为文件file1创建另一个名字（file2）。 </li>
<li><code>int unlink(char *file)</code> 删除一个文件。</li>
<li>通常若不做其他说明，返回 0 表示没有错误，返回 1 表示存在错误。</li>
</ul>
</li>
<li>后续会结合 xv6 代码会详解服务，进程、内存、文件描述符、管道和文件系统，shell 等概念。</li>
<li>shell 是用户程序，并非内核的一部分。shell 在用户态下读取命令并执行。shell 的种类有很多，可以随时被替换。xv6 shell 是 Unix Bourne shell 的一个简单实现，具体代码可以在 <code>user/sh.c:1</code> 找到。</li>
</ul>
</li>
<li>1.1 进程和内存
<ul>
<li>一个xv6进程由用户空间内存（指令、数据和堆栈）和内核专用的每个进程状态组成。 xv6 采用时间共享的方式来调度进程，从执行的进程组中透明地切换可用的CPU。 当一个进程不执行时，xv6 会保存该进程的 CPU 寄存器，当它下次运行该进程时再恢复这些寄存器。内核通过进程标识符 PID 同每个进程相关联。</li>
<li>进程使用 fork 可以创建新的进程，fork 使得新进程获得了调用进程内存的精确拷贝，包括指令和数据。fork 在原流程和新流程中都会返回。在原进程中，fork 返回新进程的 PID 。在新进程中，fork 返回 0 。原进程和新进程通常被称为父进程和子进程。</li>
<li>exit 系统调用使当前进程停止执行，并释放所打开的文件资源，例如内存。exit 的参数是一个整数，通常 0 表示成功，1 表示失败。系统调用返回当前进程的已退出（或已终止）子进程的 PID，并将子进程的退出状态复制到传递给 wait 的地址；如果调用者的子进程没有一个退出，则等待一个退出。如果调用者没有子进程，<code>wait</code>立即返回-1。如果父进程不关心子进程的退出状态，则可以传递一个 0 地址<code>wait</code>。</li>
<li>父子进程的打印顺序是随机的，取决于父子进程哪个更快调用。子进程推出后父进程返回，随后父进程打印。</li>
<li>虽然子进程与父进程具有相同的内存内容，但父进程和子进程使用单独的内存和单独的寄存器执行：更改一个变量不会影响另一个变量。例如，当<code>wait</code>的返回值存储在父进程的<code>pid</code>中时，它不会更改子进程中的变量<code>pid</code>。子进程中<code>pid</code>的值仍然为零。</li>
<li>系统调用将调用进程的内存替换为从文件系统中存储的文件中加载的新内存映像。文件必须具有特定的格式，该格式指定文件的哪一部分保存指令，哪一部分是数据，在哪个指令开始等。Xv6使用ELF格式。通常文件是编译程序源代码的结果。当成功时，它不返回调用程序；相反，从文件加载的指令在ELF标头中声明的切入点开始执行。<code>exec</code>有两个参数：分别是可执行文件的文件名和字符串参数数组。例如：</li>
</ul>
</li>
</ul>
<pre><code>char *argv[3];

argv[0] = &quot;echo&quot;;
argv[1] = &quot;hello&quot;;
argv[2] = 0;
exec(&quot;/bin/echo&quot;, argv);
printf(&quot;exec error\n&quot;);
</code></pre>
<ul>
<li>这个片段将调用程序替换为<code>/bin/echo</code>运行参数列表的程序实例<code>echo</code> <code>hello</code>。大多数程序忽略参数数组的第一个元素，一般是程序的名称。</li>
<li>xv6 shell 使用上面的调用来代表用户运行程序。shell 的主要结构很简单，参见<code>main</code>。主循环读取用户的一行输入，然后调用<code>fork</code>，创建 shell 进程的副本。父进程调用<code>wait</code>，而子进程运行命令。例如，如果在 shell 中输入<code>echo hello</code>，则调用<code>runcmd</code>时将使用“<code>echo hello</code>”作为参数。<code>runcmd</code>运行实际的命令。对于&quot;<code>echo hello</code>&quot;，它将调用<code>exec</code>。如果<code>exec</code>成功，则子进程将执行来自<code>echo</code>而不是<code>runcmd</code>的指令。在某些时候，<code>echo</code>将调用<code>out</code>，这将导致父进程从<code>main</code>中的<code>wait</code>返回。</li>
<li>为什么没有在一次调用中合并；稍后将看到shell在其I/O重定向的实现中利用了分离。为了避免创建重复进程然后立即替换它（用<code>exec</code>）的浪费，操作内核通过使用虚拟内存技术（如写时复制）来优化此用例的<code>fork</code>的实现。</li>
<li>Xv6隐式分配大多数用户空间内存：分配父内存的子副本所需的内存，并分配足够的内存来保存可执行文件。在运行时需要更多内存的进程可以调用<code>sbrk（n）</code>将其数据内存增加<code>n</code>个字节；返回新内存的位置。</li>
<li>1.2 I/O和文件描述符
<ul>
<li>文件描述符是一个整数，用来表示文件，目录或设备。xv6  使用文件描述符作为每个进程表的索引。每个进程都拥有。</li>
<li>在内部，xv6内核使用文件描述符作为每个进程表的索引，每个进程都有一个自己的文件描述符空间，并从零开始编号。通常情况下一个进程从文件描述符0（标准输入）读取信息，将输出写入文件描述符1（标准输出），并将错误信息写入文件描述符2（标准错误）。shell 利用约定来实现I/O重定向和管道。shell确保它始终打开三个文件描述符，默认情况下是控制台的文件描述符。</li>
<li>调用<code>read(fd, buf, n)</code>从文件描述符<code>fd</code>中最多读取<code>n</code>个字节，将其复制到<code>buf</code>中，并返回读取的字节数。指向一个文件的每个文件描述符都有一个与之相关的偏移量。读取 &quot;从当前文件的偏移量读取数据，然后将该偏移量向前推进多少个字节：随后的 &quot;读取 &quot;将返回第一个 &quot;读取 &quot;所返回的字节之后的数据。当没有更多的字节可读时，<code>read</code>返回0，表示文件的结束。</li>
<li>调用 <code>write(fd，buf，n)</code>将<code>n</code>个字节从<code>buf</code>写入文件描述符<code>fd</code>并返回写入的字节数。只有在发生错误时才写入少于<code>n</code>个字节。与<code>read</code>一样，<code>write</code>将数据写入当前文件偏移量，然后将偏移量向前推进写入的字节数：每次<code>写入</code>在前一次停止的地方进行。</li>
<li>下面的程序片段（构成程序<code>cat</code>的本质）将数据从其标准输入复制到其标准输出。如果发生错误，它会向标准错误写入一条消息。</li>
</ul>
</li>
</ul>
<pre><code class="language-c">char buf[512];
int n;

for(;;){
  n = read(0, buf, sizeof buf);
  if(n == 0)
    break;
  if(n &lt; 0){
    fprintf(2, &quot;read error\n&quot;);
    exit(1);
  }
  if(write(1, buf, n) != n){
    fprintf(2, &quot;write error\n&quot;);
    exit(1);
  }
}
</code></pre>
<ul>
<li>在代码片段中需要注意的重要一点是，<code>cat</code>不知道是在读取文件、控制台还是管道。同样，<code>cat</code>也不知道它是在打印到控制台、文件还是其他什么。文件描述符的使用以及文件描述符0输入和文件描述符1输出的约定允许<code>cat</code>的简单实现。</li>
<li>这个<code>close</code>系统调用释放了一个文件描述符，使得它可以在将来的<code>open</code>、<code>tube</code>或<code>dup</code>系统调用中自由使用（见下文）。新分配的文件描述符总是当前进程中编号最低的未使用描述符。</li>
<li>文件描述符和交互使I/O重定向易于实现。<code>fork</code>复制父进程的文件描述符表及其内存，以便子进程开始时与父进程完全相同的打开文件。系统调用替换调用进程的内存，但保留其文件表。这种行为允许shell通过 fork 来实现，在子进程中重新打开选定的文件描述符，然后调用<code>exec</code>来运行新程序。以下是shell为命令<code>cat</code> <code>&lt;</code> <code>input.txt</code>运行的代码的简化版本：</li>
</ul>
<pre><code>char *argv[2];

argv[0] = &quot;cat&quot;;
argv[1] = 0;
if(fork() == 0) {
  close(0);
  open(&quot;input.txt&quot;, O_RDONLY);
  exec(&quot;cat&quot;, argv);
}
</code></pre>
<ul>
<li>子进程关闭文件描述符 0 后，<code>open</code>保证为新打开的文件使用该文件描述符<code>input.txt</code>：0将是最小的可用文件描述符。<code>cat</code>然后执行文件描述符0（标准输入）引用<code>input.txt</code>。父进程的文件描述符不会被这个序列改变，因为它只修改子进程的描述符。</li>
<li>xv6 shell中的I/O重定向代码就是这样工作的。回想一下，在代码的这一点上，shell已经 fork 了子shell，<code>runcmd</code>将调用<code>exec</code>来加载新程序。</li>
<li>第二个参数<code>open</code>由一组标志组成，表示为位，用于控制<code>open</code>的作用。可能的值在文件控制（fcntl）头中定义：<code>O_RDONLY</code>、<code>O_WRONLY</code>、<code>O_RDWR</code>、<code>O_CREATE</code>和<code>O_TRUNC</code>，指示<code>open</code>打开文件以进行读取或写入，或同时进行读取和写入，如果文件不存在则创建文件，并将文件截断为零长度。</li>
<li>现在应该很清楚为什么<code>fork</code>和<code>exec</code>是分开的调用是有帮助的：在两者之间，shell 有机会重定向子进程的I/O而不会干扰主shell的I/O设置。人们可以想象一个假设的组合<code>forkexec</code>系统调用，但是用这样的调用进行I/O重定向的选项看起来很尴尬。shell可以在调用<code>forkexec</code>之前修改自己的I/O设置（然后取消这些修改）；或者<code>forkexec</code>可以将I/O重定向的指令作为参数；或者（最不吸引人的）每个程序（如<code>cat</code>）都可以被教导做自己的I/O重定向。</li>
<li>尽管<code>fork</code>复制了文件描述符表，但每个基础文件偏移量都在父文件和子文件之间共享。</li>
</ul>
<pre><code>if(fork() == 0) {
  write(1, &quot;hello &quot;, 6);
  exit(0);
} else {
  wait(0);
  write(1, &quot;world\n&quot;, 6);
}
</code></pre>
<ul>
<li>在这个片段的末尾，附加到文件描述符1的文件将包含数据<code>hello</code> <code>world</code>。父级中的<code>write</code>（由于<code>wait</code>，只有在子级完成后才运行）从子级<code>写</code>停止的地方开始。这种行为有助于从shell命令序列中产生顺序输出，例如<code>（echo</code> <code>hello</code>；<code>echo</code> <code>world）</code> <code>&gt;output.txt</code>。</li>
<li>这个<code>dup</code>系统调用复制了一个现有的文件描述符，返回一个新的文件描述符，它引用同一个底层I/O对象。两个文件描述符共享一个偏移量，就像<code>fork</code>复制的文件描述符一样。这是另一种将<code>hello</code> <code>world</code>写入文件的方法：</li>
</ul>
<pre><code>fd = dup(1);
write(1, &quot;hello &quot;, 6);
write(fd, &quot;world\n&quot;, 6);
</code></pre>
<ul>
<li>如果两个文件描述符通过一系列<code>fork</code>和<code>dup</code>调用从相同的原始文件描述符派生，则它们共享偏移量。否则，文件描述符不共享偏移量，即使它们是由对同一文件的<code>打开</code>调用引起的。<code>dup</code>允许shell实现如下命令：<code>ls</code> <code>现有文件</code> <code>非现有文件</code> <code>&gt;</code> <code>tmp1</code> <code>2&gt;&amp;1</code>。<code>2&gt;&amp;1</code>告诉shell给命令一个文件描述符2，它是描述符1的副本。现有文件的名称和不存在文件的错误消息都将显示在文件<code>tmp1</code>中。xv6 shell不支持错误文件描述符的I/O重定向，但现在您知道如何实现它了。</li>
<li>文件描述符是一个强大的抽象，因为它们隐藏了它们所连接的细节：写入文件描述符1的进程可能正在写入文件、控制台等设备或管道。</li>
<li>1.3 管道
<ul>
<li>A是一个小内核缓冲区，作为一对文件描述符暴露给进程，一个用于读取，一个用于写入。将数据写入管道的一端可以从管道的另一端读取数据。管道为进程提供了一种通信方式。</li>
<li>下面的示例代码运行程序<code>wc</code>，其标准输入连接到管道的读取端。</li>
</ul>
</li>
</ul>
<pre><code>int p[2];
char *argv[2];

argv[0] = &quot;wc&quot;;
argv[1] = 0;

pipe(p);
if(fork() == 0) {
  close(0);
  dup(p[0]);
  close(p[0]);
  close(p[1]);
  exec(&quot;/bin/wc&quot;, argv);
} else {
  close(p[0]);
  write(p[1], &quot;hello world\n&quot;, 12);
  close(p[1]);
}
</code></pre>
<ul>
<li>程序调用<code>pipe</code>，它创建一个新的管道，并记录数组<code>p</code>中的读写文件描述符。在<code>fork</code>之后，父级和子级都有引用管道的文件描述符。子级调用<code>over</code>和<code>dup</code>使文件描述符零引用管道的读取端，关闭<code>p</code>中的文件描述符，并调用<code>exec</code>运行<code>wc</code>。当<code>wc</code>从其标准输入读取时，它从管道读取。父级关闭管道的读取端，写入管道，然后关闭写入端。</li>
<li>如果没有可用的数据，管道上的<code>读取</code>等待写入数据或关闭所有引用写入端的文件描述符；在后一种情况下，<code>读取</code>将返回0，就像到达数据文件的末尾一样。<code>读取</code>阻塞直到新数据不可能到达的事实是子级在执行上述<code>wc</code>之前关闭管道的写入端很重要的原因之一：如果<code>wc</code>的文件描述符之一引用管道的写入端，<code>wc</code>将永远不会看到文件结束。</li>
<li>xv6 shell以类似于上述代码的方式实现<code>grep fork sh. c|wc-l</code>之类的管道。子进程创建一个管道来连接管道的左端和右端。然后它调用管道的左端的<code>fork</code>和<code>runcmd</code>，调用管道的右端的<code>fork</code>和<code>runcmd</code>，并等待两者都完成。管道的右端可能是一个命令，它本身包括一个管道（例如，<code>a</code> <code>|</code> <code>b</code> <code>|</code> <code>c）</code>，它本身分叉两个新的子进程（一个用于<code>b</code>，一个用于<code>c</code>）。因此，shell可以创建一个进程树。这棵树的叶子是命令，内部节点是等待左右子进程完成的进程。</li>
</ul>
<pre><code>echo hello world | wc
</code></pre>
<ul>
<li>可以在没有管道的情况下实现</li>
</ul>
<pre><code>echo hello world &gt;/tmp/xyz; wc &lt;/tmp/xyz
</code></pre>
<ul>
<li>在这种情况下，管道与临时文件相比至少有三个优点。首先，管道会自动清理自己；使用文件重定向，shell在完成时必须小心删除<code>/tmp/xyz</code>。其次，管道可以传递任意长的数据流，而文件重定向需要磁盘上足够的可用空间来存储所有数据。第三，管道允许并行执行管道阶段，而文件方法要求第一个程序在第二个程序启动之前完成。</li>
<li>1.4 文件系统
<ul>
<li>xv6文件系统提供数据文件，其中包含未解释的字节数组，以及目录，其中包含对数据文件和其他目录的命名引用。这些目录形成一棵树，从一个名为的特殊目录开始。a like<code>/a/b/c</code>指的是根目录<code>/</code>中名为<code>a</code>的目录内名为<code>b</code>的目录内名为<code>c</code>的文件或目录。不以<code>/</code>开头的路径相对于调用进程的路径进行评估，可以通过<code>chdir</code>系统调用更改。这两个代码片段打开同一个文件（假设所有涉及的目录都存在）：</li>
</ul>
</li>
</ul>
<pre><code>chdir(&quot;/a&quot;);
chdir(&quot;b&quot;);
open(&quot;c&quot;, O_RDONLY);

open(&quot;/a/b/c&quot;, O_RDONLY);
</code></pre>
<ul>
<li>第一个片段将进程的当前目录更改为<code>/a/b</code>；第二个片段既不引用也不更改进程的当前目录。</li>
<li>有创建新文件和目录的系统调用：<code>mkdir</code>创建一个新目录，使用<code>O_CREATE</code>标志<code>打开</code>创建一个新数据文件，<code>mKnod</code>创建一个新设备文件。</li>
</ul>
<pre><code>mkdir(&quot;/dir&quot;);
fd = open(&quot;/dir/file&quot;, O_CREATE|O_WRONLY);
close(fd);
mknod(&quot;/console&quot;, 1, 1);
</code></pre>
<ul>
<li><code>mKnod</code>创建一个引用设备的特殊文件。与设备文件关联的是主要和次要设备号（<code>mKnod</code>的两个参数），它们唯一标识内核设备。当进程稍后打开设备文件时，内核将<code>读取</code>和<code>写入</code>系统调用转移到内核设备实现，而不是将它们传递给文件系统。</li>
<li>文件名与文件本身不同；同一个底层文件，称为an，可以有多个名称。每个链接由目录中的一个条目组成；该条目包含文件名和对inode的引用。inode包含关于文件的内容，包括其类型（文件或目录或设备）、长度、文件内容在磁盘上的位置以及文件链接的数量。</li>
<li>该<code>fstat</code>系统调用从文件描述符引用的inode中检索信息。它填充一个<code>struct</code> <code>stat</code>，在<code>stat. h</code>中定义为：</li>
</ul>
<pre><code>#define T_DIR     1   // Directory
#define T_FILE    2   // File
#define T_DEVICE  3   // Device

struct stat {
  int dev;     // File system's disk device
  uint ino;    // Inode number
  short type;  // Type of file
  short nlink; // Number of links to file
  uint64 size; // Size of file in bytes
};
</code></pre>
<ul>
<li>这个<code>link</code>系统调用创建了另一个文件系统名，它引用了与现有文件相同的inode。这个片段创建了一个名为<code>a</code>和<code>b</code>的新文件。</li>
</ul>
<pre><code>open(&quot;a&quot;, O_CREATE|O_WRONLY);
link(&quot;a&quot;, &quot;b&quot;);
</code></pre>
<ul>
<li>读取或写入<code>a</code>与读取或写入<code>b</code>相同。每个inode由唯一的 <code>_inode_ _number_</code> 标识。在上面的代码序列之后，可以通过检查<code>fstat</code>的结果来确定<code>a</code>和<code>b</code>引用相同的底层内容：两者都将返回相同的inode编号（<code>ino</code>），并且<code>nlink</code>计数将设置为2。</li>
<li>该<code>解除关联</code>系统调用从文件系统中删除一个名称。只有当文件的链接计数为零且没有文件描述符引用它时，才释放文件的inode和保存其内容的磁盘空间</li>
</ul>
<pre><code>unlink(&quot;a&quot;);
</code></pre>
<ul>
<li>到最后一个代码序列，使inode和文件内容可以作为<code>b</code>访问。此外，</li>
</ul>
<pre><code>fd = open(&quot;/tmp/xyz&quot;, O_CREATE|O_RDWR);
unlink(&quot;/tmp/xyz&quot;);
</code></pre>
<ul>
<li>是一种创建没有名称的临时inode的惯用方法，该inode将在进程关闭<code>fd</code>或退出时被清理。</li>
<li>Unix提供了可从shell调用的文件实用程序作为用户级程序，例如<code>mkdir</code>、<code>ln</code>和<code>rm</code>。这种设计允许任何人通过添加新的用户级程序来扩展命令行界面。事后看来，这个计划似乎很明显，但在Unix时代设计的其他系统经常将这样的命令构建到shell中（并将shell构建到内核中）。</li>
<li>一个例外是<code>cd</code>，它内置在shell中。<code>cd</code>必须改变shell本身的当前工作目录。如果<code>cd</code>作为常规命令运行，那么shell将分叉一个子进程，子进程将运行<code>cd</code>，<code>cd</code>将改变_子_的工作目录。父的（即shell的）工作目录不会改变。</li>
<li>1.5 现实世界
<ul>
<li>Unix结合了“标准”文件描述符、管道和方便的shell语法，这是编写通用可重用程序的一个重大进步。这个想法引发了一种“软件工具”文化，这种文化是Unix强大和流行的主要原因，shell是第一个所谓的“脚本语言”。Unix系统调用接口今天仍然存在于BSD、Linux和macOS等系统中。</li>
<li>Unix系统调用接口已经通过可移植操作系统接口（POSIX）标准进行了标准化。Xv6_不_符合POSIX标准：它缺少许多系统调用（包括基本的系统调用，如<code>lsearch</code>），并且它提供的许多系统调用与标准不同。我们对xv6的主要目标是简单和清晰，同时提供一个简单的UNIX系统调用接口。一些人已经扩展了xv6，增加了一些系统调用和一个简单的C库，以便运行基本的Unix程序。然而，现代内核提供了比xv6更多的系统调用和更多种类的内核服务。例如，它们支持网络、窗口系统、用户级线程、许多设备的驱动程序等。现代内核不断快速发展，并提供POSIX以外的许多功能。</li>
<li>Unix通过一组文件名和文件描述符接口统一访问多种类型的资源（文件、目录和设备）。这个想法可以扩展到更多种类的资源；一个很好的例子是Plan 9，它将“资源就是文件”的概念应用于网络、图形等。然而，大多数Unix派生的操作系统并没有遵循这条路线。</li>
<li>文件系统和文件描述符是强大的抽象。即便如此，操作系统接口还有其他模型。Unix的前身Multics对文件存储进行了抽象，使其看起来像内存，从而产生了非常不同的界面风格。Multics设计的复杂性直接影响了Unix的设计者，他们的目标是构建更简单的东西。</li>
<li>Xv6没有提供用户或保护一个用户免受另一个用户的概念；在Unix术语中，所有xv6进程都以root身份运行。本书探讨了xv6如何实现其类Unix接口，但这些思想和概念不仅仅适用于Unix。任何操作系统都必须将进程多路复用到底层硬件上，将进程相互隔离，并提供受控进程间通信的机制。在学习了xv6之后，您应该能够查看其他更复杂的操作系统，并了解这些系统中xv6背后的概念。</li>
</ul>
</li>
</ul>
<h2 id="2-实验"><a class="header" href="#2-实验">2. 实验</a></h2>
<h3 id="sleep-easy"><a class="header" href="#sleep-easy">sleep (easy)</a></h3>
<p>在 xv6 中实现 Unix 中的 sleep 命令。</p>
<pre><code class="language-cpp">int
main(int argc, char *argv[]) {
    if (argc != 2) {
        fprintf(2, &quot;input error!\n&quot;);
        exit(1);
    }else {
        int k = atoi(argv[1]);
        sleep(k);
    }
    exit(0);
}
</code></pre>
<pre><code>$ sleep 2 
</code></pre>
<p>argc = 2
argv[0] = sleep
argv[1] = 2</p>
<h3 id="pingpong-easy"><a class="header" href="#pingpong-easy">pingpong (easy)</a></h3>
<pre><code class="language-cpp">#include &quot;kernel/types.h&quot;
#include &quot;kernel/stat.h&quot;
#include &quot;user/user.h&quot;

int
main(int argc, char *argv[]) {
    int p2c[2], c2p[2];
    pipe(p2c); pipe(c2p);
    char buf[64];

    if (fork() &gt; 0) {
        write(p2c[1], &quot;ping&quot;, 4);
        read(c2p[0], buf, 4);
        printf(&quot;%d: received %s\n&quot;, getpid(), buf);
    }else {
        read(p2c[0], buf, 4);
        printf(&quot;%d: received %s\n&quot;, getpid(), buf);
        write(c2p[1], &quot;pong&quot;, 4);
    }
    exit(0);
}
</code></pre>
<h3 id="primes-moderatehard"><a class="header" href="#primes-moderatehard">primes (moderate)/(hard)</a></h3>
<pre><code class="language-cpp">#include &quot;kernel/types.h&quot;
#include &quot;kernel/stat.h&quot;
#include &quot;user/user.h&quot;

void prime(int rd){
    int n;
    read(rd, &amp;n, 4);
    printf(&quot;prime %d\n&quot;, n);
    int created = 0;
    int p[2];
    int num;
    while(read(rd, &amp;num, 4) != 0){
        if(created == 0){
            pipe(p);
            created = 1;
            int pid = fork();
            if(pid == 0){
                close(p[1]);
                prime(p[0]);
                return;
            }else{
                close(p[0]);
            }
        }
        if(num % n != 0){
            write(p[1], &amp;num, 4);
        }
    }
    close(rd);
    close(p[1]);
    wait(0);
}

int
main(int argc, char *argv[]){
    int p[2];
    pipe(p);
    // 父进程
    if(fork() != 0){
        close(p[0]);
        for(int i = 2; i &lt;= 35; i++){
            // 第一个参数是文件描述符
            // 第二个参数是数据的指针
            // 第三个参数是要写入的字节数
            write(p[1], &amp;i, 4);
        }
        close(p[1]);
        wait(0);
    }else{
        // 子进程
        close(p[1]);
        prime(p[0]);
        close(p[0]);
    }
    exit(0);
}
</code></pre>
<h3 id="find-moderate"><a class="header" href="#find-moderate">find (moderate</a></h3>
<p>照着 ls.c 改就行了。</p>
<pre><code class="language-cpp">#include &quot;kernel/types.h&quot;
#include &quot;kernel/stat.h&quot;
#include &quot;user/user.h&quot;
#include &quot;kernel/fs.h&quot;

char* fmtname(char * path)
{
    static char buf[DIRSIZ+1];
    char *p;
    
    for (p = path + strlen(path); p &gt;= path &amp;&amp; *p != '/'; p--);
    p ++;
    if (strlen(p) &gt;= DIRSIZ) return p;
    memmove(buf, p, strlen(p));
    buf[strlen(p)] = 0;
    return buf;
}

void
find(char *path,char *name)
{
  char buf[512], *p;
  int fd;
  struct dirent de;
  struct stat st;

  if((fd = open(path, 0)) &lt; 0){
    fprintf(2, &quot;ls: cannot open %s\n&quot;, path);
    return;
  }

  if(fstat(fd, &amp;st) &lt; 0){
    fprintf(2, &quot;ls: cannot stat %s\n&quot;, path);
    close(fd);
    return;
  }

  switch(st.type){
  case T_FILE:
    if (strcmp(fmtname(path), name) == 0) printf(&quot;%s\n&quot;, path);
    break;

  case T_DIR:
    if(strlen(path) + 1 + DIRSIZ + 1 &gt; sizeof buf){
      printf(&quot;ls: path too long\n&quot;);
      break;
    }
    strcpy(buf, path);
    p = buf+strlen(buf);
    *p++ = '/';
    while(read(fd, &amp;de, sizeof(de)) == sizeof(de)){
      if(de.inum == 0)
        continue;
      memmove(p, de.name, DIRSIZ);
      p[DIRSIZ] = 0;
      // 忽略当前目录和父目录
      if (!strcmp(de.name, &quot;.&quot;) || !strcmp(de.name, &quot;..&quot;)) continue;
      find(buf, name);
    }
    break;
  }
  close(fd);
}

int
main(int argc, char *argv[])
{
    if (argc != 3) {
        fprintf(2, &quot;usage: find [path] [patten]\n&quot;);
        exit(1);
    }
    find(argv[1], argv[2]);
    exit(0);
}
</code></pre>
<h3 id="xargs-moderate"><a class="header" href="#xargs-moderate">xargs (moderate)</a></h3>
<pre><code>$ echo hello | xargs echo aa aaa aaa
aa aaa aaa hello

argv[0]: xargs
argv[1]: echo
argv[2]: aa
argv[3]: aaa
argv[4]: aaa    
</code></pre>
<pre><code class="language-cpp">#include &quot;kernel/types.h&quot;
#include &quot;kernel/stat.h&quot;
#include &quot;user/user.h&quot;


int
main(int argc, char *argv[]) {
    if(argc &lt; 2) {
        printf(&quot;Usage: xargs [command]\n&quot;);
        exit(-1);
    }
    // 拿到当前进程的标准化输入
    char buf[16];
    read(0, buf, 16);

    // 构造完整参数
    char *xargv[16];
    int xargc = 0;
    for (int i = 1; i &lt; argc; i++) {
        xargv[xargc++] = argv[i];
    }

    // 遍历标准输入
    char *p = buf;
    for (int i = 0; i &lt; 16; i++) {
        if (buf[i] == '\n') {
            if (fork() &gt; 0) {
                p = &amp;buf[i + 1];
                wait(0);
            }else {
                // 把标准输入放入指定位置
                buf[i] = 0;
                xargv[xargc] = p; 
                xargc++;
                xargv[xargc] = 0;
                xargc++;

                exec(xargv[0] , xargv);
                exit(0);
            }
        }
    }
    wait(0);
    exit(0);
}
</code></pre>
<pre><code>$ ./grade-lab-util
make: 'kernel/kernel' is up to date.
== Test sleep, no arguments == sleep, no arguments: OK (2.8s)
== Test sleep, returns == sleep, returns: OK (0.8s)
== Test sleep, makes syscall == sleep, makes syscall: OK (0.8s)
== Test pingpong == pingpong: OK (1.1s)
== Test primes == primes: OK (0.9s)
== Test find, in current directory == find, in current directory: OK (1.0s)
== Test find, recursive == find, recursive: OK (1.1s)
== Test xargs == xargs: OK (1.1s)
== Test time ==
time: OK
Score: 100/100
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-syscall"><a class="header" href="#lab-syscall">Lab syscall</a></h1>
<p>上一个实验仅仅是在用户态下面增加一些功能，而这个实验不仅仅是用户态还涉及到了内核。通过这个实验来了解内核的结构以及内核是如何工作的。</p>
<blockquote>
<p>需要提前阅读的内容：xv6书的第2章和第4章的4.3和4.4节，以及相关的源文件。系统调用的用户空间代码在 <code>user/user.h</code> 和 <code>user/usys.pl</code> 中。内核空间的代码是 <code>kernel/syscall.h</code> , <code>kernel/syscall.c</code>。与进程有关的代码是 <code>kernel/proc.h</code> 和 <code>kernel/proc.c</code> 。</p>
</blockquote>
<p>下面是对上述需要阅读内容的提炼总结以及部分翻译。</p>
<h2 id="1-前置阅读内容总结-1"><a class="header" href="#1-前置阅读内容总结-1">1. 前置阅读内容总结</a></h2>
<p>xv6 book ch2 总结</p>
<ul>
<li>OS 需要保证以下三个功能：多路复用：同时支持多个活动。隔离：进程出现问题不影响其他进程执行。交互：进程之间需要能够交互，例如管道。第二章主要介绍宏内核如何实现上述功能，此外还介绍了 xv6 启动时第一个进程的创建。</li>
<li>Xv6运行在多核RISC-V微处理器上，RISC-V 是一个64位的CPU。xv6 是用 &quot;LP64 &quot;C语言编写的，所以 long(L) 和指针(P)是64位的，但int是32位的。</li>
<li>CPU 需要和硬件交互，而硬件大部分呈I/O接口的形式。此处硬件是通过带&quot;-machine virt &quot;选项的qemu模拟出来的。硬件例如 RAM 、包含启动代码的ROM、与用户键盘/屏幕的串行连接以及用于存储的磁盘。</li>
<li>2.1 为什么需要 OS ？
<ul>
<li>如果直接将 OS 当作库函数，那么无法保障隔离性。</li>
<li>为了实现隔离，需要引入权限使得应用程序不能直接访问敏感的硬件资源。所以需要将硬件资源抽象为服务，例如，Unix应用程序只通过文件系统的<code>open</code>、<code>read</code>、<code>write</code>和<code>close</code>系统调用与文件系统进行交互，而不是直接读写磁盘。</li>
<li>同样，Unix 在进程之间透明地切换硬件CPU，必要时保存和恢复寄存器状态，这样应用程序就不必意识到时间共享。这种透明性允许操作系统共享CPU，即使一些应用程序处于无限循环中。</li>
<li>Unix进程使用<code>exec</code>来建立它们的内存映像，而不是直接与物理内存交互。这使得操作系统可以决定将进程放在内存的什么位置；如果内存紧张，操作系统甚至可能将进程的部分数据存储在磁盘上。<code>exec</code>还允许用户将可执行文件储存在文件系统中。</li>
<li>Unix 进程之间的许多形式的交互都是通过文件描述符进行的。文件描述符不仅可以抽象出许多细节（例如，管道或文件中的数据存储在哪里），而且它们的定义方式也可以简化交互。例如，如果管道中的一个应用程序崩溃了，内核就会为管道中的另一个进程产生一个文件结束信号。</li>
<li>xv6 中的系统调用接口经过精心设计，既为程序员提供了便利，又提供了强隔离的可能。Unix接口并不是抽象资源的唯一方式，但事实证明它是一种非常好的方式。</li>
</ul>
</li>
<li>2.2 机器模式，监督模式和系统调用
<ul>
<li>为了实现强隔离，在应用程序和 OS 之间花了条线使得应用程序崩溃后不会影响 OS ，并且 OS 还能处理崩溃的应用程序确保其他程序正确运行。</li>
<li>为了实现强隔离，操作系统必须确保应用程序不能修改（甚至不能读取）操作系统的数据结构和指令，应用程序不能访问其他进程的内存。</li>
<li>CPU提供了强隔离的硬件支持。例如，RISC-V有三种模式，CPU可以执行指令：<strong>机器模式</strong>、<strong>监督者（supervisor）模式</strong>和<strong>用户模式</strong>。在机器模式下执行的指令具有完全的权限，一个CPU在机器模式下启动。机器模式主要用于配置计算机。Xv6会在机器模式下执行几条指令，然后转为监督者模式。</li>
<li>CPU 在<strong>机器模式</strong>下启动，然后转为<strong>监督者模式</strong>，随后转为<strong>用户模式</strong>。CPU 在<strong>机器模式</strong>下具有完全的权限。在<strong>监督者模式</strong>下被允许执行特权指令，叫做允许在内核空间。例如启用和禁用中断，读写保存页表地址的寄存器等。在<strong>用户模式</strong>下执行特权指令会导致切换到监督者模式，进而终止该程序。应用程序只能执行用户模式的指令。</li>
<li>一个应用程序如果要调用内核函数（如xv6中的<code>read</code>系统调用），必须过渡到内核。CPU提供了一个特殊的指令，可以将CPU从用户模式切换到监督者模式，并在内核指定的入口处进入内核。(RISC-V为此提供了<code>ecall</code>指令。)一旦CPU切换到监督者模式，内核就可以验证系统调用的参数，决定是否允许应用程序执行请求的操作，然后拒绝或执行该操作。由内核控制监督者模式的入口点是很重要的；如果应用程序可以决定内核的入口点，那么恶意应用程序就能够在跳过参数验证的情况下进入内核。</li>
</ul>
</li>
<li>2.3 Kernel 组织
<ul>
<li>根据操作系统的哪一部分应该在监督者模式下运行存在两种方式，分别是宏内核和微内核。</li>
<li><strong>宏内核</strong>将所有系统调用的实现都在监督者模式下运行。优点是实现方便，并且 OS 之间的不同部分容易协作。缺点是接口实现复杂，一旦出问题会导致整个内核崩溃。</li>
<li><strong>微内核</strong>能不放在监督者模式下运行就不放。用户模式下执行大部分代码。例如文件系统作为用户级进程运行。应用程序通过内核提供的进程间通信机制来实现和文件服务器的交互。例如，如果一个像shell这样的应用程序想要读写文件，它就会向文件服务器发送一个消息，并等待响应。</li>
<li>在微内核中，内核接口由一些低级函数组成，用于启动应用程序、发送消息、访问设备硬件等。这种组织方式使得内核相对简单，因为大部分操作系统驻留在用户级服务器中。</li>
<li>xv6 和大多数Unix操作系统一样，是以宏内核的形式实现的。因此，xv6内核接口与操作系统接口相对应，内核实现了完整的操作系统。由于xv6不提供很多服务，所以它的内核比一些微内核要小，但从概念上讲xv6是宏内核。</li>
</ul>
</li>
<li>2.4 Code: xv6 organization
<ul>
<li>xv6内核源码在<code>kernel/</code>子目录下。按照模块化的概念，源码被分成了多个文件。模块间的接口在<code>kernel/defs.h</code>中定义。</li>
<li>bio.c 文件系统的磁盘块缓存。</li>
<li>console.c 连接到用户键盘和屏幕。</li>
<li>entry.S 最早的启动说明。</li>
<li>exec.c exec() 系统调用. </li>
<li>file.c 支持文件描述符。 </li>
<li>fs.c 文件系统。 </li>
<li>kalloc.c 物理页分配器. </li>
<li>kernelvec.S 处理来自内核的陷阱，以及定时器中断。 </li>
<li>log.c 文件系统记录和崩溃恢复。</li>
<li>main.c 在启动过程中控制其他模块的初始化。 </li>
<li>pipe.c 管道。 plic.c RISC-V中断控制器。</li>
<li>printf.c 格式化的输出到控制台。 </li>
<li>proc.c 流程和调度安排。</li>
<li>sleeplock.c 产生CPU的锁。</li>
<li>spinlock.c 不产生CPU的锁。</li>
<li>start.c 早期的机器模式启动代码。</li>
<li>string.c C语言字符串和字节数库。</li>
<li>swtch.S 线程切换。 </li>
<li>syscall.c 派遣系统调用到处理功能。</li>
<li>sysfile.c 文件相关的系统调用。</li>
<li>sysproc.c 进程相关的系统调用。</li>
<li>trampoline.S 在用户和内核之间切换的汇编代码。</li>
<li>trap.c 用C代码来处理和返回陷阱和中断。</li>
<li>uart.c 串行端口的控制台设备驱动程序。</li>
<li>virtio_disk.c 磁盘设备驱动程序。</li>
<li>vm.c 管理页表和地址空间。</li>
</ul>
</li>
<li>2.5 Process overview
<ul>
<li>xv6 以进程为单位来实现隔离。进程隔离可以防止一个进程破坏另一个进程的内存、CPU、文件描述符等。此外还可以防止进程破坏内核。内核必须小心实现进程抽象，因为一个错误或恶意的应用程序可能会欺骗内核或硬件做一些不好的事情（例如，规避隔离）。内核用来实现进程的机制包括：用户/监督模式标志、地址空间和线程的时间片轮转。</li>
<li>为了实施隔离，进程抽象为程序提供了一种拥有整个机器的错觉。进程为程序提供了一个看似私有的内存系统，或者说是地址空间，其他进程不能对其进行读写。进程还为程序提供了“私有”的CPU，用来执行程序的指令。</li>
<li>XV6 使用页表（由硬件实现）使得每个进程拥有自己的地址空间。RISC-V 页表将<strong>虚拟地址</strong>（RISC-V指令操作的地址）转换（或 &quot;映射&quot;）为<strong>物理地址</strong>（CPU芯片发送到主存储器的地址）。</li>
<li>Xv6为每个进程维护一个单独的页表，定义该进程的地址空间。如图2.3所示，进程的用户空间内存的地址空间是从虚拟地址0开始的。指令存放在最前面，其次是全局变量，然后是栈，最后是一个堆区（用于<strong>malloc</strong>），进程可以根据需要扩展。有一些因素限制了进程地址空间的最大长度：RISC-V上的指针是64位宽；硬件在页表中查找虚拟地址时只使用低的39位；xv6只使用39位中的38位。因此，最大地址是$2^{38}-1$ = 0x3fffffffff，也就是<code>MAXVA</code>（kernel/riscv.h:348）。在地址空间的顶端，xv6保留了一页，用于<strong>trampoline</strong>和映射进程<strong>trapframe</strong>的页，以便切换到内核，第4章会详细解释。</li>
<li>xv6内核为每个进程维护了许多状态，记录在<code>proc</code>结构体(kernel/proc.h:86)。一个进程最重要的内核状态是它的页表、内核栈和运行状态。用<code>p-&gt;xxx</code>来表示<code>proc</code>结构的元素，例如，<code>p-&gt;pagetable</code>是指向进程页表的指针。</li>
<li>每个进程都有一个线程在执行进程的指令。一个线程可以被暂停，然后再恢复。为了在进程之间透明地切换，内核会暂停当前运行的线程，并恢复另一个进程的线程。线程的大部分状态（局部变量、函数调用返回地址）都存储在线程的栈中。每个进程有两个栈：用户栈和内核栈（<code>p-&gt;kstack</code>）。当进程在执行用户指令时，只有它的用户栈在被使用，而它的内核栈是空的。当进程进入内核时（因为系统调用或中断），内核代码在进程的内核栈上执行；当进程在内核中时，它的用户栈仍然包含保存的数据，但不被主动使用。进程的线程在用户栈和内核栈中交替执行。内核栈是独立的（并且受到保护，不受用户代码的影响），所以即使一个进程用户栈被破坏了，内核也可以执行。</li>
<li>一个进程可以通过执行RISC-V <code>ecall</code>指令进行系统调用。该指令提高硬件权限级别，并将程序计数器改变为内核定义的入口点。入口点的代码会切换到内核栈，并执行实现系统调用的内核指令。当系统调用完成后，内核切换回用户栈，并通过调用<code>sret</code>指令返回用户空间，降低硬件特权级别，恢复执行系统调用前的用户指令。进程的线程可以在内核中阻塞等待I/O，当I/O完成后，再从离开的地方恢复。</li>
<li><code>p-&gt;state</code>表示进程是创建、就绪、运行、等待I/O，还是退出。</li>
<li><code>p-&gt;pagetable</code>以RISC-V硬件需要的格式保存进程的页表，当进程在用户空间执行时，xv6使分页硬件使用进程的<code>p-&gt;pagetable</code>。进程的页表也会记录分配给该进程内存的物理页地址。</li>
</ul>
</li>
<li>2.6 Code: starting xv6 and the first process
<ul>
<li>本节主要关注内核如何启动和运行的第一个进程。</li>
<li>当计算机开机后，会首先从一个只读存储器中读取 bootloader 。bootloader  负责将 xv6 内核加载到内存中。随后在机器模式下，CPU从 <code>_entry</code>（kernel/entry.S:6）开始执行 xv6 。RISC-V在禁用分页硬件的情况下启动：虚拟地址直接映射到物理地址。</li>
<li>loader 将xv6内核加载到物理地址<code>0x80000000</code>的内存中。之所以将内核放在<code>0x80000000</code>而不是<code>0x0</code>，是因为地址范围<code>0x0:0x80000000</code>包含I/O设备。</li>
<li><code>_entry</code>处的指令设置了一个栈，这样 xv6 就可以运行 C 代码。Xv6在文件<code>start.c</code>(kernel/start.c:11)中声明了初始栈的空间，即<code>stack0</code>。在<code>_entry</code>处的代码加载栈指针寄存器<code>sp</code>，地址为<code>stack0+4096</code>，也就是栈的顶部，因为RISC-V的栈是向下扩张的。现在内核就拥有了栈，<code>_entry</code>调用<code>start</code>(kernel/start.c:21)，并执行其C代码。</li>
<li>函数<code>start</code>执行一些只有在机器模式下才允许的配置，然后切换到监督者模式。为了进入监督者模式，RISC-V提供了指令<code>mret</code>。这条指令最常用来从上一次的调用中返回，上一次调用从监督者模式到机器模式。<code>start</code>并不是从这样的调用中返回，而是把事情设置得像有过这样的调用一样：它在寄存器<code>mstatus</code>中把上一次的特权模式设置为特权者模式，它把<code>main</code>的地址写入寄存器<code>mepc</code>中，把返回地址设置为<code>main</code>函数的地址，在特权者模式中把<code>0</code>写入页表寄存器<code>satp</code>中，禁用虚拟地址转换，并把所有中断和异常委托给特权者模式。</li>
<li>在进入特权者模式之前，<code>start</code>还要执行一项任务：对时钟芯片进行编程以初始化定时器中断。在完成了这些基本管理后，<code>start</code>通过调用<code>mret</code>“返回”到监督者模式。这将导致程序计数器变为<code>main</code>（kernel/main.c:11）的地址。</li>
<li>在<code>main</code>(kernel/main.c:11)初始化几个设备和子系统后，它通过调用<code>userinit</code>(kernel/proc.c:212)来创建第一个进程。第一个进程执行一个用RISC-V汇编编写的小程序<code>initcode.S</code>（user/initcode.S:1），它通过调用<code>exec</code>系统调用重新进入内核。正如我们在第一章中所看到的，<code>exec</code>用一个新的程序（本例中是<code>/init</code>）替换当前进程的内存和寄存器。</li>
<li>一旦内核完成<code>exec</code>，它就会在<code>/init</code>进程中返回到用户空间。<code>init</code> (user/init.c:15)在需要时会创建一个新的控制台设备文件，然后以文件描述符0、1和2的形式打开它。然后它在控制台上启动一个shell。这样系统就启动了。</li>
</ul>
</li>
<li>2.7 Real world
<ul>
<li>实际上现代操作系统中即存在宏内核，也存在微内核。许多Unix内核都是宏内核，例如 Linux 。此外大多数操作系统都采用了进程概念，大多数进程都与xv6的相似。</li>
<li>现代操作系统支持进程可以拥有多个线程，以允许一个进程利用多个CPU。在一个进程中支持多个线程涉及到不少 xv6 没有的机制，包括潜在的接口变化(如Linux的<code>clone</code>，<code>fork</code>的变种)，以控制线程所共享进程的那些部分。</li>
</ul>
</li>
<li>4.3 Code: Calling system calls
<ul>
<li>第2章以<code>initcode.S</code>调用<code>exec</code>系统调用结束（user/initcode.S:11）。接下来研究用户调用是如何在内核中实现<code>exec</code>系统调用的。</li>
<li>用户代码将<code>exec</code>的参数放在寄存器<code>a0</code>和<code>a1</code>中，并将系统调用号放在<code>a7</code>中。系统调用号与函数指针表<code>syscalls</code>数组（kernel/syscall.c:108）中的项匹配。<code>ecall</code>指令进入内核，执行<code>uservec</code>、<code>usertrap</code>，然后执行<code>syscall</code> 。</li>
<li><code>syscall</code>（kernel/syscall.c:133）从trapframe中的<code>a7</code>中得到系统调用号，并其作为索引在<code>syscalls</code>查找相应函数。对于第一个系统调用<code>exec</code>，<code>a7</code>将为<code>SYS_exec</code>（kernel/syscall.h:8），这会让<code>syscall</code>调用<code>exec</code>的实现函数<code>sys_exec</code>。</li>
<li>当系统调用函数返回时，<code>syscall</code>将其返回值记录在<code>p-&gt;trapframe-&gt;a0</code>中。用户空间的<code>exec()</code>将会返回该值，因为RISC-V上的C调用通常将返回值放在<code>a0</code>中。系统调用返回负数表示错误，0或正数表示成功。如果系统调用号无效，<code>syscall</code>会打印错误并返回-1。</li>
</ul>
</li>
<li>4.4 Code: System call arguments
<ul>
<li>内核的系统调用实现需要找到用户代码传递的参数。因为用户代码调用系统调用的包装函数，参数首先会存放在寄存器中，这是C语言存放参数的约定位置。内核trap代码将用户寄存器保存到当前进程的trap frame中，内核代码可以在那里找到它们。函数<code>argint</code>、<code>argaddr</code>和<code>argfd</code>从trap frame中以整数、指针或文件描述符的形式检索第n个系统调用参数。它们都调用<code>argraw</code>来获取保存的用户寄存器（kernel/syscall.c:35）。</li>
<li>一些系统调用传递指针作为参数，而内核必须使用这些指针来读取或写入用户内存。例如，<code>exec</code>系统调用会向内核传递一个指向用户空间中的字符串的指针数组。这些指针带来了两个挑战。首先，用户程序可能是错误的或恶意的，可能会传递给内核一个无效的指针或一个旨在欺骗内核访问内核内存而不是用户内存的指针。第二，xv6内核页表映射与用户页表映射不一样，所以内核不能使用普通指令从用户提供的地址加载或存储。</li>
<li>内核实现了安全地将数据复制到用户提供的地址或从用户提供的地址复制数据的函数。例如<code>fetchstr</code>（kernel/syscall.c:25）。文件系统调用，如<code>exec</code>，使用<code>fetchstr</code>从用户空间中检索字符串文件名参数。<code>fetchstr</code>调用<code>copyinstr</code>来做这些困难的工作。</li>
<li><code>copyinstr</code>（kernel/vm.c:406）将用户页表<code>pagetable</code>中的虚拟地址<code>srcva</code>复制到<code>dst</code>，需指定最大复制字节数。它使用<code>walkaddr</code>（调用<code>walk</code>函数）在软件中模拟分页硬件的操作，以确定<code>srcva</code>的物理地址<code>pa0</code>。<code>walkaddr</code>（kernel/vm.c:95）检查用户提供的虚拟地址是否是进程用户地址空间的一部分，所以程序不能欺骗内核读取其他内存。类似的函数<code>copyout</code>，可以将数据从内核复制到用户提供的地址。</li>
</ul>
</li>
</ul>
<h2 id="2-实验-1"><a class="header" href="#2-实验-1">2. 实验</a></h2>
<p>开始实验，切换到syscall分支。</p>
<pre><code class="language-sh">$ git checkout syscall
$ make clean
</code></pre>
<p>直接运行测试 <code>make grade</code> 发现 trace 和 sysinfotest 无法执行，接下来的任务就是实现这两个命令。</p>
<pre><code>如果出现如下问题，可将 `grade-lab-syscall` 第一行 `#!/usr/bin/env python` 改为 `#!/usr/bin/env python3` 

/usr/bin/env: ‘python’: No such file or directory
make: *** [Makefile:227: grade] Error 127

接下来再次运行 make grade 发现不能执行 trace 和 sysinfotest。
</code></pre>
<h3 id="system-call-tracing-moderate"><a class="header" href="#system-call-tracing-moderate">System call tracing (moderate)</a></h3>
<p>添加一个跟踪系统调用的功能。创建一个名为 trace 的系统调用的函数。输入中有个参数，该参数是一个整数（掩码），指定位置决定了要跟踪哪些系统调用。例如要跟踪一条命令中 fork 的系统调用。那么就要设置 fork 对应的掩码 1 &lt;&lt; SYS_fork ， 其中SYS_fork是kernel/syscall.h中的一个系统调用编号。因为 SYS_fork = 1，所以此时掩码就是 2 因为 <code>2 = 1 &lt;&lt; 1</code> 。</p>
<p>打印出要跟踪的系统调用的进程ID、系统调用的名称和返回值，包含子进程。下面是几个实现好的例子。</p>
<pre><code class="language-sh">$ trace 32 grep hello README
3: syscall read -&gt; 1023
3: syscall read -&gt; 966
3: syscall read -&gt; 70
3: syscall read -&gt; 0
</code></pre>
<p>其中 32 是掩码，而 $$32 = 2^5$$ ，查阅 <code>kernel/syscall.h</code> 可知 <code>SYS_read    5</code> ，那么要跟踪的系统调用就是 read 。将执行 <code>grep hello README</code> 过程中调用 read 的进程ID、系统调用的名称和返回值打印出来。</p>
<pre><code class="language-sh">$ trace 2147483647 grep hello README
4: syscall trace -&gt; 0
4: syscall exec -&gt; 3
4: syscall open -&gt; 3
4: syscall read -&gt; 1023
4: syscall read -&gt; 966
4: syscall read -&gt; 70
4: syscall read -&gt; 0
4: syscall close -&gt; 0
</code></pre>
<p>2147583647 的31个低位全部被设置，所以所有的系统调用都将被跟踪。</p>
<pre><code class="language-sh">$ grep hello README
$
</code></pre>
<p>这个例子中，程序没有被跟踪，所以没有输出。</p>
<pre><code class="language-sh">$ trace 2 usertests forkforkfork
usertests starting
test forkforkfork: 407: syscall fork -&gt; 408
408: syscall fork -&gt; 409
409: syscall fork -&gt; 410
410: syscall fork -&gt; 411
409: syscall fork -&gt; 412
410: syscall fork -&gt; 413
409: syscall fork -&gt; 414
411: syscall fork -&gt; 415
...
$   
</code></pre>
<p>usertests 中的 <code>forkforkfork</code> test的所有后代的fork系统调用都被追踪。</p>
<p>最终实现出来的结果就是上面所呈现的，课程进程 ID 不同。</p>
<blockquote>
<p>跟着 hint 走，下面的内容是结合了提示之后我的实现步骤。</p>
</blockquote>
<ul>
<li>
<p>在 Makefile 第 152 行处添加 <code>$U/_trace</code> 。目的是编译的时候能够识别到 trace 。</p>
</li>
<li>
<p>运行<code>make qemu</code> 发现报错，无法编译 <code>user/trace.c</code> 第 17 行的 trace 函数 。原因是这个系统调用还没有被注册，在 <code>user/user.h</code> 添加即可，接下来需要判断 trace 的函数签名，也就是输入输出。</p>
</li>
<li>
<p>由 <code>user/trace.c</code> 第 17 行处可知，trace 输入输出均为 int，此时在 <code>user/user.h</code> 第26行处添加代码 <code>int trace(int);</code> 接下来在 <code>kernel/syscall.h</code> 中添加syscall编号。 </p>
</li>
<li>
<p>在<code>user/usys.pl</code>中添加 <code>entry(&quot;trace&quot;);</code> 原因是 Makefile 调用 perl 脚本 <code>user/usys.pl</code>，产生<code>user/usys.S</code> 。 RISC-V 的 ecall 过渡到内核。(Makefile =&gt; <code>user/usys.pl</code> =&gt; <code>user/usys.S</code>)</p>
</li>
<li>
<p>此时 <code>make qemu</code> 就可以启动了。</p>
</li>
<li>
<p>此时再运行 <code>trace 32 grep hello README</code> 依旧失败，因为还未在内核中实现。</p>
</li>
<li>
<p>在 <code>kernel/sysproc.c</code> 中增加一个 sys_trace() 函数，在用户态执行 trace 函数后经过汇编代码最终切换到内核态后将会执行该函数(sys_trace())。这个函数的实现是照着上面代码改的，例如 <code>sys_exit()</code> 。其中 argint() 函数是拿到用户态输入的参数，将其保存到 n 中，其实就是掩码，将掩码保存到当前进程中，那么就需要在当前进程中加一个参数了。myproc() 表示当前进程，</p>
</li>
</ul>
<pre><code class="language-cpp">uint64
sys_trace(void){
  int n;
  if(argint(0, &amp;n) &lt; 0) {
    return -1;
  }
  myproc()-&gt;trace_mask = n;
  return 0;
}
</code></pre>
<ul>
<li>在进程 <code>kernel/proc.h</code> 第 106 行添加 <code>int trace_mask; </code> 用于记录掩码。</li>
<li>接下来是修改 <code>kernel/syscall.c</code> 中的 <code>syscall()</code> 函数以打印跟踪输出。</li>
<li>先将在头部添加 <code>extern uint64 sys_trace(void); </code>方便别的文件引用。</li>
<li>接下来在 <code>static uint64 (*syscalls[])(void)</code> 添加相应内容 <code>[SYS_trace]   sys_trace,</code></li>
<li>因为要打印系统调用名称，但是缺少系统调用号和名称之间的映射，需要建立二者的映射。</li>
</ul>
<pre><code class="language-cpp">static char* syscall_names[] = {
  [SYS_fork]    &quot;fork&quot;,
  [SYS_exit]    &quot;exit&quot;,
  [SYS_wait]    &quot;wait&quot;,
  [SYS_pipe]    &quot;pipe&quot;,
  [SYS_read]    &quot;read&quot;,
  [SYS_kill]    &quot;kill&quot;,
  [SYS_exec]    &quot;exec&quot;,
  [SYS_fstat]   &quot;fstat&quot;,
  [SYS_chdir]   &quot;chdir&quot;,
  [SYS_dup]     &quot;dup&quot;,
  [SYS_getpid]  &quot;getpid&quot;,
  [SYS_sbrk]    &quot;sbrk&quot;,
  [SYS_sleep]   &quot;sleep&quot;,
  [SYS_uptime]  &quot;uptime&quot;,
  [SYS_open]    &quot;open&quot;,
  [SYS_write]   &quot;write&quot;,
  [SYS_mknod]   &quot;mknod&quot;,
  [SYS_unlink]  &quot;unlink&quot;,
  [SYS_link]    &quot;link&quot;,
  [SYS_mkdir]   &quot;mkdir&quot;,
  [SYS_close]   &quot;close&quot;,
  [SYS_trace]   &quot;trace&quot;,
};

void
syscall(void)
{
  int num;
  struct proc *p = myproc();

  num = p-&gt;trapframe-&gt;a7;
  if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) {
    p-&gt;trapframe-&gt;a0 = syscalls[num]();
    if ((p-&gt;trace_mask &amp; (1 &lt;&lt; num)) != 0) {                                  
        printf(&quot;%d: syscall %s -&gt; %d \n&quot;, p-&gt;pid, syscall_names[num], p-&gt;trapframe-&gt;a0);
    }
  } else {
    printf(&quot;%d %s: unknown sys call %d\n&quot;,
            p-&gt;pid, p-&gt;name, num);
    p-&gt;trapframe-&gt;a0 = -1;
  }
}

</code></pre>
<p>主要关注 if 内，判断当前所执行进程的参数是否命中掩码，如果命中就打印。</p>
<pre><code class="language-sh">    if ((p-&gt;trace_mask &amp; (1 &lt;&lt; num)) != 0) {                                  
        printf(&quot;%d: syscall %s -&gt; %d \n&quot;, p-&gt;pid, syscall_names[num], p-&gt;trapframe-&gt;a0);
    }
</code></pre>
<p>修改 fork()(见kernel/proc.c)，将跟踪掩码从父进程复制到子进程，方便跟踪子进程的执行。添加 <code>np-&gt;trace_mask = p-&gt;trace_mask;</code> 即可。</p>
<p>注意修改 kernel/proc.c 中的 <code>freeproc()</code> 函数，将 <code>p-&gt;trace_mask = 0;</code> 释放进程的时候要重置相应内容。</p>
<h3 id="sysinfo-moderate"><a class="header" href="#sysinfo-moderate">Sysinfo (moderate)</a></h3>
<p>任务是添加一个系统调用函数 sysinfo ，先把用户态下的执行流程设置好。</p>
<ul>
<li>将 <code>$U/_sysinfotest</code> 添加到 Makefile 的 UPROGS 中。接下来执行 make qemu 后发现报错：</li>
<li>添加系统调用 sysinfo，步骤与 trace 相同。（如果这里卡住就回头仔细搞明白 trace 的执行流程再往下研究）。</li>
<li>sysinfo 需要将 struct sysinfo 拷贝回用户空间；参见 sys_fstat() (kernel/sysfile.c)和 filestat() (kernel/file.c)，了解如何使用 copyout() 进行拷贝。</li>
</ul>
<p>在 kernel/kalloc.c 中添加一个函数，统计自由内存的数量。</p>
<p>在 kernel/proc.c中加入一个函数，统计进程的数量。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-pgtbl"><a class="header" href="#lab-pgtbl">Lab pgtbl</a></h1>
<p><a href="https://pdos.csail.mit.edu/6.828/2020/labs/pgtbl.html">实验手册</a> / <a href="https://github.com/duguosheng/6.S081-All-in-one/blob/main/labs/requirements/lab3.md">中文版</a></p>
<h2 id="虚拟地址"><a class="header" href="#虚拟地址">虚拟地址</a></h2>
<p>https://hansimov.gitbook.io/csapp/part2/ch09-virtual-memory</p>
<p>页表为每个进程提供自己私有地址空间和内存的机制，决定了内存地址含义以及可以访问哪些范围的物理内存。</p>
<p>页表是什么？有什么用？为什么要用多级页表？</p>
<p>页表是一个存储物理地址的表，也就是一个数组，里面存的是物理地址，索引是虚拟地址。根据虚拟地址查表得物理地址。</p>
<p>每一个进程都有自己的页表，</p>
<p>早期计算机没有虚拟内存存在三个问题。</p>
<ul>
<li>程序分配走一部分内存后，剩余内存不是从零开始，需要处理偏移值。</li>
<li>内存分段后，内存的分配与回收会导致大量的内存碎片且无法高效的利用内存空间。</li>
<li>程序可以访问其他程序的数据，安全性无法得到保证。</li>
</ul>
<p>虚拟内存是如何解决以上三个问题的？</p>
<ul>
<li>每一个进程都有自己的页表且地址从零开始，解决了手动维护偏移值的问题。</li>
<li>虽然物理地址不连续，但是虚拟地址连续，不需要分配一整块的物理内存，页表同合适的物理内存建立映射即可。如果内存空间不够，内存使用置换算法同磁盘交换数据。</li>
<li>进程的无法访问对方的页表使得安全性得以保障。</li>
</ul>
<p>切换到 pgtbl 分支</p>
<p>$ git checkout pgtbl
$ make clean</p>
<h2 id="1-print-a-page-table-easy"><a class="header" href="#1-print-a-page-table-easy">1. Print a page table (easy)</a></h2>
<p>源码被分成了多个文件，在 defs.h(kernel/defs.h) 中定义模块间的接口。</p>
<p>跟着 hint 走，看明白 freewalk 函数稍微改动即可。</p>
<p><code>(pte &amp; (PTE_R|PTE_W|PTE_X)) == 0</code> 表示非叶子节点。</p>
<p>commit: <a href="https://github.com/weijiew/6.S081-2020/commit/6632a87f01b651984a54bd04f20cc63a99ca1b3f">PASS Lab3 Print a page table</a>.</p>
<p>$ make qemu-gdb
pte printout: OK (6.9s)
(Old xv6.out.pteprint failure log removed)
== Test answers-pgtbl.txt == answers-pgtbl.txt: FAIL
Cannot read answers-pgtbl.txt
== Test count copyin ==</p>
<h2 id="2-a-kernel-page-table-per-process-hard"><a class="header" href="#2-a-kernel-page-table-per-process-hard">2. A kernel page table per process (hard)</a></h2>
<p>Xv6 的每个进程都有自己的用户页表，但是共享同一个内核页表，而内核页表的地址是直接映射的。接下来的任务是修改内核，使每个进程都有自己独立的内核页表。共享的内核页表 <code>pagetable_t kernel_pagetable;</code> 位于 vm.c 中。</p>
<ul>
<li>pagetable_t 是什么？</li>
</ul>
<p>pagetable_t 是一个指向 RISC-V 根页表页的指针。可以是内核页表，也可以是进程的页表。核心函数是 walk 和 mappages ，前者通过虚拟地址得到 PTE，后者将虚拟地址映射到物理地址。</p>
<p>pagetable_t 其实就是一个数组。接下来先研究 mappages 再研究 walk 。因为 mappages 调用了 walk 。</p>
<ul>
<li>mappages 函数的功能是将一个虚拟地址范围映射到物理地址范围。</li>
</ul>
<p>结合着代码看，第二个参数 va 是开始创建 PTE 的虚拟地址，va 映射到了第四个参数 pa 指向的物理地址。映射成功返回零，如果通过 walk() 无法分配到所需页的页表就返回一。size 表示待虚拟地址的范围。</p>
<pre><code class="language-cpp">int
mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)
{
  uint64 a, last;
  pte_t *pte;

  a = PGROUNDDOWN(va); // 向下取整
  last = PGROUNDDOWN(va + size - 1);
  for(;;){
    if((pte = walk(pagetable, a, 1)) == 0)
      return -1;
    if(*pte &amp; PTE_V)
      panic(&quot;remap&quot;);
    *pte = PA2PTE(pa) | perm | PTE_V;
    if(a == last)
      break;
    a += PGSIZE;
    pa += PGSIZE;
  }
  return 0;
}
</code></pre>
<p>通过 walk() 拿到 PTE ，根据 PTE 建立和物理地址 PA 的映射。 </p>
<p>PTE 是页表(pagetable_t)的一行数据，也就是页表是由 PTE 组成。其中 PTE 由 44 位的 PPN 和 10 位的 标志位(Flags)组成。44 位的 PPN 和虚拟地址的后 12 位(offset)共同拼接组成了物理地址。其中 index 用来查找 page ，offset 对应的是一个 page 中的哪个字节。</p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318135402.png" alt="20220318135402" /></p>
<p>PTE_V 存于 Flags 标志位中，表示 PTE 是否存在</p>
<p><code>#define PA2PTE(pa) ((((uint64)pa) &gt;&gt; 12) &lt;&lt; 10)</code></p>
<p>其中 <code>PA2PTE</code> 表示将 PA 转化为 PTE ，右移 12 位表示剔除 offset (结合上图来看！上图也就是 xv6 Figure 3.1) 左移 10 位表示留出 Flags 位，后续通过按位或运算(|)将 Flags 拼接上来。</p>
<p>a == last 表示范围内的映射完了。<code>a += PGSIZE;</code> 表示步长是 PGSIZE，也就是 4096 bytes .</p>
<ul>
<li>接下来研究 walk() 函数，结合图 Figure 3.2 来看，经过两次循环拿到最底层的页表，然后返回对应的 PTE 。最开始我不明白为啥用这么多页表，后来一想发现这其实就是一颗多叉树。顶层的页表步长最大，因为表里面套表。首先通过顶层的页表确定大致范围然后不断缩小范围，这样可以大大加快索引速度。</li>
</ul>
<pre><code class="language-cpp">pte_t *
walk(pagetable_t pagetable, uint64 va, int alloc)
{
  if(va &gt;= MAXVA) // va 是虚拟地址
    panic(&quot;walk&quot;);

  for(int level = 2; level &gt; 0; level--) { // 三级页表
    pte_t *pte = &amp;pagetable[PX(level, va)];
    if(*pte &amp; PTE_V) { // PTE_V 表示页表合法
      pagetable = (pagetable_t)PTE2PA(*pte);
    } else {
      if(!alloc || (pagetable = (pde_t*)kalloc()) == 0)
        return 0;
      memset(pagetable, 0, PGSIZE);
      *pte = PA2PTE(pagetable) | PTE_V;
    }
  }
  return &amp;pagetable[PX(0, va)];
}
</code></pre>
<p>通过实验的要求是所有 usertests 运行正常。注意此时还没有改动代码，usertests 是可以正常运行的，将共享的内核页表改为独享的内核页表之后 usertests 依旧能正常运行才算通过实验。注意这个测试跑的很慢。</p>
<p>Some hints:</p>
<ol>
<li>在 struct proc 中增加一个字段，用于进程的内核页表。</li>
</ol>
<blockquote>
<p>proc 是用于描述进程的结构体，其中包含了进程的所有状态信息。</p>
</blockquote>
<p>在 proc 结构体中 (kernel/proc.h) 添加内核页表，表示进程独占的内核页表。每个进程的内核页表应该与现有的全局内核页表相同。</p>
<ol start="2">
<li>为一个新进程生成内核页表的合理方法是实现一个修改版的 kvminit，它可以生成一个新的页表而不是修改 kernel_pagetable 。你想从 allocproc 中调用这个函数。</li>
</ol>
<blockquote>
<p>阅读 kvminit，kvminit 是什么？ xv6 3.3 Code: creating an address space</p>
</blockquote>
<p>修改 kvminit ，之前是内核页表写死，现在抽象出来提供单独的调用。创建一个单独的页表.</p>
<ol start="3">
<li>确保每个进程的内核页表都有对该进程的内核堆栈的映射。在未修改的xv6中，所有的内核栈都是在 procinit 中设置的。你需要把这些功能的一部分或全部转移到 allocproc。</li>
</ol>
<p>删除初始化进程(procinit())时分配的共享内核栈。改为在 allocproc 中进行分配单独的内核栈。照着 procinit() 中删除部分改改就行,改为固定每一个进程的固定位置.</p>
<ol start="4">
<li>修改scheduler()来加载进程的内核页表到核心的satp寄存器(参阅kvminithart来获取启发)。不要忘记在调用完w_satp()后调用sfence_vma()</li>
</ol>
<p>scheduler() 函数是干什么的?</p>
<ol start="6">
<li>没有进程运行时scheduler()应当使用kernel_pagetable</li>
</ol>
<p>在 scheduler() 中，调度某个RUNNABLE的进程前，先切到它的内核页表，运行完毕后，再切回global kernel pagetable。</p>
<ol start="7">
<li>
<p>在freeproc中释放一个进程的内核页表</p>
</li>
<li>
<p>你需要一种方法来释放页表，而不必释放叶子物理内存页面。</p>
</li>
</ol>
<p>递归释放三级页表,循环也行,和打印页表的逻辑类似.</p>
<h2 id="simplify-copyincopyinstr-hard"><a class="header" href="#simplify-copyincopyinstr-hard">Simplify copyin/copyinstr (hard)</a></h2>
<p>在用户进程内核页表中添加用户页表映射的副本。用户态下查询物理地址需要查表,而内核态下查询可以直接通过 mmu 查询加快速度。</p>
<p>阅读原 copyin 函数，大致流程为找到虚拟地址对应的物理地址，读取物理地址中的内容并将数据存入 dst 中。</p>
<pre><code class="language-cpp">// 
int
copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
{
  uint64 n, va0, pa0;

  while(len &gt; 0){ // 遍历 len 长度
    va0 = PGROUNDDOWN(srcva); // 虚拟地址向下取整
    pa0 = walkaddr(pagetable, va0); // 将虚拟地址转为物理地址
    if(pa0 == 0) // 没有找到物理地址
      return -1;
    n = PGSIZE - (srcva - va0);
    if(n &gt; len) // 截断处理
      n = len;
    memmove(dst, (void *)(pa0 + (srcva - va0)), n);

    len -= n;
    dst += n;
    srcva = va0 + PGSIZE;
  }
  return 0;
}
</code></pre>
<p>现在的问题是进程的内核态也要维护一个页表副本。所以需要将一个页表的映射关系拷贝到另外一个页表中。</p>
<p>遍历用户页表拿到 PTE ，将其映射到内核页表中即可。注意拷贝的时候需要将页表设置为非用户页<code>&amp; ~PTE_U</code>，因为 RISC-V 中内核无法直接访问用户页。</p>
<p>除此之外还需要实现一个复原页表的功能，也就是移除映射。</p>
<p>内核从 PLIC 开始向下增长，用户进程不能超过 PLIC 所以不能有 CLINT 的映射。修改 kvminit 单独给 CLINT 添加映射，用户进程的内核页表不能有 CLINT 的映射。</p>
<p>用户进程地址空间的增长不能超过内核，而内核是从 PLIC 起步，所以用户进程的地址范围不能超过 PLIC 。</p>
<p>修改 fork 函数，从父进程复制到子进程后，再将子进程的用户态页表复制到内核态下。</p>
<p>exec() 清除内核页表中的旧映射，建立新映射。</p>
<p>growproc() 增加或缩小 n 比特的内存。如果 n &lt; 0 则删除对应内核页表的映射，反之则申请相应内存然后同步映射到页表中。</p>
<p>userinit() 记得复制页表。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-trap"><a class="header" href="#lab-trap">Lab trap</a></h1>
<ul>
<li>
<p>实验手册：https://pdos.csail.mit.edu/6.S081/2020/labs/traps.html</p>
</li>
<li>
<p>中文版：http://xv6.dgs.zone/labs/requirements/lab4.html</p>
</li>
<li>
<p><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec06-isolation-and-system-call-entry-exit-robert">lec6</a></p>
</li>
<li>
<p>https://www.bilibili.com/video/BV19k4y1C7kA?p=4</p>
</li>
<li>
<p>https://www.bilibili.com/video/BV19k4y1C7kA?p=5</p>
</li>
<li>
<p>视频解析：https://www.bilibili.com/video/BV1FT4y127WW/?spm_id_from=pageDriver</p>
</li>
</ul>
<h2 id="总结-1"><a class="header" href="#总结-1">总结</a></h2>
<p>指令在执行的时候是会暂停的，以下三种情况下会暂停普通指令的执行：</p>
<ol>
<li>系统调用。例如系统执行 ecall 指令。</li>
<li>异常。例如除零或使用无效地址。</li>
<li>中断。例如设备发出读写请求。</li>
</ol>
<p>以上三种情况统称为 trap 。trap 是透明的，也就是被执行的代码感知不到 trap 的存在。</p>
<p>trap 的大致流程如下：</p>
<ol>
<li>控制权交给内核。</li>
<li>内核保存寄存器状态方便日后恢复。</li>
<li>内核执行相应代码。</li>
<li>内核恢复状态并从 trap 中返回。</li>
<li>代码回到原来的地方。</li>
</ol>
<p>在切换的过程中需要修改寄存器的状态，以下是一些重要寄存器的介绍。</p>
<ul>
<li>程序计数器(Program Counter Register) ，指向了当前正在指向的下一条指令。</li>
<li>mode ，表明当前mode的标志位，这个标志位表明了当前是supervisor mode还是user mode。当我们在运行Shell的时候，自然是在user mode。</li>
<li>SATP（Supervisor Address Translation and Protection） 指向page table的物理内存地址。</li>
<li>STVEC（Supervisor Trap Vector Base Address Register）指向了内核中处理trap的指令的起始地址。</li>
<li>SEPC（Supervisor Exception Program Counter）在trap的过程中保存程序计数器的值。</li>
<li>SSRATCH（Supervisor Scratch Register）寄存器，这也是个非常重要的寄存器（详见6.5）。</li>
</ul>
<p>这些寄存器表明了执行系统调用时计算机的状态。</p>
<p>trap 流程</p>
<ol>
<li>保存 32 个用户寄存器。</li>
<li>保存程序计数器 CP ，中断完成后通过之前的 PC 继续执行。</li>
<li>将 mode 改成 supervisor mode 。</li>
<li>将 SATP 指向 kernel page table 。</li>
<li>将堆栈寄存器指向位于内核的一个地址，因为我们需要一个堆栈来调用内核的C函数。</li>
<li>设置好后跳入内核的C代码。</li>
</ol>
<p>这一节的重点是如何从将程序执行从用户空间切换到内核的一个位置。</p>
<p>用户代码不能接入到 user/kernel 切换，因为会破坏安全性，所以trap中涉及到的硬件和内核机制不能依赖任何来自用户空间东西。例如我们不能依赖32个用户寄存器，它们可能保存的是恶意的数据，所以，XV6的trap机制不会查看这些寄存器，而只是将它们保存起来。</p>
<p>trap 机制对用户代码是透明的。也就是用户代码察觉不到 trap 的执行。</p>
<p>可以在supervisor mode完成，但是不能在user mode完成的工作：读写SATP寄存器，也就是page table的指针；STVEC，也就是处理trap的内核指令地址；SEPC，保存当发生trap时的程序计数器；SSCRATCH等等。</p>
<p>在 supervisor mode 下可以使用PTE_U标志位为0的PTE。当PTE_U标志位为1的时候，表明用户代码可以使用这个页表；</p>
<p>supervisor mode 中的代码并不能读写任意物理地址。在supervisor mode中，就像普通的用户代码一样，也需要通过page table来访问内存。如果一个虚拟地址并不在当前由SATP指向的page table中，又或者SATP指向的page table中PTE_U=1，那么supervisor mode不能使用那个地址。所以，即使我们在supervisor mode，我们还是受限于当前page table设置的虚拟地址。</p>
<p>如何通过trap进入到内核空间：</p>
<ol>
<li>write 通过执行 ECALL 指令来执行系统调用。</li>
<li>ECALL指令会切换到具有supervisor mode的内核中。ecall 具体干了三件事情：
<ol>
<li>将代码从user mode改到supervisor mode。</li>
<li>将程序计数器的值保存在了SEPC寄存器。</li>
<li>ecall会跳转到STVEC寄存器指向的指令。</li>
</ol>
</li>
<li>在内核中执行的第一个指令是一个由汇编语言写的函数，叫做 uservec ，位于 trampoline.s 中。
<ol>
<li>保存现场，也就是保存 32 个通用寄存器中的数据。</li>
<li>切换到内核页表，内核栈，将当前进程的 CPUid 加载到寄存器中。</li>
<li>跳转到 usertrap() 。</li>
</ol>
</li>
<li>之后跳转到 trap.c 中的 usertrap() 中。
<ol>
<li>更改STVEC寄存器。(从用户态到内核态，如果已经在内核中了那么很多操作将会省去)</li>
<li>通过 myproc 函数获取当前正在执行的进行。</li>
<li>保存当前进程的SEPC寄存器到一个与该进程关联的内存中(trapframe)，因为中间如果发生进程切换可能会导致数据被覆盖。</li>
<li>分析为什么执行 usertrap() 调用，8 表示因为系统调用而执行 usertrap() 函数。</li>
<li>判断当前进程是否已被杀掉。</li>
<li>之前保存的 PC + 4，指向返回地址。</li>
<li>执行 syscall 前开启中断。此时是可以被中断的。</li>
</ol>
</li>
<li>在 usertrap 中，执行 syscall 函数。
<ol>
<li>根据传入的代表系统调用的数字进行查找，并在内核中执行具体实现了系统调用功能的函数。此时就是sys_write。</li>
<li>sys_write 将要显示数据输出到console上，完成后会返回给 syscall 函数。</li>
</ol>
</li>
<li>usertrap 最终调用了 trap.c 中的 usertrapret() 函数，该函数实现了在C代码中实现的返回到用户空间的工作。
<ol>
<li>首先关闭中断，更新STVEC寄存器来指向用户空间的trap处理代码，将STVEC更新到指向用户空间的trap处理代码时。</li>
<li>存储了内核页表，内核栈的指针。</li>
<li>存储了usertrap函数的指针，这样trampoline代码才能跳转到这个函数（注，详见6.5中 ld t0 (16)a0 指令）。</li>
<li>从tp寄存器中读取当前的CPU核编号，并存储在trapframe中，这样trampoline代码才能恢复这个数字，因为用户代码可能会修改这个数字。</li>
</ol>
</li>
<li>此时又回到 trampoline.s 中，执行 userret 完成的了一些细节。调用机器指令返回到用户空间并恢复ECALL之后的用户程序的执行。
<ol>
<li>切换page table 。</li>
</ol>
</li>
</ol>
<p>trampoline page 中包含了内核的trap处理代码。</p>
<p>ecall尽量的简单可以提升软件设计的灵活性。</p>
<h2 id="调试"><a class="header" href="#调试">调试</a></h2>
<p>使用 <code>make fs.img</code> 编译文件 <code>user/call.c</code> 生成 <code>user/call.asm</code> 阅读该文件。</p>
<p><code>sudo apt-get install tmux</code> 下载 tmux 。</p>
<p>输入 <code>$ tmux</code> 启动。</p>
<p>ctrl +b 方向键 可以调整选中的窗口。例如 ctrl +b ⬆ 会把光标移动到上方的窗格。</p>
<p>一个窗口运行 <code>make qemu-gdb</code> 指定一个 CPU 会更好。</p>
<p>在另一个窗口执行：</p>
<pre><code class="language-cpp">gdb-multiarch kernel/kernel

# (gdb) 进入gdb后执行
set confirm off
set architecture riscv:rv64
set riscv use-compressed-breakpoints yes
target remote localhost:26000 
</code></pre>
<p><code>file user/_call</code> 调试用户态下的程序。</p>
<p><code>b main</code> 在 main 处打一个断点。</p>
<p>在第一个窗口中执行 call 命令。（没有特殊说明其他命令都是在第二个窗口中执行）</p>
<p><code>layout split</code> 开启更多窗口，提供更多信息。</p>
<p>gdb 常用命令。</p>
<pre><code class="language-sh">b # 打断点 (e.g.     b main | b *0x30)
c # continue

layout split # view src-code &amp; asm-code

ni # 单步执行汇编(不进函数)
si # 单步执行汇编(有函数则进入函数)
n # 单步执行源码
s # 单步执行源码

p # print
p $a0 # 打印a0寄存器的值
p/x 1536 # 以16进制的格式打印1536
i r a0 # info registers a0
x/i 0x630 # 查看0x630地址处的指令
</code></pre>
<h2 id="risc-v-assembly-easy"><a class="header" href="#risc-v-assembly-easy">RISC-V assembly (easy)</a></h2>
<ol>
<li>Which registers contain arguments to functions? For example, which register holds 13 in main's call to printf?</li>
</ol>
<p>a0 a2-a7 其中 a2 保存 13</p>
<ol start="2">
<li>Where is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)</li>
</ol>
<p>函数调用已经被内联了。</p>
<ol start="3">
<li>At what address is the function printf located?</li>
</ol>
<p>0000000000000630</p>
<ol start="4">
<li>What value is in the register ra just after the jalr to printf in main?</li>
</ol>
<p>经过 jalr 跳转后 ra 的值是 0x38 其中 ra 是 return adddress 的缩写。</p>
<p>跳转之前打印 ra 中的数据</p>
<p><code>jalr	1536(ra)</code> 表示跳转到 ra 寄存器中的值加上 1536 所在地址。
其中 1536 在 16 进制下是 0x600 ，此时 ra 寄存器中的值是 0x30 。所以将会跳转到 0x630 处。
此外 ra 的值将会变为 pc + 4 即 0x38. 也就是 return address 。执行完函数之后通过 ra 返回。</p>
<ol start="4">
<li>
<p>Q: Run the following code.</p>
<p>unsigned int i = 0x00646c72;
printf(&quot;H%x Wo%s&quot;, 57616, &amp;i);</p>
</li>
</ol>
<p>What is the output?
If the RISC-V were instead big-endian what would you set i to in order to yield the same output?
Would you need to change 57616 to a different value?
A: &quot;He110 World&quot;; 0x726c6400; no, 57616 is 110 in hex regardless of endianness.</p>
<p>%X 表示无符号以十六进制表示的整数。%s 表示输出字符串。</p>
<p>其中 57616 在 16 进制下是 E110 。 </p>
<p>其中 72:r 6c:l 64:d 符合 Risc-V 小段的输出，如果是大端的话需要将 i 修改为 0x726c6400 。</p>
<ol start="5">
<li>
<p>In the following code, what is going to be printed after 'y='? (note: the answer is not a specific value.) Why does this happen?</p>
<p>printf(&quot;x=%d y=%d&quot;, 3);</p>
<p>$ call
x=3 y=5221</p>
</li>
</ol>
<ul>
<li><a href="https://github.com/weijiew/6.S081-2020/commit/a3894ff5e3b7e9a3e08a0a1ea1697ff3bac9bb87">详细代码</a></li>
</ul>
<h2 id="backtrace-moderate"><a class="header" href="#backtrace-moderate">Backtrace (moderate)</a></h2>
<p>建议阅读《程序员的自我修养》第十章。</p>
<p>bttest 将会调用 sys_sleep，在 sys_sleep 中插入 backtrace() 。</p>
<p>在 kernel/defs.h 中添加 backtrace() 并在 kernel/printf.c 中实现。</p>
<p>在 kernel/riscv.h 添加获取 frame pointer 的代码，代码如下：</p>
<pre><code class="language-c">static inline uint64
r_fp()
{
  uint64 x;
  asm volatile(&quot;mv %0, s0&quot; : &quot;=r&quot; (x) );
  return x;
}
</code></pre>
<p>其中 s0 中存储了 frame pointer 。在 backtrace 中将会调用该函数。</p>
<p>将 backtrace() 加入 panic 中，当跳转到 panic 时将会打印调用函数的信息。</p>
<p>栈指针 sp (stack pointer)。 指向栈的最高处。</p>
<p>栈帧指针 fp (frame pointer)。指向栈帧(stack frame)的最高处。</p>
<p>可以简单的理解为 sp 是当前函数在栈中地址上界，而 fp 则是当前具体执行到那一步了。</p>
<p>fp - 8 表示返回地址， fp - 16 表示上一个 fp 的地址。</p>
<p>fp 保存在寄存器 s0 中，每个函数调用栈</p>
<p>通过循环，不断打印 ra ，通过 pre fp 拿到父函数的地址再打印 ra 即可。</p>
<ul>
<li><a href="https://github.com/weijiew/6.S081-2020/commit/102e77e9b3324df1062b8812b578f0d5b95d1a71">详细代码</a></li>
</ul>
<h2 id="alarm-hard"><a class="header" href="#alarm-hard">Alarm (hard)</a></h2>
<p>实现一个进程使用 CPU time 时周期性的发出警告的功能。例如周期性的检查中断/异常需要用到这个功能。</p>
<p>增加一个系统调用 sigalarm(interval, handler)，其中 handler 是一个函数，interval 是一个整数，表示经过的时间。sigalarm 的功能是经过 interval 个 CPU ticks ，调用 handler 函数。如果 sigalarm(0, 0) 内核将会停止周期性调用。</p>
<p>proc 中需要保存 interval ，还需要一个字段表示当前时间 n ，每次调用 n-- 。当 n = 0 时执行函数并更新状态。</p>
<p>如果有 handler 函数正在执行那么就不能执行别的 handler 函数，需要加一个字段判断一下。</p>
<p>最后注意恢复。</p>
<pre><code>== Test answers-traps.txt == answers-traps.txt: OK 
== Test backtrace test == 
$ make qemu-gdb
backtrace test: OK (12.1s) 
== Test running alarmtest == 
$ make qemu-gdb
(4.5s) 
== Test   alarmtest: test0 == 
alarmtest: test0: OK 
== Test   alarmtest: test1 == 
alarmtest: test1: OK 
== Test   alarmtest: test2 == 
alarmtest: test2: OK 
== Test usertests == 
$ make qemu-gdb
usertests: OK (116.5s) 
== Test time == 
time: OK 
Score: 85/85
</code></pre>
<ul>
<li><a href="https://github.com/weijiew/6.S081-2020/commit/bddcd70db9d2f61749c8bd58b8100f49217a122d">详细代码</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-lazy"><a class="header" href="#lab-lazy">Lab lazy</a></h1>
<p>首先阅读实验手册 <a href="https://pdos.csail.mit.edu/6.S081/2020/labs/lazy.html">Lab: xv6 lazy page allocation</a> / <a href="http://xv6.dgs.zone/labs/requirements/lab5.html">中文</a> 。</p>
<p>首先切换分支：</p>
<p>$ git fetch
$ git checkout lazy
$ make clean</p>
<p>接下来学习前置内容.</p>
<h2 id="0-总结"><a class="header" href="#0-总结">0. 总结</a></h2>
<p>在此之前申请内存的时候是用</p>
<p>总的来说,当申请内存的时候是立即分配.这个实验要实现的是只有真正使用的时候才会立即分配内存.</p>
<blockquote>
<p>下面是阅读 <a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec08-page-faults-frans">Lec8</a> 的一些总结和 </p>
</blockquote>
<p>总的来说四块内容:</p>
<ul>
<li>lazy allocation</li>
<li>copy-on-write fork</li>
<li>demand paging</li>
<li>memory mapped files</li>
</ul>
<p>在 XV6 中，一旦用户空间进程触发了page fault，会导致进程被杀掉。</p>
<p>虚拟内存的两个优点：Isolation，level of indirection 。</p>
<p>trampoline page，它使得内核可以将一个物理内存page映射到多个用户地址空间中。</p>
<p>guard page，它同时在内核空间和用户空间用来保护Stack。</p>
<p>直接映射表示虚拟地址就是物理地址。</p>
<p>page fault 三个有价值的信息：</p>
<ul>
<li>引起page fault的内存地址。</li>
<li>引起page fault的原因类型。</li>
<li>引起page fault时的程序计数器值，这表明了page fault在用户空间发生的位置。</li>
</ul>
<p>当程序出现 page fault 时会触发 trap 机制，也就是将程序运行切换到内核，同时也会将出错的地址存放在STVAL寄存器中。</p>
<p>SCAUSE 寄存器中保存了触发 page fault 的原因。例如 13 表示是因为 load 引起的 page fault；15 表示是因为 store 引起的 page fault；12 表示是因为指令执行引起的 page fault 。</p>
<p>综上因为 page fault 触发 trap 机制并且进入到内核空间，STVAL 寄存器和 SCAUSE 寄存器都会有相应的值。</p>
<p>第三个信息触发引起page fault时的程序计数器值。通过 trap 机制我们已经了解到这个地址存放在 SEPC（Supervisor Exception Program Counter）寄存器中，并同时会保存在 trapframe-&gt;epc 中。关注这个值的目的在于当修复 page table 后可以通过重新执行对应的指令。</p>
<p>sbrk 可以扩大自己的 heap 。最初 sbrk 位于 heap 的底端，同时也是 stack 的顶端。由 p-&gt;sz 表示。</p>
<p>默认的 sbrk 是 eager allocation ，也就是一旦调用就立即分配相应的内存。但在实际使用中应用程序所需内存的大小是难以预测的，并且为了考虑最坏的情况分配的内存更倾向于多分配一些。所以常常会导致有些内存永远也用不上。</p>
<p>lazy allocation 的思想是使用的时候在具体分配，而不是一下子分配好。sbrk 调用的时候仅仅是将 <code>p-&gt;sz + n</code>，n 是需要新分配的内存page数量，此时内核不会分配任何物理内存。直到使用到这块内存时才会去分配物理内存。</p>
<p>所以，如果我们解析一个大于旧的p-&gt;sz，但是又小于新的p-&gt;sz（注，也就是旧的p-&gt;sz + n）的虚拟地址，我们希望内核能够分配一个内存page，并且重新执行指令。</p>
<p>如果出现一个 page fault ，并且虚拟地址小于当前p-&gt;sz，同时大于stack，可以认为来自 heap 的内存并且内核还没有分配物理内存。解决这个问题可以通过 kalloc 函数分配一个内存 page 初始化 page 内容为零，并将其映射到用户页表中。然后重新执行指令即可。</p>
<p>eager allocation 可以明确的知道物理内存不够。lazy allocation 当发现物理内存不够的时候有两种解决方案，其一是直接返回一个错误并杀掉进程。</p>
<p>通过 sbrk 扩容后，p-&gt;sz 会更新，如果待解析的地址旧的 p-&gt;sz 且小于新的 p-&gt;sz 则认为是有效地址，只是还未分配。但是大于新的 p-&gt;sz 则认为是程序错误。</p>
<ul>
<li>Zero Fill On Demand </li>
</ul>
<p>用户程序的地址空间分为text区域，data区域，同时还有一个BSS区域.</p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318135511.png" alt="20220318135511" />
Copy On Write Fork</p>
<p>子进程和父进程的一些全局变量是共享的,而在此之前子进程复制了一份. 这些变量是只读的.</p>
<p>只有在修改的时候才会单独复制要修改的页并更新映射关系.父进程和子进程都采用同样的处理方式.</p>
<p>当向一个只读 page 执行写操作时,如何区分是普通读写还是 copy-on-write 场景?</p>
<p>通过读取页表的 RSW 位可以判断是否为 copy-on-write 场景进而执行相应的操作。</p>
<p>当多个进程指向同一个物理页的时候其中一个进程不能释放共享的页表,否则会导致其他页的出问题.
通过引用计数来解决这个问题.</p>
<ul>
<li>Demand paging</li>
</ul>
<p>text和data也以 lazy 的方式加载.也就是所谓的按需加载.</p>
<p>如果内存不够用可以选择 LRU 算法.</p>
<p>dirty page 和 non-dirty page 更倾向于撤回后者.因为前者很有可能继续更改.</p>
<ul>
<li>Memory Mapped Files</li>
</ul>
<p>page fault 结合了 page table 和 trap .</p>
<h2 id="1-eliminate-allocation-from-sbrk-easy"><a class="header" href="#1-eliminate-allocation-from-sbrk-easy">1. Eliminate allocation from sbrk() (easy)</a></h2>
<ol>
<li>
<p>修改 sysproc.c 中的 sys_sbrk(). 删除对growproc()的调用,更新 sz. </p>
</li>
<li>
<p>make qmeu 启动 xv6 并输出  echo hi 会报错: </p>
<p>$ echo hi
usertrap(): unexpected scause 0x000000000000000f pid=3
sepc=0x00000000000012ac stval=0x0000000000004008
panic: uvmunmap: not mapped</p>
</li>
</ol>
<p>原因是没有读取的内容还没有被映射,也就是没有分配物理内存,这是符合预期的.</p>
<h2 id="2-lazy-allocation-moderate"><a class="header" href="#2-lazy-allocation-moderate">2. Lazy allocation (moderate)</a></h2>
<p>解决上面的错误,也就是新分配一个物理页面并映射到发生错误的地址，然后返回到用户空间，让进程继续执行。</p>
<p>scause 寄存器中保存了报错原因,由报错可知 <code>scause 0x000000000000000f</code> 也就是 15 .</p>
<p>通过查看 RISC-V 的文档可知 15 表示是因为 store 引起的 page fault . (lec8) 而 13 是页错误.</p>
<p>发生 13 或 15 类型的错误,原因是没有真正的分配内存,这是符合预期的,因为之前只是简单的修改了 sz .</p>
<p>在 usertrap 中分配内存.通过 r_scause() 获取出错类型,通过 r_stval 获取映射失败的虚拟地址.然后分配内存即可.</p>
<p>接下来运行 make qemu 输出如下内容会出错:</p>
<p>$ echo hi
panic: uvmunmap: not mapped</p>
<p>这是因为 lazy 的缘故,消除映射的时候以为映射过了,其实有些地址没有建立映射但是进行了消除.此处简单的 cotinue 即可.</p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318135538.png" alt="20220318135538" /></p>
<p>接下来就可以正常输出了:</p>
<p>$ echo hi
hi</p>
<h2 id="lazytests-and-usertests-moderate"><a class="header" href="#lazytests-and-usertests-moderate">Lazytests and Usertests (moderate)</a></h2>
<p>处理 sbrk 参数为负的情况,直接在 sys_sbrk 中处理即可.</p>
<p>处理不合理的地址,地址应当小于 sz 大于 sp .</p>
<p>处理 uvmcopy 函数,发现没有建立映射的内存 cotinue 即可.</p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318135555.png" alt="20220318135555" />
修改 fork() 函数,其中需要将父页的内容复制到子页中(uvmcopy),而复制的过程中因为 lazy 的缘故存在一些没有映射的页,所以当发现地址不存在时需要忽略.</p>
<p>接下来是处理系统调用,当发生系统调用执行(exe.c)函数的时候的时候发现地址不存在(walkaddr),需要分配内存并建立相关映射,这块的逻辑和 usertrap 的处理类似了.</p>
<h2 id="参考-2"><a class="header" href="#参考-2">参考</a></h2>
<ol>
<li>https://zhuanlan.zhihu.com/p/367314945</li>
<li>https://blog.miigon.net/posts/s081-lab5-lazy-page-allocation/</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-cow"><a class="header" href="#lab-cow">Lab cow</a></h1>
<ul>
<li>
<p><a href="http://xv6.dgs.zone/labs/requirements/lab6.html">实验手册</a></p>
</li>
<li>
<p><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec09-interrupts">lec09-interrupts</a></p>
</li>
</ul>
<p>实现 Copy On Write Fork, 这个概念在 lec8 中已经讲过了.</p>
<p>不能随便释放物理页,因为共享页可能有多个 PTE 引用.释放时需要保证不能有其他 PTE 的引用.</p>
<blockquote>
<p>在 shell 中执行指令时，首先会 fork 一个子进程，然后在子进程中使用 exec 执行 shell 中的指令。在这个过程中，fork 需要完整的拷贝所有父进程的地址空间，但在 exec 执行时，又会完全丢弃这个地址空间，创建一个新的，因此会造成很大的浪费。</p>
</blockquote>
<blockquote>
<p>为了优化这个特定场景（fork 时）的内存利用率，我们可以在 fork 时，并不实际分配内存（与上一个实验的懒分配很像），而是让子进程和父进程共享相同的内存区域（页表不同，但指向的物理地址相同）。但为了保证进程之间的隔离性，我们不能同时对这块区域进行写操作，因此，设置共享的内存地址只有读权限。当需要向内存页中写入数据时，会触发缺页中断，此时再拷贝一个内存页，更新进程的页表，将内容写进去，然后重新执行刚才出错的指令。</p>
</blockquote>
<p>切换分支</p>
<pre><code>$ git fetch
$ git checkout cow
$ make clean
</code></pre>
<h2 id="implement-copy-on-write-hard"><a class="header" href="#implement-copy-on-write-hard">Implement copy-on write (hard)</a></h2>
<p>目标:实现 COW 并通过 cowtest 和 usertests .</p>
<ol>
<li>修改 uvmcopy() 父子进程共享物理页并将该页设置为只读,也就是清除 PTE_W 标志。设置 PTE_W 非法可以参考 uvmclear() . </li>
<li>设置 PTE_COW 方便识别. 利用 RSW (reserved for software) 位来表示.</li>
<li>为每一个物理页设置引用计数,统计引用该页的次数.也就是设置数组,数组的每一位表示该页的引用次数. kmem 表示物理页.</li>
<li>CHUfreerange 表示释放范围内的物理页,释放的时候将页面的引用次数设置为 1 .</li>
<li>在 usertrap 中捕获 page falut ,为 cow page 分配物理内存.</li>
<li>使用 kalloc() 进行内存分配时，需要将对应 page 的 reference count 设置为 1，使用kfree()释放内存时，只能将reference count为 0 的页面放回空闲列表。</li>
<li>注意读写的时候需要加锁.</li>
<li>处理 copyout() , 从内核复制到用户时需要分配相应的物理内存.</li>
</ol>
<h2 id="参考-3"><a class="header" href="#参考-3">参考</a></h2>
<ol>
<li>https://www.wmc1999.top/posts/6-s081-lab6-cow/</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-thread"><a class="header" href="#lab-thread">Lab thread</a></h1>
<p><a href="http://xv6.dgs.zone/labs/requirements/lab7.html">实验手册</a></p>
<p>实现用户级线程之间的切换，使用多线程来切换。</p>
<p>切换分支</p>
<pre><code>$ git fetch
$ git checkout thread
$ make clean
</code></pre>
<h2 id="总结-2"><a class="header" href="#总结-2">总结</a></h2>
<p><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec09-interrupts">lec09-interrupts</a></p>
<p>中断的场景：</p>
<ol>
<li>网卡收到了一个packet，网卡会生成一个中断。</li>
<li>用户通过键盘按下了一个按键，键盘会产生一个中断。</li>
</ol>
<p>操作系统需要做的是，保存当前的工作，处理中断，处理完成之后再恢复之前的工作。</p>
<p>系统调用，page fault，中断，都使用相同的机制但是又不完全一样。</p>
<p>中断与系统调用的三个差别：</p>
<ol>
<li>asynchronous 系统调用发生在正在运行进程的 context 中，而中断于当前运行在 CPU 上的进程没有任何关系。</li>
<li>concurrency CPU和生成中断的设备是并行的在运行。</li>
<li>program device 每个设备都有一个编程手册，就像RISC-V有一个包含了指令和寄存器的手册一样。设备的编程手册包含了它有什么样的寄存器，它能执行什么样的操作，在读写控制寄存器的时候，设备会如何响应。</li>
</ol>
<p>PLIC(Platform Level Interrupt Control)会管理来自于外设的中断。</p>
<p>53 个不同的来自于设备的中断经过 PLIC 路由到某个 CPU 的核中处理。</p>
<ol>
<li>PLIC会通知当前有一个待处理的中断</li>
<li>其中一个CPU核会Claim接收中断，这样PLIC就不会把中断发给其他的CPU处理</li>
<li>CPU核处理完中断之后，CPU会通知PLIC</li>
<li>PLIC将不再保存中断的信息</li>
</ol>
<p>Console是如何显示出“$ ls” 其中“ $ ”是Shell程序的输出，而“ls”是用户通过键盘输入之后再显示出来的。</p>
<p>位于 sh.c getcmd() 中，设备会将字符传输给UART的寄存器，UART之后会在发送完字符之后产生一个中断。
在QEMU中，模拟的线路的另一端会有另一个UART芯片（模拟的），这个UART芯片连接到了虚拟的Console，它会进一步将“$ ”显示在console上。</p>
<p>对于“ls”，这是用户输入的字符。键盘连接到了UART的输入线路，当你在键盘上按下一个按键，UART芯片会将按键字符通过串口线发送到另一端的UART芯片。另一端的UART芯片先将数据bit合并成一个Byte，之后再产生一个中断，并告诉处理器说这里有一个来自于键盘的字符。之后Interrupt handler会处理来自于UART的字符。</p>
<ul>
<li>位于start.c的start函数。在机器模式的 stack0 下从 entry.S 在这里以机器模式跳到这个函数上。
<ul>
<li>这里将所有的中断都设置在Supervisor mode，然后设置SIE寄存器来接收External，软件和定时器中断，之后初始化定时器。</li>
<li>处理 main 函数
<ul>
<li>第一个外设是 console，处理 consoleinit 函数
<ul>
<li>初始化锁</li>
<li>调用了 uartinit 配置好UART芯片使其可以被使用。
<ul>
<li>关闭中断</li>
<li>设置波特率(串口线的传输速率)</li>
<li>设置字符长度为8bit</li>
<li>重置FIFO</li>
<li>重新打开中断</li>
</ul>
</li>
</ul>
</li>
<li>调用plicinit函数
<ul>
<li>代码的第一行使能了UART的中断，这里实际上就是设置PLIC会接收哪些中断，进而将中断路由到CPU。</li>
<li>代码的第二行设置PLIC接收来自IO磁盘的中断。</li>
</ul>
</li>
<li>plicinithart函数
<ul>
<li>plicinit是由0号CPU运行，之后，每个CPU的核都需要调用plicinithart函数表明对于哪些外设中断感兴趣。</li>
<li>在plicinithart函数中，每个CPU的核都表明自己对来自于UART和VIRTIO的中断感兴趣。因为我们忽略中断的优先级，所以我们将优先级设置为0。</li>
</ul>
</li>
</ul>
</li>
<li>此时已经有了生成中断的外部设备，我们有了PLIC可以传递中断到单个的CPU。</li>
<li>在main函数的最后，程序调用了scheduler函数，
<ul>
<li>scheduler函数主要是运行进程。但是在实际运行进程之前，会执行intr_on函数来使得CPU能接收中断。
<ul>
<li>intr_on函数只完成一件事情，就是设置SSTATUS寄存器，打开中断标志位。</li>
</ul>
</li>
</ul>
</li>
<li>在这个时间点，中断被完全打开了。如果PLIC正好有pending的中断，那么这个CPU核会收到中断。</li>
</ul>
</li>
</ul>
<blockquote>
<p>阅读 xv6 手册中的“第7章: 调度”， lec11,13</p>
</blockquote>
<p>https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec11-thread-switching-robert/</p>
<p>为什么要用多线程？</p>
<ol>
<li>多个用户共同使用一台机器。</li>
<li>程序结构简单。</li>
<li>多线程在多核机器上可以通过并行实现加速。</li>
</ol>
<p>线程的状态由三部分组成：</p>
<ol>
<li>PC </li>
<li>保存变量的寄存器。</li>
<li>程序栈，记录了函数调用的记录栈。</li>
</ol>
<p>多线程并行的两个策略：</p>
<ol>
<li>在多核处理器上使用多个 CPU 。</li>
<li>一个 CPU 在多个线程之间切换。</li>
</ol>
<p>通过其他方式也可以实现并行，例如 event-driven programming 或 state machine ，但线程不是最简单的但却是最有效的。</p>
<p>实现线程面临的挑战：</p>
<ol>
<li>如何实现线程间的切换，也就是所谓的调度(Scheduling) 。</li>
<li>切换线程时保存并恢复状态。</li>
<li>如何处理密集型线程。</li>
</ol>
<p>利用中断来处理密集型线程，中断处理程序优先级更高。 具体流程为定时器中断将CPU控制权给到内核，内核再自愿的出让CPU。这也被称之为 pre-emptive scheduling ，即用户代码本身没有让出 CPU 反之则是 voluntary scheduling 。</p>
<p>线程的三种状态：</p>
<ol>
<li>RUNNING，线程当前正在某个CPU上运行。</li>
<li>RUNABLE，线程还没有在某个CPU上运行，但是一旦有空闲的CPU就可以运行。</li>
<li>SLEEPING 不想运行在CPU上的线程，因为这些线程可能在等待I/O或者其他事件。</li>
</ol>
<p>从 RUNNING 转变为 RUNABLE 时需要将位于寄存器中的信息(trapframe)拷贝到内存中，例如 PC 。反之则要将之前保存的信息拷贝回对应 CPU 的寄存器中。</p>
<p>用户进程之间的切换流程：首先切换到 a 程序对应的内核进程，然后切换到 b 程序的内核进程，最后切换到 b 程序的用户进程。</p>
<p>程序 a 切换到程序 b 的具体流程： </p>
<ol>
<li>
<p>将 a 程序内核线程的内核寄存器保存在一个 context 对象中。</p>
</li>
<li>
<p>恢复 b 程序的 context 对象。</p>
</li>
<li>
<p>b 程序可继续进行中断，然后返回。</p>
</li>
<li>
<p>一个定时器中断强迫 CPU 从用户空间进程切换到内核，trampoline 代码将用户寄存器保存于用户进程对应的 trapframe 对象中；</p>
</li>
<li>
<p>在内核中运行 usertrap，来实际执行相应的中断处理程序。这时 CPU 处于进程 P1 的内核线程和内核栈上，执行内核中普通的C代码；</p>
</li>
<li>
<p>假设进程 P1 对应的内核线程决定它想出让 CPU，它会做很多工作，这个我们稍后会看，但是最后它会调用swtch函数（译注：switch 是C 语言关键字，因此这个函数命名为swtch 来避免冲突），这是整个线程切换的核心函数之一；</p>
</li>
<li>
<p>swtch函数会保存用户进程P1对应内核线程的寄存器至context对象。所以目前为止有两类寄存器：用户寄存器存在trapframe中，内核线程的寄存器存在context中。</p>
<ol>
<li>CPU 上运行的内核线程可以直接切换到这个 CPU 对应的调度器线程。</li>
<li>swtch 函数会恢复之前为 CPU0 的调度器线程保存的寄存器和 stack pointer，之后就在调度器线程的context 下执行 schedulder 函数。</li>
<li>在schedulder函数中会做一些清理工作，例如将进程P1设置成RUNABLE状态。</li>
<li>通过进程表单找到下一个RUNABLE进程。假设找到的下一个进程是P2（虽然也有可能找到的还是P1），schedulder函数会再次调用swtch函数，完成下面步骤：
<ol>
<li>先保存自己的寄存器到调度器线程的context对象</li>
<li>找到进程P2之前保存的context，恢复其中的寄存器</li>
<li>因为进程 P2 在进入RUNABLE状态之前，如刚刚介绍的进程 P1 一样，必然也调用了swtch函数。所以之前的swtch函数会被恢复，并返回到进程 P2 所在的系统调用或者中断处理程序中（注，因为 P2 进程之前调用 swtch 函数必然在系统调用或者中断处理程序中）。</li>
<li>不论是系统调用也好中断处理程序也好，在从用户空间进入到内核空间时会保存用户寄存器到trapframe对象。所以当内核程序执行完成之后，trapframe中的用户寄存器会被恢复。</li>
<li>最后用户进程P2就恢复运行了。</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>调度器线程：每一个CPU都有一个完全不同的调度器线程。调度器线程也是一种内核线程，它也有自己的context对象。任何运行在CPU1上的进程，当它决定出让CPU，它都会切换到CPU1对应的调度器线程，并由调度器线程切换到下一个进程。</p>
<p><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec11-thread-switching-robert/11.4-xv6-thread-switching-2">没看懂，需要反复看！！！</a></p>
<h2 id="xv6-book-ch7"><a class="header" href="#xv6-book-ch7">xv6 book ch7</a></h2>
<p>三个问题：</p>
<ol>
<li>如何从一个进程切换到另一个进程？</li>
<li>如何对用户进程透明的强制切换？</li>
<li>许多 CPU 可能会在进程间并发切换，需要设计一个锁来避免竞争。</li>
<li>第四，当进程退出时，必须释放进程的内存和其他资源，但它自己不能做到这一切，因为它不能释放自己的内核栈，同时又在使用内核栈。</li>
<li>第五，多核机器的每个内核必须记住它正在执行的进程，这样系统调用就会修改相应进程的内核状态。</li>
</ol>
<h2 id="1-uthread-switching-between-threads-moderate"><a class="header" href="#1-uthread-switching-between-threads-moderate">1. Uthread: switching between threads (moderate)</a></h2>
<p>设计并实现用户级线程上下文切换机制，</p>
<p>有三个文件：</p>
<ol>
<li><code>user/uthread.c</code> 包含大多数用户级线程包，以及三个简单测试线程的代码。</li>
<li><code>user/uthread_switch.S</code></li>
<li><code>Makefile</code> 构建 uthread 程序</li>
</ol>
<p>任务：</p>
<ol>
<li>实现线程的保存和恢复。</li>
<li>线程之间的切换。</li>
</ol>
<p>通过 <code>make grade</code> </p>
<p>将代码添加下面两个文件中的函数</p>
<ul>
<li><code>user/uthread.c</code> 中的 thread_create() 和 thread_schedule()</li>
<li><code>user/uthread_switch.S</code> 中的 thread_switch()</li>
</ul>
<p>当 thread_schedule() 第一次运行给定线程时，该线程在自己的栈上执行传递给 thread_create() 的函数。</p>
<p>另一个目标是确保 thread_switch() 保存被切换线程的寄存器，恢复切换到线程的寄存器，并返回到后一个线程指令中最后停止的点。</p>
<p>必须决定保存/恢复寄存器的位置；修改 struct thread 以保存寄存器是一个很好的计划。</p>
<p>您需要在 thread_schedule 中添加对 thread_switch 的调用；您可以将需要的任何参数传递给thread_switch，但目的是将线程从t切换到 next_thread。</p>
<ol>
<li>thread_switch 只需要保存/还原被调用方保存的寄存器</li>
</ol>
<p>保存 callee-save register 中的内容。</p>
<ol start="2">
<li>
<p>在 <code>user/uthread.asm</code> 中可以看到 uthread 的汇编代码，这对于调试可能很方便。</p>
</li>
<li>
<p>为线程的结构体 <code>struct thread</code> 添加需要保存的 <code>struct context ctx;</code>。其中 context 从 <code>kernel/proc.h</code> 中复制，这些是需要保存的 callee 寄存器。</p>
</li>
</ol>
<p>保存到哪里？</p>
<ol start="2">
<li><code>thread_create()</code> 中更新寄存器 ra 和 sp 的值。</li>
</ol>
<p>ra 是什么？ sp 是什么？</p>
<ol start="3">
<li>
<p>在 <code>thread_schedule</code> 中调用 <code>thread_switch</code> 实现线程上下文切换。</p>
</li>
<li>
<p><code>thread_switch</code> 具体在 <code>user/uthread_switch.S</code> 中实现，可参考 <code>swtch.S</code></p>
</li>
</ol>
<p>输入 make grade </p>
<h2 id="2-using-threads-moderate"><a class="header" href="#2-using-threads-moderate">2. Using threads (moderate)</a></h2>
<p>多线程情况下同时对同一个桶执行插入操作的时候可能回导致数据丢失。</p>
<p>$ make ph
$ ./ph 1</p>
<p>创建互斥锁：</p>
<p>静态创建：<code>pthread_mutex_t lock[NBUCKET] = { PTHREAD_MUTEX_INITIALIZER };</code> </p>
<p>也可以用动态的方式创建 <code>pthread_mutex_init(&amp;locks[i], NULL);  //NULL为默认的互斥锁</code> 但是需要在main 函数中初始化。</p>
<p>然后对 insert 加互斥锁即可，get 的时候不会有问题。</p>
<h2 id="3-barriermoderate"><a class="header" href="#3-barriermoderate">3. Barrier(moderate)</a></h2>
<p>记录当前已经来临的线程，如果线程达到上限就唤醒所有线程然后释放锁，反之则使来临的线程沉睡，醒来后重新获取锁。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-lock"><a class="header" href="#lab-lock">Lab lock</a></h1>
<p>首先切换代码：</p>
<pre><code>$ git fetch
$ git checkout lock
$ make clean
</code></pre>
<p>前置内容：</p>
<pre><code>第6章：《锁》和相应的代码。
第3.5节：《代码：物理内存分配》
第8.1节至第8.3节：《概述》、《Buffer cache层》和《代码：Buffer cache》
</code></pre>
<h2 id="总结-3"><a class="header" href="#总结-3">总结</a></h2>
<p>在多核机器上并行性差的原因是因为锁的争用。</p>
<p>这个实验必须跑在多核机器上！</p>
<p>通过 kalloctest 可以判断锁的争夺次数，通过 usertests sbrkmuch 判断是否可以正常分配内存。确保通过 usertests 和 make grade 。</p>
<p>使用 cpuid 返回当前内核时需要关闭中断(push_off)，用完后再打开(push_off)。</p>
<p>锁优化的两个思路：</p>
<ol>
<li>能不共享就不共享。</li>
<li>非得共享就尽可能的降低锁的粒度。</li>
</ol>
<h2 id="memory-allocatormoderate"><a class="header" href="#memory-allocatormoderate">Memory allocator(moderate)</a></h2>
<p><code>user/kalloctest.c</code> 中三个进程的地址空间对kalloc和kfree的多次调用。</p>
<p>优化前锁的正用情况：</p>
<pre><code>$  kalloctest
start test1
test1 results:
--- lock kmem/bcache stats
lock: kmem: #fetch-and-add 14549 #acquire() 433016
lock: bcache: #fetch-and-add 0 #acquire() 1242
--- top 5 contended locks:
lock: proc: #fetch-and-add 94663 #acquire() 505245
lock: proc: #fetch-and-add 41749 #acquire() 505570
lock: proc: #fetch-and-add 31109 #acquire() 505573
lock: kmem: #fetch-and-add 14549 #acquire() 433016
lock: virtio_disk: #fetch-and-add 13668 #acquire() 114
tot= 14549
test1 FAIL
start test2
total free number of pages: 32499 (out of 32768)
</code></pre>
<p>重新设计 kalloc.c 降低对 kmem 锁的争用，从而提高并行性。</p>
<p>之前是对一个整个 freelist 直接上锁，一个 CPU 占用后就不能再用了。</p>
<blockquote>
<p>此处用到了第一个策略，能不共享就不共享。</p>
</blockquote>
<p>可以将 freelist 拆分，为每个 CPU 分配独立的 freelist 从而支持多个 CPU 同时申请内存，也就是并发。</p>
<p>除此之外可能存在某个 CPU 申请过猛的情况，也就是 freelist 不够用了，此时可以从别的 CPU 对应的 freelist 中借。</p>
<ol>
<li>修改 kmem 数据结构，改为数组实现，分别对应不同的 CPU 。</li>
<li>修改 kfree，之前是直接删，现在需要获得 cpuid ，而 hind 提及获取 cpuid 时需要关闭中断。</li>
<li>CPU 中 freelist 不够用了，可以从别的 freelist 中借。借有两种策略，一种是直接对着一个收割，另一种是均匀收割。均匀收割的话不数字不能太大，否则依旧存在锁征用。</li>
</ol>
<p>下面是 64 个块均匀收割的输出：</p>
<pre><code>--- lock kmem/bcache stats
lock: kmem_cpu_0: #fetch-and-add 41 #acquire() 577717
lock: kmem_cpu_1: #fetch-and-add 0 #acquire() 2358581
lock: kmem_cpu_2: #fetch-and-add 0 #acquire() 1973063
lock: kmem_cpu_3: #fetch-and-add 0 #acquire() 380552
lock: kmem_cpu_4: #fetch-and-add 0 #acquire() 380552
lock: kmem_cpu_5: #fetch-and-add 0 #acquire() 380552
lock: kmem_cpu_6: #fetch-and-add 0 #acquire() 380552
lock: kmem_cpu_7: #fetch-and-add 0 #acquire() 380552
</code></pre>
<p>下面是 32 个块均匀收割的输出：</p>
<pre><code>--- lock kmem/bcache stats
lock: kmem_cpu_0: #fetch-and-add 0 #acquire() 87445
lock: kmem_cpu_1: #fetch-and-add 0 #acquire() 174204
lock: kmem_cpu_2: #fetch-and-add 0 #acquire() 171477
lock: kmem_cpu_3: #fetch-and-add 0 #acquire() 55
lock: kmem_cpu_4: #fetch-and-add 0 #acquire() 55
lock: kmem_cpu_5: #fetch-and-add 0 #acquire() 55
lock: kmem_cpu_6: #fetch-and-add 0 #acquire() 55
lock: kmem_cpu_7: #fetch-and-add 0 #acquire() 55
</code></pre>
<p>显然在均匀收割的情况下，32 较为合理。</p>
<h2 id="buffer-cache-hard"><a class="header" href="#buffer-cache-hard">Buffer cache (hard)</a></h2>
<p>优化 Buffer cache 部分的锁征用问题。</p>
<p>和 kalloc 不同的是，kalloc 是一个 CPU 占用一个 freelist ，而此处则是一个 Buffer cache 可被多个 CPU 访问。所以不能从能不共享就不共享的角度来处理，而是从尽可能降低锁的粒度的角度处理。</p>
<p>此前是将一整个 Buffer cache 链表加锁。可以改为数组加链表，当两个进程同时访问数组的同一个位置时才加锁，这样可以细化锁的粒度，从而降低并发。</p>
<p>换成数组加链表：</p>
<ol>
<li>首先根据 dev 和 blockno 生成对应索引，查看对应桶中的是否存在 blockno 。</li>
<li>如果存在直接返回。</li>
<li>如果不存在就选择 LRU 节点删除。</li>
<li>取出每一个桶中的 LRU 节点(加锁)，遍历所有桶，寻找使用次数最少的节点驱逐。</li>
<li>然后根据 key 将待查找的节点加入桶中。</li>
</ol>
<p>存在的问题：</p>
<p>在多线程场景下，如果对单个链表加锁，去锁后不能保证之前取得的 LRU 节点依旧有效，因为在去锁后有可能别的节点调用该节点使得 LRU 节点更改。</p>
<p>解决方案：</p>
<p>在遍历桶的时候，如果桶中没有节点不可能成为 LRU 节点则直接释放锁，反之锁不释放始终保持。也就是之前锁的策略粒度太小出问题了，需要加大粒度。</p>
<p>存在的问题：</p>
<p>接下来是死锁的问题，两个进程同时保持并申请对方的资源时会导致死锁。上一个方案加大了锁的粒度进而导致了存在死锁的可能。</p>
<p>死锁的四个条件：</p>
<ol>
<li>互斥（一个资源在任何时候只能属于一个线程）</li>
<li>请求保持（线程在拿着一个锁的情况下，去申请另一个锁）</li>
<li>不剥夺（外力不强制剥夺一个线程已经拥有的资源）</li>
<li>环路等待（请求资源的顺序形成了一个环）</li>
</ol>
<p>可以通过释放待查找桶的锁来解决问题。但是存在多个进程同时申请获得多分缓存的情况。</p>
<p>可以将驱逐+重分配的过程限制为单线程。也就是乐观锁。</p>
<p>bget 的功能是，如果带查找的节点在缓存中那么直接返回，反之驱逐 LRU 节点。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-fs"><a class="header" href="#lab-fs">Lab fs</a></h1>
<p>首先切换分支：</p>
<pre><code>$ git fetch
$ git checkout fs
$ make clean
</code></pre>
<p>按照顺序看完下面的内容后再开始做实验，结合着代码来看，其实有很多重叠的内容，重点关注自己不理解的地方。</p>
<ol>
<li><a href="https://www.bilibili.com/video/BV19k4y1C7kA?p=13">lec13 视频</a></li>
<li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec14-file-systems-frans">lec13 视频文字版</a> </li>
<li><a href="http://xv6.dgs.zone/labs/requirements/lab9.html">lab 手册</a></li>
<li><a href="http://xv6.dgs.zone/tranlate_books/book-riscv-rev1/c8/s0.html">xv6 book Chapter 8 File system</a> </li>
</ol>
<h2 id="上述内容总结"><a class="header" href="#上述内容总结">上述内容总结</a></h2>
<p>七层文件系统：</p>
<ol>
<li>磁盘层在 virtio 磁盘上读写块。</li>
<li>Buffer cache 缓存磁盘块并同步访问，确保一个块只能同时被内核中的一个进程访问。
<ol>
<li>同步访问磁盘块，以确保磁盘块在内存中只有一个 buffer 缓存，并且一次只有一个内核线程能使用该 buffer 缓存；</li>
<li>缓存常用块，以便不需要从慢速磁盘重新读取它们。</li>
<li>bread 返回一个在内存中可以读取和修改的块副本 buf 。</li>
<li>bwrite 将修改后的 buffer 写到磁盘上相应的块。内核线程在使用完一个 buffer 后，必须通过调用 brelse 释放它。buffer cache 为每个 buffer 都设有 sleep-lock，以确保每次只有一个线程使用 buffer（从而使用相应的磁盘块）。bread 返回的 buffer 会被锁定，而 brelse 释放锁。</li>
<li>buffer cache 容量有限，用 LRU 来实现置换。</li>
<li>buffer 缓存是一个由 buffer 组成的双端链表。由函数 binit 用静态数组 buf 初始化这个 链表， binit 在启动时由 main(kernel/main.c:27)调用。访问 buffer 缓存是通过链表，而不是 buf 数组。</li>
<li></li>
</ol>
</li>
<li>日志层允许上层通过事务更新多个磁盘块，并确保在崩溃时，磁盘块是原子更新的（即全部更新或不更新）</li>
<li>索引结点层提供单独的文件，每个文件表示为一个索引结点，其中包含唯一的索引号（i-number）和一些保存文件数据的块。</li>
<li>目录层将每个目录实现为一种特殊的索引结点，其内容是一系列目录项，每个目录项包含一个文件名和索引号。</li>
<li>路径名层提供了分层路径名，如/usr/rtm/xv6/fs.c，并通过递归查找来解析它们。</li>
<li>文件描述符层用文件系统接口抽象了许多 Unix 资源（如管道、设备、文件等），使程序员的生产力得到大大的提高。</li>
</ol>
<h3 id="xv6-站在文件系统的角度来看磁盘"><a class="header" href="#xv6-站在文件系统的角度来看磁盘">XV6 站在文件系统的角度来看磁盘</a></h3>
<p>首先需要考虑磁盘的组成，站在文件系统的角度来看，磁盘可以看成一个字节数组，由 block 组成。</p>
<p>在 xv6 中一个 block 是 1024 字节，其中又由 2 个 sector 组成，那么一个 sector 就是 512 字节。</p>
<p>从数组的角度来看，整个磁盘可看成由 block 组成的数组。 </p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318135634.png" alt="20220318135634" /></p>
<ol>
<li>block0 被称为 boot block 其中要么不使用，要么存储的是启动 OS 的代码，通过这些程序使得 OS 代码能够加载到内存中。</li>
<li>block1 被称为 super block 其中中存储的是一些元数据，例如文件系统大小，数据块数量，inode 的数量。通过mkdfs 将该块写入，然后通过该块建立起初始的文件系统。</li>
<li>block2-31 被称为 log block  中存储的是日志信息，用来做崩溃恢复之类的工作。</li>
<li>block32 到 45 中存储的是 inode。一个 inode 是 64 byte，而一个 block 是 1024 byte，所以每个 block 中存储了多个 inode。inode 用来表示一个文件的元数据，代表一个文件对象，所以一个 inode 就是一个文件。通过一个整数来唯一标识一个文件，而非文件名。
<ol>
<li>其中 type 字段表明inode是文件还是目录。</li>
<li>nlink 字段，也就是link计数器，用来跟踪究竟有多少文件名指向了当前的inode。</li>
<li>size字段，表明了文件数据有多少个字节。</li>
<li>bn0 到 bn11，12 个指向 block 的指针，block 用来直接存数据。</li>
<li>bn12 也是指向 block 但这是一个二级索引，指向的 block 中存其他 block 的地址。其中一个索引是 4 字节，所以一共指向了 256 个 block 。所以空间上限是 (12 + 256)*1024 。</li>
<li>如果用来表示目录，目录由 entry 组成。前两个字节表示 inode 序号，后 14 个字节表示文件名。
<ol>
<li>例如根目录(<code>/</code>)的 inode 在编号 1 中，也就是 block32 的 64B 到 128B 中。</li>
<li>如果查找其他目录，例如目录 <code>/y</code> ，从 inode1 的 bn0 中开始扫描，如果找到文件中会包含 inode 编号，然后读取相应编号查看相应的 block 。</li>
<li>如果查看 <code>/y/x</code> 则从存储 <code>/y</code> indoe 编号开始继续从 bn0 开始遍历，直到找到 <code>/y/x</code> 对应的 indoe 编号。</li>
</ol>
</li>
</ol>
</li>
<li>block45 中存储的是 bitmap ，只占据一个block，用来判断数据块是否空闲，0 表示空闲，1 反之。</li>
<li>block46 之后就都是数据块了。</li>
</ol>
<p>通常 log，inode，bitmap 被称为元数据块。</p>
<h3 id="xv6-创建一个文件所经过的流程"><a class="header" href="#xv6-创建一个文件所经过的流程">XV6 创建一个文件所经过的流程</a></h3>
<p>分析 <code>echo “hi” &gt; x</code> 执行流程：</p>
<ol>
<li>创建文件
<ol>
<li>write 33 通过修改 inode 中的 type 字段表示将要被使用，这个字段同时也表示 inode 是文件还是目录。inode的type从空闲改成了文件，并写入磁盘表示这个inode已经被使用了</li>
<li>write 33 实际写入 inode 的内容。inode 的内容会包含 linkcount 为 1 以及其他内容。</li>
<li>write 46 向第一个 data block 写数据，这个 data block 属于根目录并且是根目录的第一个 block 。添加 x 的 entry 到根目录的 block 中。</li>
<li>write 32 block 32 保存的仍然是inode。更新了根目录的大小，因为我们刚刚添加了 16 个字节的 entry 来代表文件 x 的信息。</li>
<li>write 33 再次更新了文件 x 的 inode ，尽管还没有写入任何数据。</li>
</ol>
</li>
<li>将 &quot;hi&quot; 写入文件
<ol>
<li>write 45 更新 bitmap 。通过扫描bitmap来找到一个还没有使用的data block将对应的bit设置为1。</li>
<li>write 595 两次调用表明，文件系统挑选了data block 595。x 的 inode 中第一个direct block number是595。因为写入了两个字符，所以write 595被调用了两次。</li>
<li>write 33 更新inode的size，direct block number(595)，字段。因为现在文件 x 中有了两个字符。</li>
</ol>
</li>
<li>将 &quot;\n&quot; 写入文件
<ol>
<li>write 595</li>
<li>write 33</li>
</ol>
</li>
</ol>
<h2 id="large-filesmoderate"><a class="header" href="#large-filesmoderate">Large files(moderate)</a></h2>
<p>增加xv6文件的最大大小。</p>
<p>通过 <code>bigfile</code> 来判断是否创建成功，下面是创建失败的情况。</p>
<pre><code>$ bigfile
..
wrote 268 blocks
bigfile: file is too small
</code></pre>
<p>bigfile 将会创建一个包含 65803 个块的文件，但未修改的 xv6 将文件限制为 268 个块。</p>
<p>为了支持 65803 个块，目前一共 12 + 1 ，12 是直接地址，1 是间接地址。将 1 指向的块在此拆分变成二级间接块，即 256*256。</p>
<p>12 中再拆出一个间接块就够了，即 <code>256*256+256+11 = 65803</code> 。</p>
<p>读懂 fs.c 中的 bmap() 。</p>
<p>ip-&gt;addrs[]的前11个元素应该是直接块；第12个应该是一个一级间接块（与当前的一样）；13号应该是你的新二级间接块。</p>
<ol>
<li>修改 NDIRECT</li>
<li>修改 MAXFILE</li>
<li>修改 dinode ，dinode 是在磁盘中 inode 的结构。</li>
<li>修改 inode，inode 是在内存中的 inode 的机构。</li>
<li>需要重新生成 fs.img ，也就是先 make clean 再 make qemu 。</li>
<li>修改 bmap (一级改成二级就行)</li>
<li>修改 itrunc (同上)</li>
</ol>
<p>没啥难的，照着改就成。</p>
<h2 id="symbolic-linksmoderate"><a class="header" href="#symbolic-linksmoderate">Symbolic links(moderate)</a></h2>
<p>支持软连接，也就是为文件创建一个新名称。</p>
<p><code>symlink(char *target, char *path)</code> 例如 symlink(&quot;x/y&quot;,&quot;x/z&quot;); 为文件 <code>x/y</code> 创建 <code>x/z</code> 的文件名。</p>
<p>本质上是为 path 创建 inode ，将 target 写入 path 创建的 inode 中。</p>
<p>通过 sys_open 来创建文件， open 有两个参数，第一个参数是 path 表示文件的路径，第二个参数是 omode 表示权限，表示可读/可写/可执行。</p>
<p>sys_open 打开文件，需要处理递归遇到符号链接的情况。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-mmap"><a class="header" href="#lab-mmap">Lab mmap</a></h1>
<p>切换分支：</p>
<pre><code>$ git fetch
$ git checkout mmap
$ make clean
</code></pre>
<p>阅读：https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec17-virtual-memory-for-applications-frans</p>
<p>实现 mmap 和 munmap 并通过 mmaptest 测试程序。</p>
<ol>
<li>
<p>首先增加系统调用使得能够正常通过编译。</p>
</li>
<li>
<p>理解 mmap，munmap 形参及其作用，前者是建立映射，后者是消除映射。于在进程之间共享内存，将文件映射到进程地址空间。</p>
<pre><code>void *mmap(void *addr, size_t length, int prot, int flags,
           int fd, off_t offset);

int munmap(void *addr, size_t length);
</code></pre>
</li>
</ol>
<p>对于 mmap</p>
<ol>
<li>第一个参数是一个想映射到的特定地址，如果传入null表示不指定特定地址，这样的话内核会选择一个地址来完成映射，并从系统调用返回。此时假设 addr 是 0 。</li>
<li>第二个参数是想要映射的地址段长度 len。</li>
<li>第三个参数是 Protection bit ，例如读写R|W。</li>
<li>第四个参数暂时跳过不做讨论，它的值可以是 MAP_PRIVATE 。它指定了如果你更新了传入的对象，会发生什么。（注，第四个参数是flags，MAP_PRIVATE是其中一个值，在mmap文件的场景下，MAP_PRIVATE表明更新文件不会写入磁盘，只会更新在内存中的拷贝，详见man page）。</li>
<li>第五个参数是传入的对象，在上面的例子中就是文件描述符。</li>
<li>第六个参数是 offset。</li>
</ol>
<p>具体作用是将文件描述符中指向的文件内容，根据起始地址加上 offset 开始,映射 len 长度，将这块区域映射到特定的内存地址上。然后只需要通过指针就可以访问，而不用通过 read/write 系统调用就可以直接从磁盘读取文件内容。这个接口可以用来操纵存储在文件中的数据结构。</p>
<p><a href="https://www.cnblogs.com/huxiao-tee/p/4660352.html">mmap 和常规文件操作的区别，或者说优势？</a></p>
<blockquote>
<p>总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高。</p>
</blockquote>
<p>mmap 还可以用作他途。除了可以映射文件之外，还可以用来映射匿名的内存（Anonymous Memory）。这是sbrk（注，详见8.2）的替代方案，你可以向内核申请物理内存，然后映射到特定的虚拟内存地址。</p>
<p>对于 munmap</p>
<pre><code>   int munmap(void *addr, size_t length);
</code></pre>
<p>功能是消除从 addr 开始，长度为 length 地址之间的映射。</p>
<ol start="3">
<li>实现惰性加载(lab5)。也就是当真正需要的时候才进行映射，此处调用 vmatrylazytouch 函数。
<ol>
<li>首先获取当前进程，根据进程和传进来的虚拟地址拿到对应的 vma 。</li>
<li>申请一块内存用于存放从 inode 中读取的数据。</li>
<li>设置标志位然后建立映射。</li>
</ol>
</li>
<li>定义 vma 结构体，在进程的结构体中定义 vma 数组，因为没有内存分配器所以先定义 16 个空槽来用。</li>
<li>实现 munmap ， 取消从 addr 开始，长度为 sz 的内存映射。
<ol>
<li>文档中调用 uvmunmap， 重写 uvmunmap 增加脏页写回磁盘的处理。</li>
</ol>
</li>
<li>修改 fork 父子进程共享 vma 且要增加 vma 的引用计数。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-net"><a class="header" href="#lab-net">Lab net</a></h1>
<p>https://pdos.csail.mit.edu/6.S081/2020/labs/net.html</p>
<p>实现一个网络接口的驱动程序。</p>
<p>切换分支</p>
<pre><code>$ git fetch
$ git checkout net
$ make clean
</code></pre>
<h2 id="总结-4"><a class="header" href="#总结-4">总结</a></h2>
<p>数据包到达后写入网卡，然后将数据包复制到内存中。</p>
<p>网卡需要知道将数据写到哪里。DMA 环是一个数据包缓冲区的指针数组，其中存储的是缓冲区的指针，通过该指针拿到真正存储数据的地址。RX 环和 DMA 环类似，只不过是用来发送数据的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318135709.png" alt="20220318135709" /></p>
<p>用 E1000 来处理网络通信，站在 xv6 的角度来看 E1000 是一个和真正以太网(LAN)相连的硬件。但实际上 E1000 和 LAN 都是由 qmeu 提供。在这个网络中 xv6 的 IP 地址是 10.0.2.15 。在这个 LAN 上还存在一个地址是 10.0.2.2 的 IP。当 XV6 使用 E1000 向 10.0.2.2 发数据时，qemu 将会复制将数据发送出去。</p>
<p>使用 qmeu 用户模式下的网络栈。 </p>
<p><code>packets.pcap</code> 文件中记录了待发送和待接收的数据。通过命令 <code>tcpdump -XXnr packets.pcap</code> 可查看。</p>
<p><code>kernel/e1000.c</code> 包含了 E1000 初始化代码以及两个待填充的空函数(transmitting,receiving)。</p>
<p><code>kernel/e1000_dev.h</code> 包含了一些 E1000 寄存器和标志位的定义。</p>
<p><code>kernel/net.c </code> 和 <code>kernel/net.h </code> 包含了一些简单网络协议的实现以及表示一个报文的数据结构(mbuf) </p>
<p><code>kernel/pci.c</code> 包含的代码用于 xv6 启动时搜索 PCI 总线上的 E1000 卡。</p>
<h2 id="your-job-hard"><a class="header" href="#your-job-hard">Your Job (hard)</a></h2>
<p>实现 <code>kernel/e1000.c</code> 中的发送数据(e1000_transimit)和接收数据(e1000_recv)的代码。并通过 <code>make grade</code> 。</p>
<p>头节点和尾节点可以结合着这张图来考虑。</p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318135850.png" alt="20220318135850" /></p>
<h3 id="实现-e1000_transmit"><a class="header" href="#实现-e1000_transmit">实现 e1000_transmit</a></h3>
<p>首先要明确的是 e1000_transmit 负责将输入的数据报塞入缓冲区中。</p>
<p>e1000_transimit 函数的输入是 mbuf ，mbuf 表示一个数据帧。内存中维护了一个环形队列(tx_ring),其中 E1000_TDH 作为队头指针，E1000_TDT 作为队尾指针。将 mbuf 塞入环形队列中。</p>
<ol>
<li>首先获取根据 E1000_TDT 获取到下一个可用位置的索引。</li>
<li>根据索引拿到状态描述符(tx_desc)，检查 status 和 E1000_TXD_STAT_DD 判断该位置是否能用。</li>
<li>判断当前缓冲区中之前遗留的数据是否已经被释放，如果没有就释放一下(mbuffree)。</li>
<li>将输入的 mbuf 加入缓冲区中并更新状态。</li>
<li>tail 下标加一。</li>
</ol>
<h3 id="实现-e1000_recv"><a class="header" href="#实现-e1000_recv">实现 e1000_recv</a></h3>
<p>读取缓冲区中的数据</p>
<ol>
<li>进最大可能处理完所能处理的缓冲区，所以需要一个循环。</li>
<li>获取下标，根据下标获取对应缓冲区的描述符并判断是否合法。</li>
<li>更新状态并传递给上层网络栈(net_rx)。</li>
<li>数据已经传走了，更新当前缓冲区。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="从零实现关系型数据库"><a class="header" href="#从零实现关系型数据库">从零实现关系型数据库</a></h1>
<h2 id="1-什么是关系型数据库"><a class="header" href="#1-什么是关系型数据库">1. 什么是关系型数据库？</a></h2>
<p>关系型数据库（RDBMS，Relational Database Management System）是一种以表格（表格也被称为关系）的形式来组织和存储数据的数据库管理系统。在关系型数据库中，数据以行和列的形式存储在表格中，每个表格都具有一个特定的结构，包括列的名称、数据类型和行的数据。这些表格之间可以建立关系，从而允许数据在不同表格之间进行关联和查询。</p>
<p>关系型数据库的主要特点包括：</p>
<ol>
<li>
<p>结构化数据：数据以表格形式存储，每列都有明确定义的数据类型，这使得数据具有高度的结构性，适用于复杂的查询和分析。</p>
</li>
<li>
<p>数据完整性：关系型数据库支持各种数据完整性约束，如主键、外键、唯一性约束等，以确保数据的一致性和完整性。</p>
</li>
<li>
<p>SQL语言：关系型数据库使用结构化查询语言（SQL）进行数据操作和查询。SQL提供了强大的查询能力，允许用户执行各种复杂的数据操作。</p>
</li>
<li>
<p>ACID属性：关系型数据库遵循ACID（原子性、一致性、隔离性和持久性）属性，确保数据库操作是可靠的、一致的和持久的。</p>
</li>
<li>
<p>多用户支持：关系型数据库可以同时支持多个用户访问和操作数据，提供了良好的并发控制机制，以防止数据冲突和数据损坏。</p>
</li>
<li>
<p>数据表之间的关联：关系型数据库允许在不同表格之间建立关联，通过主键和外键等机制实现数据的关联和连接，从而支持复杂的查询和数据分析。</p>
</li>
<li>
<p>可扩展性：关系型数据库可以通过添加新表格、索引、视图等来扩展数据模型，以满足不断变化的需求。</p>
</li>
</ol>
<p>一些常见的关系型数据库系统包括MySQL、Oracle Database、Microsoft SQL Server、PostgreSQL、SQLite等。这些数据库系统在企业应用、数据分析、网站开发等各种领域都有广泛的应用。</p>
<h2 id="2-关系型数据库由哪几部分组成"><a class="header" href="#2-关系型数据库由哪几部分组成">2. 关系型数据库由哪几部分组成？</a></h2>
<p>一个关系型数据库通常由以下几个主要部分组成：</p>
<ol>
<li>
<p>数据表（Tables）：数据表是数据库中的核心组成部分，用于存储数据。每个数据表包含多个列和行，列定义了数据的属性，行包含实际的数据记录。</p>
</li>
<li>
<p>列（Columns）：列定义了数据表中存储的数据的属性。每列有一个名称和数据类型，用于规定存储在该列中的数据的格式。</p>
</li>
<li>
<p>行（Rows）：行是数据表中的数据记录。每行包含一组数据，每个数据都对应于该行中各个列的值。</p>
</li>
<li>
<p>主键（Primary Key）：主键是一列或一组列，用于唯一标识数据表中的每个行。主键确保每行都有一个唯一的标识符，有助于数据的唯一性和快速检索。</p>
</li>
<li>
<p>外键（Foreign Key）：外键是一个或多个列，用于建立不同数据表之间的关联。外键与其他表的主键相对应，用于维护表之间的引用完整性和关联。</p>
</li>
<li>
<p>索引（Indexes）：索引是用于加速数据检索的数据结构。它们允许数据库系统快速查找数据表中的特定行，减少查询的时间复杂度。</p>
</li>
<li>
<p>触发器（Triggers）：触发器是一段预定义的代码，可以在特定的数据库操作（如插入、更新或删除数据）发生时自动触发执行。</p>
</li>
<li>
<p>存储过程（Stored Procedures）：存储过程是一组SQL语句的集合，可以在数据库中保存和重复使用。它们提供了一种在数据库内部执行操作的方法，可以提高性能和安全性。</p>
</li>
<li>
<p>视图（Views）：视图是虚拟表，由一个或多个数据表的查询结果组成。它们允许用户以一种简化的方式访问和操作数据，而无需直接访问底层表。</p>
</li>
<li>
<p>事务（Transactions）：事务是一组数据库操作，要么全部执行成功，要么全部失败。它们用于确保数据的一致性和完整性，支持ACID（原子性、一致性、隔离性和持久性）属性。</p>
</li>
<li>
<p>查询语言（Query Language）：关系型数据库使用结构化查询语言（SQL）来执行数据查询、插入、更新和删除等操作。</p>
</li>
</ol>
<p>这些是关系型数据库的基本组成部分，不同的关系型数据库管理系统（如MySQL、Oracle、SQL Server、PostgreSQL等）可能会有一些特定的功能和特性。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="从-table-开始"><a class="header" href="#从-table-开始">从 Table 开始</a></h1>
<p>在关系型数据库中，Table 是一个很重要的概念，由行和列组成。可以将 Table 当做二维数组，Excel 也是 Table 。而 Table 是由一行一行数据组成的，一行数据就是 Tuple 。</p>
<h2 id="1-tupledesc-实现"><a class="header" href="#1-tupledesc-实现">1. TupleDesc 实现</a></h2>
<p>在关系型数据库中，&quot;Tuple&quot;（元组）是指数据库表格中的一行数据记录。每个元组都表示表格中的一个特定数据项或记录，通常由一组值组成，这些值对应于表格的不同列。元组在关系型数据库中是数据的基本单元，它们用于存储和表示实际的数据。</p>
<p>以下是一个示例，展示了一个名为 &quot;Employees&quot; 的数据库表格中的两个元组：</p>
<pre><code>| EmployeeID | FirstName | LastName | Department |
|------------|-----------|----------|------------|
| 1          | John      | Smith    | HR         |
| 2          | Jane      | Doe      | IT         |
</code></pre>
<p>在上面的示例中，每一行都是一个元组，包含了关于员工的信息。每个元组由一组列（EmployeeID、FirstName、LastName、Department）的值组成。元组是关系型数据库中数据的基本单位，查询语言（如SQL）用于操作和检索这些元组，以执行各种数据操作和查询。</p>
<p>接下来研究怎么用代码来表示一张表的表头，即 TupleDesc 。</p>
<pre><code>| EmployeeID | FirstName | LastName | Department |
|------------|-----------|----------|------------|
| 1          | John      | Smith    | HR         |
| 2          | Jane      | Doe      | IT         |
</code></pre>
<p>设计成结构体的话需要两部分组成，即名称和类型。例如 EmployeeID 的类型是 int ，而名称为 EmployeeID 。所以结构体可以设计成下面这样：</p>
<pre><code class="language-go">// TDItem describes a field in a tuple schema.
type TDItem struct {
	FieldType int   // Field type
	FieldName string // Field name
}
</code></pre>
<p>但是因为 FieldType 不仅仅是 int ，还存在其他类型，例如上面的表中 FirstName 类型是 string 。所以需要引入一个新的变量来表示不同类型，修改后的代码如下：</p>
<pre><code class="language-go">// Type represents a types.
type Type int

// Constants for different types.
const (
	INT_TYPE Type = iota
	STRING_TYPE
)

// TDItem describes a field in a tuple schema.
type TDItem struct {
	FieldType Type   // Field type
	FieldName string // Field name
}
</code></pre>
<p>上面已经可以表示出来一个列名了，但是一个 Table 存在多列，所以需要一个数组来存放多个列明，即 TupleDesc ，代码如下：</p>
<pre><code class="language-go">// TupleDesc describes the schema of a tuple, including a list of fields.
type TupleDesc struct {
	Items []TDItem // List of fields
}
</code></pre>
<p>TupleDesc 结构体已经设计好了，还需要实现对应的构造函数以及相应的方法，函数接口如下，可以考虑自行实现。</p>
<pre><code class="language-go">// NewTupleDesc creates a TupleDesc with anonymous fields.
// It takes an array of Type (field types) as input and returns the newly created TupleDesc.
// If the lengths of the type and field name arrays do not match, it returns an error.
func NewTupleDesc(typeAr []Type) (*TupleDesc, error)

// NewTupleDescWithNames creates a new TupleDesc.
// It takes two arrays as input: an array of Type (field types) and an array of strings (field names).
// It returns the newly created TupleDesc or an error if the lengths of the type and field name arrays do not match.
func NewTupleDescWithNames(typeAr []Type, fieldAr []string) (*TupleDesc, error)

// NumFields returns the number of fields in the schema.
func (td *TupleDesc) NumFields() int

// GetFieldName gets the field name based on the field index.
// It takes an integer (field index) as input and returns the field name or an error if the index is out of bounds.
func (td *TupleDesc) GetFieldName(i int) (string, error)

// GetFieldType gets the field type based on the field index.
// It takes an integer (field index) as input and returns the field type or an error if the index is out of bounds.
func (td *TupleDesc) GetFieldType(i int) (Type, error)

// FieldNameToIndex gets the field index based on the field name.
// It takes a string (field name) as input and returns the field index or an error if the name is not found.
func (td *TupleDesc) FieldNameToIndex(name string) (int, error) 

// GetSize returns the size of the tuple in bytes.
func (td *TupleDesc) GetSize() int

// Merge combines two TupleDesc instances and returns a new TupleDesc.
func (td1 *TupleDesc) Merge(td2 *TupleDesc) *TupleDesc 

// Equals compares two TupleDesc instances for equality.
func (td1 *TupleDesc) Equals(td2 *TupleDesc) bool 

// String returns the string representation of the TupleDesc.
func (td *TupleDesc) String() string
</code></pre>
<h2 id="2-tuple-实现"><a class="header" href="#2-tuple-实现">2. Tuple 实现</a></h2>
<p>接下来研究如何设计 Tuple ，首先需要一个数组来存放数据，可以起名为 Field ，可以设计成一个接口，因为存在很多类型，例如 int、String 等。此外还需要一个指向 TupleDesc 的指针，最后还需要一个 id 用来标识 tuple 。</p>
<p>综上，结构体可以设计成下面的样子：</p>
<pre><code class="language-go">// Tuple represents a tuple containing fields that conform to the TupleDesc.
type Tuple struct {
	tupleDesc *TupleDesc
	recordId  *RecordId
	fields    []Field
}
</code></pre>
<p>接下来需要实现对应的构造函数，RecordId 和 Field 后续会讲解，此处先跳过。</p>
<pre><code class="language-go">// NewTuple creates a new tuple with the specified TupleDesc.
func NewTuple(td *TupleDesc) *Tuple {
	return &amp;Tuple{
		tupleDesc: td,
		fields:    make([]Field, td.NumFields()),
	}
}
</code></pre>
<p>接下来实现对应的方法：</p>
<pre><code class="language-go">// GetTupleDesc returns the TupleDesc associated with this tuple.
func (t *Tuple) GetTupleDesc() *TupleDesc

// GetRecordId returns the RecordId associated with this tuple.
func (t *Tuple) GetRecordId() *RecordId

// SetRecordId sets the RecordId associated with this tuple.
func (t *Tuple) SetRecordId(rid *RecordId) 

// SetField sets the field at the specified index in the tuple.
func (t *Tuple) SetField(i int, f Field)

// GetField returns the field at the specified index in the tuple.
func (t *Tuple) GetField(i int) Field 

// toString returns a string representation of the tuple, including its TupleDesc and fields.
func (t *Tuple) toString() string 

// Fields returns the fields stored in this tuple.
func (t *Tuple) Fields() []Field 

// ResetTupleDesc updates the TupleDesc associated with this tuple.
func (t *Tuple) ResetTupleDesc(td *TupleDesc)
</code></pre>
<h2 id="3-recordid"><a class="header" href="#3-recordid">3. RecordId</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-2-实现-tuple"><a class="header" href="#part-2-实现-tuple">Part 2. 实现 Tuple</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-3-实现-page"><a class="header" href="#part-3-实现-page">Part 3. 实现 Page</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-4-实现-heapfile"><a class="header" href="#part-4-实现-heapfile">Part 4. 实现 HeapFile</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-5-实现-bufferpool"><a class="header" href="#part-5-实现-bufferpool">Part 5. 实现 BufferPool</a></h1>
<p>Buffer Pool（缓冲池）是数据库管理系统（DBMS）中的一个关键组件，用于管理和优化数据库的内存访问。它是在内存和磁盘之间提供了一个缓冲层，以改善数据库的性能。以下是关于Buffer Pool的一些重要信息：</p>
<ol>
<li>
<p><strong>缓冲池的作用</strong>：数据库中的数据通常存储在磁盘上，但磁盘访问速度相对较慢。为了提高数据库的查询和更新性能，DBMS会使用缓冲池将最常用的数据页（数据块）缓存在内存中。这样，当查询需要访问数据时，可以首先尝试从缓冲池中获取，而不必每次都从磁盘读取数据。</p>
</li>
<li>
<p><strong>数据页缓存</strong>：缓冲池通常以数据页（通常是固定大小的块）为单位来管理内存。当数据库需要访问数据页时，它首先检查缓冲池中是否已经有了该数据页的副本。如果有，它就可以直接从内存中获取数据，而不必执行磁盘读取操作。</p>
</li>
<li>
<p><strong>替换策略</strong>：缓冲池具有有限的内存容量，因此必须根据某种策略来管理哪些数据页应该留在缓冲池中，哪些应该被替换出去。常见的替换策略包括最近最少使用（LRU，Least Recently Used）和最不常使用（LFU，Least Frequently Used）等。</p>
</li>
<li>
<p><strong>脏页管理</strong>：当数据库执行写操作时，会涉及到修改数据页的内容。这些被修改但尚未写回磁盘的数据页称为&quot;脏页&quot;。缓冲池需要跟踪和管理这些脏页，并在适当的时候将其刷新（写回）到磁盘以保持数据的一致性。</p>
</li>
<li>
<p><strong>性能优化</strong>：通过合理配置缓冲池的大小以及选择适当的替换策略，DBMS可以显著提高查询性能。合理的缓冲池管理可以减少对磁盘的频繁访问，从而减少了I/O延迟，提高了数据库的整体性能。</p>
</li>
</ol>
<p>总之，Buffer Pool是数据库管理系统中用于管理内存和磁盘之间数据访问的关键组件。它通过在内存中缓存最常用的数据页来提高查询性能，并通过适当的替换策略和脏页管理来优化数据库的性能和一致性。</p>
<h2 id="1-如何实现-bufferpool-"><a class="header" href="#1-如何实现-bufferpool-">1. 如何实现 BufferPool ？</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-6-实现-catalog"><a class="header" href="#part-6-实现-catalog">Part 6. 实现 Catalog</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="part-7-实现-catalog"><a class="header" href="#part-7-实现-catalog">Part 7. 实现 Catalog</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="6830-database-systems-spring-2021"><a class="header" href="#6830-database-systems-spring-2021">6.830 Database Systems Spring 2021</a></h1>
<p>课程主页：http://dsg.csail.mit.edu/6.830/</p>
<p>本地有测试，gradescope 没有开放。</p>
<p>建议 JDK 1.8 ，不要求具体平台。</p>
<p>直接 IEDA 打开就行。</p>
<p>接下来是 6 个 lab 实验手册的翻译。</p>
<ul>
<li>lab1：Tuple/HeapFile等基础设施</li>
<li>lab2：查询算子 Join/GroupBy 等</li>
<li>lab3：查询优化</li>
<li>lab4：事务锁和死锁</li>
<li>lab5：B+树增删</li>
<li>lab6：回滚和恢复</li>
</ul>
<p>首先下载代码：<code>git clone https://github.com/MIT-DB-Class/simple-db-hw-2021</code></p>
<p>然后 IDEA 打开，接下来阅读 lab1.md 。</p>
<p>前面 ant 的讲解目前用不到，快速扫一遍就行。</p>
<p>一些要注意的点：</p>
<ol>
<li>先看对应测试类，看明白测试逻辑后再开始写，通过逐个测试。（有种升级打怪的感觉🤣）</li>
<li>仔细阅读注释，注释有很多提示信息。</li>
<li>文档建议环境 JDK 1.8 ，因为 Java 所以不限制平台，windows 上也能做。</li>
<li>本地测试不全，GradeScope 不开放。感觉这个影响不大，课程的要求是搞定本地测试即可。</li>
<li>有一些术语直译的话难以理解，建议直接搜英文原意。</li>
<li>测试分为普通测试和系统测试，系统测试在 test/simpledb/systemtest 文件夹下，普通测试在 test/simpledb/ 目录下。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-1-simpledb"><a class="header" href="#lab-1-simpledb">Lab 1: SimpleDB</a></h1>
<p>直接 IDEA 打开，等待加载。快速扫一遍搞清楚怎么测试，如何验证代码正确就行。</p>
<p>我没有安装 ant ，用 IDEA 打开后就自动加载进来了。</p>
<p><img src="6.830/ans/image/2-lab1/1647090442719.png" alt="" /></p>
<h2 id="exercise-1"><a class="header" href="#exercise-1">Exercise 1</a></h2>
<p>实现下面的两个方法并通过单元测试 TupleTest 和 TupleDescTest 。</p>
<ul>
<li>src/java/simpledb/storage/TupleDesc.java</li>
<li>src/java/simpledb/storage/Tuple.java</li>
</ul>
<p>一个 Tuple 对象表示一行数据，一个 TupleDesc 对象表示数据的表头。</p>
<p>TupleDesc 表示表头，其中有一个 TDItem 队列，而 TDItem 表示一个属性，其中有 fieldType 和 fieldName 两个字段。例如学生的姓名属性，其中 fieldName 就是姓名，因为姓名是字符串而 fieldType 就是字符串。</p>
<p>接下来研究 fieldType，这是一个 Type 对象，点进去后发现分为 INT_TYPE 和 STRING_TYPE 类型。</p>
<p>Field 是一个接口，实现了 String 和 Int 。</p>
<h2 id="exercise-2"><a class="header" href="#exercise-2">Exercise 2</a></h2>
<p>实现 <code>common/Catalog.java</code> 并通过 CatalogTest .</p>
<p>接下来研究 Catalog 类，其中实现了一个 Table 内部类，这个类维护了多张表。Catalog 存了一堆表，目前是通过程序来填充表，最终将会实现从磁盘中读取表的功能。</p>
<p>看明白测试再写 <code>Catalog.java</code> 。写一个 Table 类（类似 TDItem），内部包含 file，name，pkeyField 三个字段，用容器来存 Table 。</p>
<p>Table 表示一张表，其中有三个属性，分别是 file，name 和 pkeyField 。其中 pkeyField 表示主键，name 表示表的名字，而 file 则是一个 DbFile 对象。</p>
<p>然后用 HashMap 来存，其中 <code>key: file.getId()</code>，<code>value:Table</code>。接下来实现几个方法就行了。</p>
<p>注意重名的处理，如果有就删除再添加。</p>
<p>接下来研究 DbFile ，这是一个接口，可由 HeapFile 和 B+ 树实现。目前是 HeapFile，其中存了一堆 Tuple 。</p>
<p>接下来研究 HeapFile 的结构。</p>
<h2 id="exercise-3"><a class="header" href="#exercise-3">Exercise 3</a></h2>
<p>实现文件中的 getPage() 方法:</p>
<ul>
<li>src/java/simpledb/storage/BufferPool.java</li>
</ul>
<p>用 ConcurrentHashMap （HashMap 存在并发问题，不过本地测试没有体现）来存 page，其中 key 和 value 分别是 PageId 和 Page 。</p>
<p><code>getPage()</code> 首先根据 pid 判断是否已经缓存，如果没有缓存再调用 Database.getCatalog() 方法去 Catalog 中加载。加载后依旧缓存一下。</p>
<p>DbFile 接口实现了和磁盘读写之间的读写 page ，插入删除 tuple 等功能。</p>
<p>一个 DbFile 中存了一个 table ，数据库中的 Table 和 DbFile 是对应。</p>
<p>HeapFile 是 DbFile 的一种实现。除此之外还有 B-trees 实现，此处仅需由 heap file 提供即可。</p>
<p>一个 HeapFile 中存了一个 Page 集合，HeapPage 是 Page 的一种实现，其中每一个 page 都存有固定数量(BufferPool.DEFAULT_PAGE_SIZE) 的 tuple 。</p>
<p>HeapFile 中的每一页(page)都有一组槽(slot)，每一个 slot 中“嵌入”一个 tuple 。此外，每一个 page 除了 slot 之外还有 head 部分，head 部分用来存 page 中的 slot 是否被使用。</p>
<p>数据库中的 block 对应此处的 HeapFile，而在内存中数据以 Page 为单位。</p>
<h2 id="exercise-4"><a class="header" href="#exercise-4">Exercise 4</a></h2>
<p>实现 <code>storage/HeapPageId.java</code>,<code>storage/RecordId.java</code> 和 <code>storage/HeapPage.java</code> 三个类并通过 HeapPageIdTest、RecordIDTest 和 HeapPageReadTest 的单元测试。</p>
<p>照着测试类可以很轻松的把前两个解决，第三个需要仔细研究文档。</p>
<p>HeapFile 中存了一组 Page ，而 Page 中存 tuple 。在数据库中一张 table 对应一个 Heap File 。 </p>
<p>接下来研究 HeapFile 的文件结构。在 HeapFile 分为 head 和 slot 两部分，slot 对应一个 tuple ，注意此处的 tuple 长度相同。而 head 则是 bitmap ，用于表示 slot 是否被使用，0 表示没有被用， 1 表示已经被使用了。</p>
<p><code>_tuples per page_ = floor((_page size_ * 8) / (_tuple size_ * 8 + 1)) </code></p>
<p>其中 <code>_page size_ * 8</code> 表示一页需要多少二进制位，<code>_tuple size_ * 8 + 1</code> 表示一个 tuple 占多少二进制位。除此之外，一个 tuple 存在与否也占一个二进制位，所以加一。二者做除法就是一页上可以存放多少 tuple 。</p>
<p>根据页面的 tuple 数字可以确定 bitmap 的个数。<code>headerBytes = ceiling(tupsPerPage/8)</code></p>
<p>接下来就可以实现 <code>getNumTuples()</code> <code>getHeaderSize()</code> 这两个方法了。注意迭代器中需要过滤，将 null 消除。</p>
<h2 id="exercise-5"><a class="header" href="#exercise-5">Exercise 5</a></h2>
<p>实现下面类中的方法。</p>
<p>src/java/simpledb/storage/HeapPageId.java
src/java/simpledb/storage/RecordId.java
src/java/simpledb/storage/HeapPage.java</p>
<p>实现 <code>storage/HeapFile.java</code> 这个类其中 <code>readPage()</code> 实现有些复杂。</p>
<p>从磁盘上读取一个页面。大致思路如下：首先确定偏移值（页数乘单页大小），然后初始化一张空 page ，最后根据偏移值将空 page 填满。 最后跑通 HeapFileReadTest 这个类。</p>
<h2 id="exercise-6"><a class="header" href="#exercise-6">Exercise 6.</a></h2>
<p>实现 <code>execution/SeqScan.java</code> 并通过 <code>systemtest/ScanTest.java</code> 。</p>
<p>BufferPool 需要支持缓存。</p>
<h2 id="a-simple-query"><a class="header" href="#a-simple-query">A simple query</a></h2>
<p>总结：Catalog 中有多个 table，一个 table 对应一个 DbFile ，HeapFile 中存了多个 Page，一个 Page 中有一个 head 和多个 slot ，一个 slot 存一个 tuple。</p>
<p>HeapFile 是 DbFile 的一种实现方式，除此之外还有 BTreeFile 。</p>
<p>执行一个简单的查询将各个部分连接到一起。创建一个文件 (some_data_file.txt) 内容如下：</p>
<p>1,1,1
2,2,2 
3,4,4</p>
<p>编译 <code>dist/simpledb.jar</code> 如下图：</p>
<p><img src="6.830/ans/image/index/1643904391084.png" alt="" /></p>
<p>其中 <code>java -jar dist/simpledb.jar convert some_data_file.txt 3</code> 3 表示输入的数据有三列。键入该命令后生成 <code>some_data_file.dat</code> 文件。</p>
<p>接下来研究 <code>test</code> 中的代码。</p>
<p>首先创建一个 3 列的 TupleDesc 对象，然后读取 <code>some_data_file.dat</code> 生成 HeapFile 对象也就是 Table 。然后将 Table 加入到 Catalog 中。</p>
<p>完成数据库系统的初始化后，接下来创建一个查询计划。该计划由<code>SeqScan</code>操作符组成，从磁盘上扫描 tuple 然后在命令行中输出。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-2-simpledb-operators"><a class="header" href="#lab-2-simpledb-operators">Lab 2: SimpleDB Operators</a></h1>
<p>这个 lab 大致要实现。</p>
<ul>
<li>
<p>实现 Filter 和 Join ，已经提供了 Project 和 OrderBy 的实现。</p>
</li>
<li>
<p>实现 StringAggregator 和 IntegerAggregator 。编写计算一个特定字段在输入 tuple 序列的多个组中的聚合。其中 IntegerAggregator 使用整数除法来计算平均数，因为 SimpleDB 只支持整数。StringAggegator 只需要支持 COUNT 聚合，因为其他操作对字符串没有意义。</p>
</li>
<li>
<p>实现<code>Aggregate</code>操作符。和其他运算符一样，聚合运算符实现了 <code>OpIterator</code> 接口，这样它们就可以放在 SimpleDB 查询计划中。注意<code>Aggregate</code>运算符的输出是每次调用<code>next()</code>时整个组的聚合值，并且聚合构造器需要聚合和分组字段。</p>
</li>
<li>
<p>实现<code>insert</code>和<code>delete</code>操作符。像所有的操作符一样，<code>Insert</code>和<code>Delete</code>实现了<code>OpIterator</code>，接受一个要插入或删除的 tuple 流，并输出一个带有整数字段的单一 tuple ，表示插入或删除的 tuple 数量。这些操作者将需要调用<code>BufferPool</code>中的适当方法，这些方法实际上是修改磁盘上的页面。检查插入和删除 tuple 的测试是否正常工作。</p>
</li>
<li>
<p>实现 BufferPool 中的页面置换策略(LRU) 。</p>
</li>
</ul>
<h2 id="exercise-1-1"><a class="header" href="#exercise-1-1">Exercise 1</a></h2>
<p>实现 <code>execution/Predicate.java</code>,<code>execution/JoinPredicate.java</code>,<code>execution/Filter.java</code> 和 <code>execution/Join.java</code> 并通过 PredicateTest、JoinPredicateTest、FilterTest 和 JoinTest 中的单元测试。此外，还需通过系统测试 FilterTest 和 JoinTest。</p>
<p>Filter，Join，Project 和 OrderBy 都是数据库中常见的算子(operator)。</p>
<p>已经提供了 Project 和 OrderBy 的实现，实现 Filter 和 Join 。</p>
<p>Project 是投影的意思。使用 <code>SELECT *</code> 表示查询表的所有列，使用 <code>SELECT 列1, 列2, 列3</code> 则可以仅返回指定列，这种操作称为投影。研究一下 Project 类就会发现其实就选择指定列输出。</p>
<p>OrderBy 表示按照指定字段排序输出结果集。</p>
<p>接下来实现 Filter 直译是过滤的意思，将符合条件的留下，所以需要一个判断语句。而判断也就是 Predicate 直译是谓词，第一次看到这个意思我是迷茫的，其实本质上就是一个真或假的表达式。准确的定义解释是：A predicate is an expression that evaluates to True or False 。 </p>
<p><code>Predicate.java</code> 比较表内的字段和提供的数据，三个参数分别是待比较的字段序号、比较符和待比较的数。其中 <code>filter()</code> 方法输入一个 Tuple ，然后比较 Tuple 的 Field 是否符合预期。</p>
<p><code>JoinPredicate.java</code> 和 <code>Predicate.java</code> 类似，只是实现两个 Tuple 的比较。</p>
<p><code>Filter.java</code> 在构造函数中实例化 Predicate 和 OpIterator。其中 <code>fetchNext()</code> 方法逐个读取 OpIterator 中的 Tuple ，然后让他们与 Predicate 中 Field 进行比较，如果为真则返回该 Tuple。</p>
<p><code>Join.java</code> 就是对 <code>JoinPredicate.java</code> 的使用，通过构造函数实例化 <code>JoinPredicate</code> 和两个OpIterator 。实现一系类get方法和open、close等迭代器的函数。最后完成fetchNext函数找到两个迭代器中可以jion的字段进行join。</p>
<p>fetchNext 中由两个 while 循环进行遍历，直到最外层迭代器遍历完成，每次遍历 child1 取出一个 Tuple ，与 child2 中的所有 Tuple 做 filter 比较，直到有符合要求的，创建新的 TupleDesc ，并且将 child1 和 child2 的字段（field），加入newTuple中，然后返回newTuple，同时将 child2 重置到最开始。</p>
<h2 id="exercise-2-1"><a class="header" href="#exercise-2-1">Exercise 2</a></h2>
<p>实现下面几个方法并通过 IntegerAggregatorTest 、StringAggregatorTest 和 AggregateTest 单元测试。此外还需要通过 AggregateTest 的系统测试。</p>
<ul>
<li>src/java/simpledb/execution/IntegerAggregator.java</li>
<li>src/java/simpledb/execution/StringAggregator.java</li>
<li>src/java/simpledb/execution/Aggregate.java</li>
</ul>
<p>只需要实现单个字段的聚合（aggregation）和单个字段的分组（group by）即可。聚合其实就对一组数据进行操作（加减乘除，最值等）。具体可参考：<a href="https://www.runoob.com/sql/sql-groupby.html">SQL GROUP BY 语句</a>。</p>
<p><code>IntegerAggregator(0, Type.INT_TYPE, 1, Aggregator.Op.SUM)</code> 是生成一个整数聚合的对象。</p>
<p>其中 0 表示分组(Group By)字段位置，也就是根据第零列来聚合。可以为 NO_GROUPING，表示不进行聚合。</p>
<p>Type.INT_TYPE 表示这一列的数据类型，目前只有整数和字符串。1 表示待聚合的字段，Aggregator.Op.SUM 表示执行加法操作。</p>
<p>需要看懂 IntegerAggregatorTest 测试类。其中 scan1 是一张基础表，sum/min/max/avg 是四张经过聚合操作后的表，用于验证 scan1 经过聚合后的结果是否符合预期。</p>
<p><code>mergeTupleIntoGroup()</code> 根据 gbField 字段先判断是否需要进行 group by 。如果需要，那么根据 gbField 从 tup 中提取待聚合的字段，再判断是否是初次填入，然后根据对应 Op 执行对应逻辑。如果不需要 group by 直接累加即可，不需要映射，</p>
<p>StringAggregator 和 IntegerAggregator 逻辑类似，并且仅支持 COUNT 。</p>
<p>Aggregate 是将前两个整合一下。</p>
<h2 id="exercise-3-1"><a class="header" href="#exercise-3-1">Exercise 3.</a></h2>
<p>增加 tuple 或删除 tuple</p>
<ol>
<li>编写 <code>HeapPage.java</code> 并通过 <code>HeapPageWriteTest</code> 。</li>
</ol>
<p>首先根据要删除 tuple 的 RecordId 判断是否被使用，如果已经被使用就比较当前的 tuple 和待删除的 tuple 对象，一致就删除并标记。如果没有被使用那么 tuple slot 就是空。</p>
<ul>
<li>markDirty() 用一个队列来记录脏页的 tid，如果是脏页就加入队列中，如果不是就从队列中删除。</li>
<li>isDirty() 返回队列中最后一个脏页，如果没有脏页就返回 null。</li>
<li>insertTuple() 首先判断当前页面 td 和待插入 tuple 的 TupleDesc 是否匹配。然后遍历空余的 slot，寻找插入位置找到后插入并设置 RecordId 。最后标记该位置已经被插入。</li>
<li>markSlotUsed() 修改 head 表示 tuple 被使用。</li>
<li>deleteTuple() 依旧是判断当前页面 td 和待删除 tuple 的 TupleDesc 是否匹配。然后根据待删除的 tuple 找到 RecordId 判断是否存在，最后根据索引判断 slot 是否被使用，如果使用就删除。</li>
</ul>
<ol start="2">
<li>编写 HeapFile.java 并通过 <code>HeapFileWriteTest</code> </li>
</ol>
<ul>
<li><code>insertTuple()</code> 如果当前没有页面就调用 writePage 在磁盘中创建空页。然后去 BufferPool 取页，接下来判断取到的页中是否含有空 slot ，然后插入 tuple 。</li>
<li><code>deleteTuple()</code> 从 BufferPool 中取出 page 然后删除 tuple 。</li>
</ul>
<ol start="3">
<li>编写 BufferPool.java 中的 insertTuple() 和 deleteTuple() 并通过 <code>BufferPoolWriteTest</code>。</li>
</ol>
<h2 id="exercise-4-1"><a class="header" href="#exercise-4-1">Exercise 4.</a></h2>
<p>实现 <code>execution/Insert.java</code> 和 <code>execution/Delete.java</code> 并通过 InsertTest 和 InsertTest，DeleteTest system tests</p>
<h2 id="exercise-5-1"><a class="header" href="#exercise-5-1">Exercise 5.</a></h2>
<p>实现 BufferPool.java 中的 flushPage() 方法，</p>
<p>通过 EvictionTest system test</p>
<p>discardPage() 方法是直接从缓冲池中删除不写回磁盘。</p>
<p>用 LRU 来实现！通过这道题可以学会 LRU ，<a href="https://leetcode-cn.com/problems/lru-cache/">Leetcode 146. LRU 缓存</a>，这个<a href="https://www.bilibili.com/video/BV1hp4y1x7MH">视频</a>讲的很好！ </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-3-query-optimization"><a class="header" href="#lab-3-query-optimization">Lab 3: Query Optimization</a></h1>
<ul>
<li><a href="https://www.infoq.cn/article/GhhQlV10HWLFQjTTxRtA">数据库内核杂谈（七）：数据库优化器（上）</a></li>
</ul>
<blockquote>
<p>查询优化并非是让用户写出能够被高效处理的查询，而是期望系统能够构造一个让查询执行代价最小的查询计划。</p>
</blockquote>
<p>这个 lab 大致要实现一个查询优化器，实现一个选择性估计框架和一个基于成本(Selinger)的优化器。</p>
<ol>
<li>
<p>实现 TableStats 类中的方法，使其能够使用直方图（IntHistogram类提供的骨架）或你设计的其他形式的统计数据来估计过滤器的选择性和扫描的成本。</p>
</li>
<li>
<p>实现 JoinOptimizer 类中的方法，使其能够估计 join 的成本和选择性。</p>
</li>
<li>
<p>编写 JoinOptimizer 中的 orderJoins 方法。这个方法必须为一系列的连接产生一个最佳的顺序（可能使用Selinger算法），给定前两个步骤中计算的统计数据。</p>
</li>
</ol>
<p>基于开销优化器的主要思想：</p>
<p>评估不同查询计划下的成本，根据成本选择最佳的排列和连接方式。</p>
<p>精确的估计是很难的，这个实验只关注连接序列和基本表访问的成本。</p>
<p>根据 table 的统计数据来估计不同查询计划的开销。通常一个计划的成本与 intermediate joins 和 tuple 数量，以及 selectivity of filter 和 join predicates 的选择性有关。</p>
<p>根据统计数据以最佳方式排列连接和选择，并从几个备选方案中选择连接算法的最佳实现。</p>
<p>当使用嵌套循环连接时，记得两个表t1和t2（其中t1是外表）之间的连接成本是简单的。</p>
<pre><code>joincost(t1 join t2) = scancost(t1) + ntups(t1) x scancost(t2) //IO cost
                    + ntups(t1) x ntups(t2)  //CPU cost
Here, ntups(t1) is the number of tuples in table t1.
</code></pre>
<p>这里，ntups(t1)是表t1中 tuples 的数量。</p>
<p>首先要计算出开销，而开销由 I/O 开销和 CPU 开销两部分组成。其中需要用到表中 tuple 的数量。下面是如何统计 tuple 数。</p>
<blockquote>
<p>查询的开销为什么这样算？</p>
</blockquote>
<h2 id="exercise-1-inthistogramjava"><a class="header" href="#exercise-1-inthistogramjava">Exercise 1: IntHistogram.java</a></h2>
<p>实现 IntHistogram 并通过 IntHistogramTest。</p>
<p>针对一个属性构建一张直方图，横坐标代表属性对应范围，纵坐标代表对应范围内 tuple 的数量。</p>
<p>其实就是计算对应条件下 tuple 的数量对于总数的占比。</p>
<p>占比计算 <code>(h / w) / ntups</code>  ntups 是纵坐标的累加和，也就是 tuple 的总数。</p>
<p><code>(h / w)</code> 表示桶中含有值常数的 tuples 的预期数量。 h 的表示桶中 tuple 的总数，并不是均匀的高度！！！</p>
<p>部分区间的占比 ：<code>b_part = (b_right - const)/ w_b</code> <code>b_f = h_b / ntups</code> <code>b_f x b_part</code></p>
<ul>
<li><code>addValue(int v)</code></li>
</ul>
<p>根据输入数据构建直方图的分部，计算出对应桶序号累加即可。</p>
<ul>
<li><code>estimateSelectivity(Predicate.Op op, int v)</code> 估计</li>
</ul>
<p>这个类用来计算占比。具体的计算规则是根据运算符 op 判断(大于，小于，等于...)，v 就是 const ，遍历。例如 op 是大于， v 是 3 ，那么就是计算横坐标大于 3 所有 tuple 个数除以总 tuple 个数(ntuple)。也就是大于 3 tuple 占总 tuple 的百分比。</p>
<h2 id="exercise-2-tablestatsjava"><a class="header" href="#exercise-2-tablestatsjava">Exercise 2: TableStats.java</a></h2>
<p>实现 TableStats 并通过 TableStatsTest。</p>
<ul>
<li>实现TableStats构造函数</li>
</ul>
<p>为 table 的每一个 field 构建一张直方图。</p>
<p>根据 tableid 拿到 table，然后遍历 table 的每个字段(field)构建直方图。注意 field 分为整数和字符串两种类型，分别用 map 来存。</p>
<p>首先获取每一列对应的内容，放入 list 中。然后获取所有列的内容，一列就是一个 field ，一列生成一个直方图。</p>
<ul>
<li>estimateScanCost() </li>
</ul>
<p>IO 成本是页数乘上单页 IO 的开销。</p>
<ul>
<li>estimateTableCardinality()</li>
</ul>
<p>tuple 总数乘上系数 (selectivityFactor)。</p>
<ul>
<li>estimateSelectivity()</li>
</ul>
<p>根据输入的参数来估计 Selectivity ，三个参数分别是待估计的字段，比较符号，const。区分field 的int 和 string 分别调用 estimateSelectivity() 即可。</p>
<h2 id="exercise-3-join-cost-estimation"><a class="header" href="#exercise-3-join-cost-estimation">Exercise 3: Join Cost Estimation</a></h2>
<p>编写 JoinOptimizer 并通过 JoinOptimizerTest 中的 estimateJoinCostTest 和 estimateJoinCardinality 即可。</p>
<ul>
<li>实现 <code>estimateJoinCost()</code> 方法，估计 join 的成本。</li>
</ul>
<p>计算公式：</p>
<p>joincost(t1 join t2) = scancost(t1) + ntups(t1) x scancost(t2) //IO cost
+ ntups(t1) x ntups(t2)  //CPU cost</p>
<blockquote>
<p>Nested-loop (NL) join是所有join算法中最naive的一种。假设有两张表R和S，NL join会用二重循环的方法扫描每个(r, s)对，如果行r和行s满足join的条件，就输出之。显然，其I/O复杂度为O(|R||S|)。随着参与join的表个数增加，循环嵌套的层数就越多，时间复杂度也越高。因此虽然它的实现很简单，但效率也较低。</p>
</blockquote>
<p>总结：成本 (cost) 分为 I/O 成本和 CPU 成本。I/O 成本是扫描表时和磁盘交互所产生的，而 CPU 成本是判断数据是否符合条件所产生的。其中 cost1 是扫描 t1 的 I/O 成本，cost2 同理。因为是 NL join 所以总的 I/O 开销就是 <code>cost1 + card1 * cost2</code> 。而 CPU 开销则是 <code>card1 * card2</code> 。总成本相加即可。</p>
<ul>
<li>estimateJoinCardinality 估计 join 后产生的 tuple 数。</li>
</ul>
<p>lab3.md 中 2.2.4 Join Cardinality 部分有详细解释。</p>
<p>Cardinality 表示一列数据中数据的重复程度，如果等于 1 那么数据没有重复的，如果等于 0 那么全部都重复，其他情况加载 [0 , 1] 之间。具体可参考：<a href="https://stackoverflow.com/questions/10621077/what-is-cardinality-in-databases">What is cardinality in Databases?</a> 。</p>
<p>对于等价连接() 其中一个属性是主键时，由连接产生的 tuples 的数量不能大于非主键属性的cardinality。只要保证这一点成立即可，所以其中一个是主键的话就选择一个小的，两个都是主键的话选择小的，两个都不是主键的话选择大的。这块的实现很灵活。</p>
<p>对于非等价连接文档给了公式 <code>card1 * card2 * 0.3</code> 。</p>
<h2 id="exercise-4-join-ordering"><a class="header" href="#exercise-4-join-ordering">Exercise 4: Join Ordering</a></h2>
<p>实现 JoinOptimizer.java 中的 orderJoins 方法并通过 JoinOptimizerTest 和系统测试 QueryTest 。</p>
<p>ex3 实现了开销估计和基数个数的估计。这个练习则是在多表连接的情况下根据开销分析选择最优的连接顺序。直接枚举的话复杂度是 O(n!) 。此处选择了一种 DP 的方法将复杂度降低到了 O(2^n)。</p>
<p>首先要理解什么是 left-deep-tree 可参考这篇<a href="https://www.infoq.cn/article/JCJyMrGDQHl8osMFQ7ZR">文章</a>，写的很好！</p>
<p>然后阅读 <a href="https://blog.csdn.net/weixin_45834777/article/details/120788433?spm=1001.2014.3001.5501">Exercise 4: Join Ordering</a> 部分。</p>
<p>JoinOptimizer 中的 join 属性是一个队列，其中存的都是 LogicalJoinNode 对象。</p>
<p>PlanCache 类，用来缓存 Selinger 实现中所考虑的连接子集的最佳顺序，接下来的任务就是找到最佳顺序。</p>
<p><code>enumerateSubsets(joins, i);</code> 其中 i 表示子集中的子集的元素个数。例如 a,b,c 三张表，当 i=1 时，返回数据大致形态 set(set(ab) , set(ac), set(bc)) ， 注意 ab 是一个 LogicalJoinNode 所以尺寸是 1 。如果 i=2 ，那么返回的数据类似 set(set(ab, c) , set(ac, b), set(bc, a)) 。可以优化为回溯，避免创建大量对象。</p>
<blockquote>
<p>这块内容建议阅读帆船书《Database System Concepts》第七版的 16.4.1 Cost-Based Join-Order Selection 部分</p>
</blockquote>
<p>DP step:</p>
<ol>
<li>首先枚举左深树的组合顺序。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318195217.png" alt="20220318195217" /></p>
<ol start="2">
<li>枚举不同顺序下不同 Join 算法的开销。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318195401.png" alt="20220318195401" /></p>
<ol start="3">
<li>枚举每一个表的读表方式的开销。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220318195454.png" alt="20220318195454" /></p>
<ol start="4">
<li>暴力计算。</li>
</ol>
<p>小于 12 个表用 DP ，否则开销巨大。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-4-simpledb-transactions"><a class="header" href="#lab-4-simpledb-transactions">Lab 4: SimpleDB Transactions</a></h1>
<p>Transactions 被翻译为事物，其实就是一个原子级的操作，重点是操作不能被中断。用锁来实现原子级别的操作，但是单纯用锁的话存在串行化的问题，于是引入了 2PL 从而保证了串行化。</p>
<p>在 2PL 下，事物分为增长阶段 (growing phase) 和收缩阶段 (shrinking phase) ，区别在于前者只能不断加锁，而后者只能不断减锁，一旦开始减锁就意味着从增长阶段转为收缩阶段。</p>
<blockquote>
<p>2PL 建议看这个视频 <a href="https://www.bilibili.com/video/BV1AZ4y1Q7vx/?spm_id_from=333.788">16-两阶段锁</a> 或者阅读 《Database System Concepts》 18.1.3 The Two-Phase Locking Protocol 这篇文章也不错：https://zhuanlan.zhihu.com/p/59535337</p>
</blockquote>
<h2 id="exercise-1-and-2"><a class="header" href="#exercise-1-and-2">Exercise 1 and 2.</a></h2>
<p>这两个练习是编写 BufferPool  最终通过 LockingTest 。</p>
<p>为 BufferPool 添加获取锁和释放锁的功能，修改 getPage() 实现 unsafeReleasePage(), holdsLock() 实现下一个练习才能通过 LockingTest 。</p>
<p>具体思路，实现一个 Lock 类和 LockManager 类。LockManager 类实现三个功能申请锁、释放锁、查看指定数据页的指定事务是否有锁。</p>
<h2 id="exercise-3-2"><a class="header" href="#exercise-3-2">Exercise 3.</a></h2>
<p>之前没有区分是否是脏页就直接写回了，不能将脏页直接淘汰。</p>
<p>修改 evictPage() 方法，倒着遍历，删除一个非脏页即可。</p>
<h2 id="exercise-4-2"><a class="header" href="#exercise-4-2">Exercise 4.</a></h2>
<p>实现 <code>transactionComplete()</code> </p>
<p>通过 TransactionTest 单元测试和 AbortEvictionTest 系统测试</p>
<p>如果 commit 那么就把 tid 对应的所有页面持久化，也就是写入磁盘否则把该事物相关的页面加载进缓存中。</p>
<h2 id="exercise-5-2"><a class="header" href="#exercise-5-2">Exercise 5.</a></h2>
<p>检测死锁，然后通过 DeadlockTest 和 TransactionTest 系统测试。</p>
<p>设置一个区间，如果超时就说明发生死锁了。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-5-b-tree-index"><a class="header" href="#lab-5-b-tree-index">Lab 5: B+ Tree Index</a></h1>
<p>了解 B+ 树。</p>
<p>BTreeFile 由四种不同的页面组成，</p>
<ul>
<li>BTreeInternalPage.java 内部页</li>
<li>BTreeLeafPage.java 叶子页</li>
<li>BTreePage.java 包含了叶子页和内部页的共同代码</li>
<li>BTreeHeaderPage.java 跟踪文件中哪些页正在使用</li>
</ul>
<h2 id="exercise-1-btreefilefindleafpage"><a class="header" href="#exercise-1-btreefilefindleafpage">Exercise 1: BTreeFile.findLeafPage()</a></h2>
<p>在 BTreeFile.java 中实现 findLeafPage() 方法，功能是给定一个特定的键值的情况下找到合适的叶子页。</p>
<p>具体流程如下图：根节点是 6 是一个内部页，两个指针分别指向了叶子页。如果输入 1 那么 findLeafPage() 应当返回第一个叶子页。如果输入 8 那么应当返回第二个叶子页。如果输入 6 此时左右叶子页都含有 6 ，函数应当返回第一个叶子页，也就是左边的叶子页。</p>
<p><img src="6.830/ans/image/index/1644485406419.png" alt="" /></p>
<p>findLeafPage() 递归搜索节点，节点内部的数据可以通过 BTreeInternalPage.iterator() 访问。</p>
<p>当 key value 为空的时候，应当递归做左边的子页进而找到最左边的叶子页。BTreePageId.java中的pgcateg() 函数检查页面的类型。可以假设只有叶子页和内部页会被传递给这个函数。</p>
<p>BTreeFile.getPage() 和 BufferPool.getPage() 原理一样但需要一个额外的参数来跟踪脏页。</p>
<p>findLeafPage() 访问的每一个内部（非叶子）页面都应该以 READ_ONLY 权限获取，除了返回的叶子页面，它应该以作为函数参数提供的权限获取。这些权限在本实验中不重要但是后续实验中很重要。</p>
<blockquote>
<p>这个练习很简单，上面的内容本来是文档的总结，后来发现几乎就是代码的文字版。。。</p>
</blockquote>
<p>通过 BTreeFileReadTest.java 中的所有单元测试和 BTreeScanTest.java 中的系统测试。</p>
<h2 id="exercise-2-splitting-pages"><a class="header" href="#exercise-2-splitting-pages">Exercise 2: Splitting Pages</a></h2>
<p>在 BTreeFile.java 中实现 splitLeafPage() 和 splitInternalPage() 并通过 BTreeFileInsertTest.java 中的单元测试和 systemtest/BTreeFileInsertTest.java 中的系统测试。</p>
<p>通过 findLeafPage() 可以找到应该插入 tuple 的正确叶子页，但是页满的情况下插入 tuple 可能会导致页分裂，进而导致父节点分裂也就是递归分裂。</p>
<p>如果被分割的页面是根页面，你将需要创建一个新的内部节点来成为新的根页面，并更新 BTreeRootPtrPage
否则，需要以 READ_WRITE 权限获取父页，进行递归分割，并添加一个 entry。getParentWithEmptySlots()对于处理这些不同的情况非常有用。</p>
<p>在 splitLeafPage() 中将键“复制”到父页上，页节点中保留一份。而在 splitInternalPage() 中，你应该将键“推”到父页上，内部节点不保留。</p>
<p>当内部节点被分割时，需要更新所有被移动的子节点的父指针。updateParentPointers() 很有用。</p>
<p>每当创建一个新的页面时，无论是因为拆分一个页面还是创建一个新的根页面，都要调用 getEmptyPage() 来获取新的页面。这是一个抽象函数，它将允许我们重新使用因合并而被删除的页面（在下一节涉及）。</p>
<p>BTreeLeafPage.iterator() 和 BTreeInternalPage.iterator() 实现了叶子页和内部页进行交互，除此之外还提供了反向迭代器 BTreeLeafPage.reverseIterator() 和 BTreeInternalPage.reverseIterator() 。</p>
<p>BTreeEntry.java 中有一个 key 和两个 child pointers ，除此之外还有一个 recordId 用于识别底层页面上键和子指针的位置。</p>
<h2 id="exercise-3-redistributing-pages"><a class="header" href="#exercise-3-redistributing-pages">Exercise 3: Redistributing pages</a></h2>
<p>实现 BTreeFile.stealFromLeafPage(), BTreeFile.stealFromLeftInternalPage(), BTreeFile.stealFromRightInternalPage() 并通过 BTreeFileDeleteTest.java 中的一些单元测试（如testStealFromLeftLeafPage和testStealFromRightLeafPage）</p>
<p>删除存在两种情况，如果兄弟节点数据比较多可以从兄弟节点借，反之数据较少可以和兄弟节点合并。</p>
<p>stealFromLeafPage() 两个页面 tuple 加一起然后除二，平均分成两个 leaf page 。</p>
<h2 id="exercise-4-merging-pages"><a class="header" href="#exercise-4-merging-pages">Exercise 4: Merging pages</a></h2>
<p>实现 BTreeFile.mergeLeafPages() 和 BTreeFile.mergeInternalPages() 。</p>
<p>现在应该能够通过 BTreeFileDeleteTest.java 中的所有单元测试和 systemtest/BTreeFileDeleteTest.java 中的系统测试。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-6-rollback-and-recovery"><a class="header" href="#lab-6-rollback-and-recovery">Lab 6: Rollback and Recovery</a></h1>
<p>根据日志内容实现 rollback 和 recovery 。</p>
<p>当读取 page 时，代码会记住 page 中的原始内容作为 before-image 。 当事务更新 page 时，修改后的 page 作为 after-image 。使用 before-image 在 aborts 进行 rollback 并在 recovery 期间撤销失败的事务。</p>
<h2 id="exercise-1-logfilerollback"><a class="header" href="#exercise-1-logfilerollback">Exercise 1: LogFile.rollback()</a></h2>
<p>实现LogFile.java中的rollback()函数</p>
<p>通过LogTest系统测试的TestAbort和TestAbortCommitInterleaved子测试。</p>
<p>rollback() 回滚指定事务，已经提交了的事务上不能执行该方法。将上一个版本的数据写回磁盘。</p>
<p>当一个事务中止时，在该事务释放其锁之前，这个函数被调用。它的工作是解除事务可能对数据库做出的任何改变。</p>
<h2 id="exercise-2-logfilerecover"><a class="header" href="#exercise-2-logfilerecover">Exercise 2: LogFile.recover()</a></h2>
<p>实现 Implement LogFile.recover().</p>
<p>重启数据库时会率先调用 LogFile.recover() </p>
<p>对于未提交的事务：使用before-image对其进行恢复，对于已提交的事务：使用after-image对其进行恢复。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-1-翻译"><a class="header" href="#lab-1-翻译">Lab 1 翻译</a></h1>
<p><strong>Assigned: Wed, Feb 24</strong></p>
<p><strong>Due: Wed, Mar 10 11:59 PM EDT</strong></p>
<!--
**Bug Update:** We have a [page](bugs.html) to keep track
of SimpleDB bugs that you or we find. Fixes for bugs/annoyances will also be
posted there. Some bugs may have already been found, so do take a look at the page
to get the latest version/ patches for the lab code.
-->
<p>In the lab assignments in 6.830 you will write a basic database management system called SimpleDB. For this lab, you will focus on implementing the core modules required to access stored data on disk; in future labs, you will add support for various query processing operators, as well as transactions, locking, and concurrent queries.</p>
<p>在6.830的实验作业中，你将编写一个名为SimpleDB的基本数据库管理系统。在这个实验中，你将专注于实现访问磁盘上存储的数据所需的核心模块；在未来的实验中，你将增加对各种查询处理操作符以及事务、锁定和并发查询的支持。</p>
<p>SimpleDB is written in Java. We have provided you with a set of mostly unimplemented classes and interfaces. You will need to write the code for these classes. We will grade your code by running a set of system tests written using <a href="http://junit.sourceforge.net/">JUnit</a>. We have also provided a number of unit tests, which we will not use for grading but that you may find useful in verifying that your code works. We also encourage you to develop your own test suite in addition to our tests.</p>
<p>SimpleDB是用Java编写的。我们已经为你提供了一组大部分未实现的类和接口。你将需要为这些类编写代码。我们将通过运行一组用<a href="http://junit.sourceforge.net/">JUnit</a>编写的系统测试来评定你的代码。我们还提供了一些单元测试，我们不会在评分中使用这些测试，但你可能会发现这些测试对验证你的代码是否工作很有用。我们也鼓励你在我们的测试之外，开发你自己的测试套件。</p>
<p>The remainder of this document describes the basic architecture of SimpleDB, gives some suggestions about how to start coding, and discusses how to hand in your lab.</p>
<p>本文件的其余部分描述了SimpleDB的基本架构，给出了一些关于如何开始编码的建议，并讨论了如何在实验中交接。</p>
<p>We <strong>strongly recommend</strong> that you start as early as possible on this lab. It requires you to write a fair amount of code!</p>
<p>我们***强烈建议你尽早开始做这个实验。它需要你写相当数量的代码!</p>
<!--

##  0.  Find bugs, be patient, earn candy bars 

SimpleDB is a relatively complex piece of code.
It is very possible you are going to find bugs, inconsistencies, and bad,
outdated, or incorrect documentation, etc.

We ask you, therefore, to do this lab with an adventurous mindset.  Don't get
mad if something is not clear, or even wrong; rather, try to figure it out
yourself or send us a friendly email.  We promise to help out by posting
bug fixes, new commits to the HW repo, etc., as bugs and issues are reported.

<p>...and if you find a bug in our code, we`ll give you a candy bar (see [Section 3.3](#bugs))!

-->
<!--which you can find [here](bugs.html).</p>-->
<h2 id="0-environment-setup"><a class="header" href="#0-environment-setup">0. Environment Setup</a></h2>
<p><strong>Start by downloading the code for lab 1 from the course GitHub repository by following the instructions <a href="https://github.com/MIT-DB-Class/simple-db-hw-2021">here</a>.</strong></p>
<p>首先按照说明<a href="https://github.com/MIT-DB-Class/simple-db-hw-2021">这里</a>从课程的GitHub资源库下载实验1的代码。</p>
<p>These instructions are written for Athena or any other Unix-based platform (e.g., Linux, MacOS, etc.)  Because the code is written in Java, it should work under Windows as well, although the directions in this document may not apply.</p>
<p>这些说明是为Athena或任何其他基于Unix的平台（如Linux、MacOS等）编写的。因为代码是用Java编写的，所以在Windows下也应该可以工作，尽管本文件中的说明可能不适用。</p>
<p>We have included <a href="6.830/cn/2-lab1.html#eclipse">Section 1.2</a> on using the project with Eclipse or IntelliJ.</p>
<p>我们已经包括了<a href="6.830/cn/2-lab1.html#eclipse">第1.2节</a>关于用Eclipse或IntelliJ使用该项目。</p>
<h2 id="1-getting-started"><a class="header" href="#1-getting-started">1. Getting started</a></h2>
<p>SimpleDB uses the <a href="http://ant.apache.org/">Ant build tool</a> to compile the code and run tests. Ant is similar to <a href="http://www.gnu.org/software/make/manual/">make</a>, but the build file is written in XML and is somewhat better suited to Java code. Most modern Linux distributions include Ant. Under Athena, it is included in the <code>sipb</code> locker, which you can get to by typing <code>add sipb</code> at the Athena prompt. Note that on some versions of Athena you must also run <code>add -f java</code> to set the environment correctly for Java programs. See the <a href="http://web.mit.edu/acs/www/languages.html#Java">Athena documentation on using Java</a> for more details.</p>
<p>SimpleDB使用<a href="http://ant.apache.org/">Ant构建工具</a>来编译代码和运行测试。Ant类似于<a href="http://www.gnu.org/software/make/manual/">make</a>，但构建文件是用XML写的，在某种程度上更适合于Java代码。大多数现代Linux发行版都包括Ant。在Athena下，它被包含在<code>sipb</code>锁存器中，你可以通过在Athena提示符下输入<code>add sipb</code>来获得它。注意，在某些版本的Athena上，你还必须运行<code>add -f java</code>来为Java程序正确设置环境。更多细节见<a href="http://web.mit.edu/acs/www/languages.html#Java">Athena使用Java的文档</a>。</p>
<p>To help you during development, we have provided a set of unit tests in addition to the end-to-end tests that we use for grading. These are by no means comprehensive, and you should not rely on them exclusively to verify the correctness of your project (put those 6.170 skills to use!).</p>
<p>为了在开发过程中帮助你，除了我们用于评分的端到端测试外，我们还提供了一套单元测试。这些绝不是全面的，你不应该完全依赖它们来验证你的项目的正确性（把那些6.170的技能用上吧！）。</p>
<p>To run the unit tests use the <code>test</code> build target:</p>
<p>要运行单元测试，请使用<code>test</code>构建目标。</p>
<pre><code>$ cd [project-directory]
$ # run all unit tests
$ ant test
$ # run a specific unit test
$ ant runtest -Dtest=TupleTest
</code></pre>
<p>You should see output similar to:</p>
<p>你应该看到类似的输出。</p>
<pre><code> build output...

test:
    [junit] Running simpledb.CatalogTest
    [junit] Testsuite: simpledb.CatalogTest
    [junit] Tests run: 2, Failures: 0, Errors: 2, Time elapsed: 0.037 sec
    [junit] Tests run: 2, Failures: 0, Errors: 2, Time elapsed: 0.037 sec

 ... stack traces and error reports ...
</code></pre>
<p>The output above indicates that two errors occurred during compilation; this is because the code we have given you doesn't yet work. As you complete parts of the lab, you will work towards passing additional unit tests.</p>
<p>上面的输出表明，在编译过程中发生了两个错误；这是因为我们给你的代码还不能工作。当你完成实验的部分内容时，你将努力通过额外的单元测试。</p>
<p>If you wish to write new unit tests as you code, they should be added to the <tt>test simpledb</tt> directory.</p>
<p>如果你希望在编码时编写新的单元测试，它们应该被添加到<tt>test simpledb</tt> catalog 。</p>
<p>For more details about how to use Ant, see the [manual](http://ant.apache.org/manual/). The [Running Ant](http://ant.apache.org/manual/running.html) section provides details about using the `ant` command. However, the quick reference table below should be sufficient for working on the labs.
<p>关于如何使用Ant的更多细节，请参阅[手册](http://ant.apache.org/manual/)。运行Ant](http://ant.apache.org/manual/running.html)部分提供了关于使用`ant`命令的细节。然而，下面的快速参考表应该足以用于实验的工作。
<div class="table-wrapper"><table><thead><tr><th>Command</th><th>Description</th></tr></thead><tbody>
<tr><td>ant</td><td>Build the default target (for simpledb, this is dist). 构建默认的目标（对于simpledb，这是dist）。</td></tr>
<tr><td>ant -projecthelp</td><td>List all the targets in <code>build.xml</code> with descriptions. 列出<code>build.xml</code>中的所有目标和描述。</td></tr>
<tr><td>ant dist</td><td>Compile the code in src and package it in <code>dist/simpledb.jar</code>. 编译src中的代码并将其打包到<code>dist/simpledb.jar</code>中。</td></tr>
<tr><td>ant test</td><td>Compile and run all the unit tests. 编译并运行所有单元测试。</td></tr>
<tr><td>ant runtest -Dtest=testname</td><td>Run the unit test named <code>testname</code>. 运行名为<code>testname</code>的单元测试。</td></tr>
<tr><td>ant systemtest</td><td>Compile and run all the system tests. 编译并运行所有的系统测试。</td></tr>
<tr><td>ant runsystest -Dtest=testname</td><td>Compile and run the system test named <code>testname</code>. 编译并运行名为<code>testname</code>的系统测试。</td></tr>
</tbody></table>
</div>
<p>If you are under windows system and don't want to run ant tests from command line, you can also run them from eclipse. Right click build.xml, in the targets tab, you can see &quot;runtest&quot; &quot;runsystest&quot; etc. For example, select runtest would be equivalent to &quot;ant runtest&quot; from command line. Arguments such as &quot;-Dtest=testname&quot; can be specified in the &quot;Main&quot; Tab, &quot; Arguments&quot; textbox. Note that you can also create a shortcut to runtest by copying from build.xml, modifying targets and arguments and renaming it to, say, runtest_build.xml.</p>
<p>如果你在windows系统下，不想从命令行运行ant测试，你也可以从eclipse运行它们。右击build.xml，在target标签中，你可以看到 &quot;runtest&quot;&quot;runystest &quot;等。例如，选择runtest就相当于从命令行中的 &quot;ant runtest&quot;。诸如&quot;-Dtest=testname &quot;这样的参数可以在 &quot;主 &quot;标签的 &quot;参数 &quot;文本框中指定。注意，你也可以通过复制build.xml，修改目标和参数，并将其重命名为例如runtest_build.xml来创建runtest的快捷方式。</p>
<h3 id="11-running-end-to-end-tests"><a class="header" href="#11-running-end-to-end-tests">1.1. Running end-to-end tests</a></h3>
<p>We have also provided a set of end-to-end tests that will eventually be used for grading. These tests are structured as JUnit tests that live in the <code>test/simpledb/systemtest</code> directory. To run all the system tests, use the <code>systemtest</code> build target:</p>
<p>我们还提供了一套端到端的测试，最终将用于评分。这些测试的结构是JUnit测试，存在于<code>test/simpledb/systemtest</code> catalog 中。要运行所有的系统测试，请使用<code>systemtest</code>构建目标。</p>
<pre><code>$ ant systemtest

 ... build output ...

    [junit] Testcase: testSmall took 0.017 sec
    [junit]     Caused an ERROR
    [junit] expected to find the following tuples:
    [junit]     19128
    [junit] 
    [junit] java.lang.AssertionError: expected to find the following tuples:
    [junit]     19128
    [junit] 
    [junit]     at simpledb.systemtest.SystemTestUtil.matchTuples(SystemTestUtil.java:122)
    [junit]     at simpledb.systemtest.SystemTestUtil.matchTuples(SystemTestUtil.java:83)
    [junit]     at simpledb.systemtest.SystemTestUtil.matchTuples(SystemTestUtil.java:75)
    [junit]     at simpledb.systemtest.ScanTest.validateScan(ScanTest.java:30)
    [junit]     at simpledb.systemtest.ScanTest.testSmall(ScanTest.java:40)

 ... more error messages ...
</code></pre>
<p>This indicates that this test failed, showing the stack trace where the error was detected. To debug, start by reading the source code where the error occurred. When the tests pass, you will see something like the following:</p>
<p>这表明这个测试失败了，显示检测到错误的堆栈跟踪。要进行调试，首先阅读发生错误的源代码。当测试通过时，你会看到类似下面的内容。</p>
<pre><code>$ ant systemtest

 ... build output ...

    [junit] Testsuite: simpledb.systemtest.ScanTest
    [junit] Tests run: 3, Failures: 0, Errors: 0, Time elapsed: 7.278 sec
    [junit] Tests run: 3, Failures: 0, Errors: 0, Time elapsed: 7.278 sec
    [junit] 
    [junit] Testcase: testSmall took 0.937 sec
    [junit] Testcase: testLarge took 5.276 sec
    [junit] Testcase: testRandom took 1.049 sec

BUILD SUCCESSFUL
Total time: 52 seconds
</code></pre>
<h4 id="111-creating-dummy-tables"><a class="header" href="#111-creating-dummy-tables">1.1.1 Creating dummy tables</a></h4>
<p>It is likely you'll want to create your own tests and your own data tables to test your own implementation of SimpleDB. You can create any <code>.txt</code> file and convert it to a <code>.dat</code> file in SimpleDB's <code>HeapFile</code> format using the
command:</p>
<p>你很可能想要创建自己的测试和自己的数据表来测试你自己的SimpleDB的实现。你可以创建任何&quot;.txt &quot;文件并将其转换成SimpleDB的 &quot;HeapFile &quot;格式的&quot;.dat &quot;文件，使用
命令。</p>
<pre><code>$ java -jar dist/simpledb.jar convert file.txt N
</code></pre>
<p>where <code>file.txt</code> is the name of the file and <code>N</code> is the number of columns in the file. Notice that <code>file.txt</code> has to be in the following format:</p>
<p>其中<code>file.txt</code>是文件的名称，<code>N</code>是文件中的列数。请注意，<code>file.txt</code>必须是以下格式。</p>
<pre><code>int1,int2,...,intN
int1,int2,...,intN
int1,int2,...,intN
int1,int2,...,intN
</code></pre>
<p>...where each intN is a non-negative integer.</p>
<p>...其中每个intN是一个非负整数。</p>
<p>To view the contents of a table, use the <code>print</code> command:</p>
<p>要查看一个表的内容，使用<code>print</code>命令。</p>
<pre><code>$ java -jar dist/simpledb.jar print file.dat N
</code></pre>
<p>where <code>file.dat</code> is the name of a table created with the <tt>convert</tt> command, and <code>N</code> is the number of columns in the file.</p>
<p>其中 <code>file.dat</code> 是用<tt>convert</tt>命令创建的表的名称，<code>N</code> 是文件中的列数。</p>
<h3 id="12-working-with-an-ide"><a class="header" href="#12-working-with-an-ide">1.2. Working with an IDE</a></h3>
<p>IDEs (Integrated Development Environments) are graphical software development environments that may help you manage larger projects. We provide instructions for setting up both <a href="http://www.eclipse.org">Eclipse</a> and <a href="https://www.jetbrains.com/idea/">IntelliJ</a>. The instructions we provide for Eclipse were generated by using Eclipse for Java Developers (not the enterprise edition) with Java 1.7. For IntelliJ, we are using the Ultimate edition, which you can get with an education license through your mit.edu account <a href="https://www.jetbrains.com/community/education/#students">here</a>. We strongly encourage you to set up and learn one of the IDEs for this project.</p>
<p>IDE（集成开发环境）是图形化的软件开发环境，可以帮助你管理大型项目。我们提供<a href="http://www.eclipse.org">Eclipse</a>和<a href="https://www.jetbrains.com/idea/">IntelliJ</a>的设置说明。我们为 Eclipse 提供的说明是通过使用 Java 1.7 的 Eclipse for Java Developers（不是企业版）生成的。对于 IntelliJ，我们使用的是终极版，你可以通过你的 mit.edu 账户获得教育许可<a href="https://www.jetbrains.com/community/education/#students">这里</a>。我们强烈建议你为这个项目设置并学习其中的一个IDE。</p>
<p><strong>Preparing the Codebase</strong></p>
<p><strong>准备代码库</strong>。</p>
<p>Run the following command to generate the project file for IDEs:</p>
<p>运行下面的命令来生成用于IDE的项目文件。</p>
<pre><code>ant eclipse
</code></pre>
<p><strong>Setting the Lab Up in Eclipse</strong></p>
<ul>
<li>
<p>Once Eclipse is installed, start it, and note that the first screen asks you to select a location for your workspace (we will refer to this directory as $W). Select the directory containing your simple-db-hw repository.</p>
</li>
<li>
<p>In Eclipse, select File-&gt;New-&gt;Project-&gt;Java-&gt;Java Project, and push Next.</p>
</li>
<li>
<p>Enter &quot;simple-db-hw&quot; as the project name.</p>
</li>
<li>
<p>On the same screen that you entered the project name, select &quot;Create project from existing source,&quot; and browse to $W/simple-db-hw.</p>
</li>
<li>
<p>Click finish, and you should be able to see &quot;simple-db-hw&quot; as a new project in the Project Explorer tab on the left-hand side of your screen. Opening this project reveals the directory structure discussed above - implementation code can be found in &quot;src,&quot; and unit tests and system tests found in &quot;test.&quot;</p>
</li>
<li>
<p>一旦Eclipse安装完毕，启动它，注意第一个屏幕会要求你为你的工作区选择一个位置（我们将这个 catalog 称为$W）。选择包含simple-db-hw资源库的 catalog 。</p>
</li>
<li>
<p>在Eclipse中，选择File-&gt;New-&gt;Project-&gt;Java-&gt;Java Project，然后按Next。</p>
</li>
<li>
<p>输入 &quot;simple-db-hw &quot;作为项目名称。</p>
</li>
<li>
<p>在你输入项目名称的同一个屏幕上，选择 &quot;从现有源码创建项目&quot;，并浏览到$W/simple-db-hw。</p>
</li>
<li>
<p>点击完成，你应该能够看到 &quot;simple-db-hw &quot;作为一个新的项目出现在屏幕左侧的 &quot;项目浏览器 &quot;标签中。打开这个项目可以看到上面讨论的 catalog 结构--实现代码可以在 &quot;src &quot;中找到，单元测试和系统测试在 &quot;test &quot;中找到。</p>
</li>
</ul>
<p><strong>Note:</strong> that this class assumes that you are using the official Oracle release of Java. This is the default on MacOS X, and for most Windows Eclipse installs; but many Linux distributions default to alternate Java runtimes (like OpenJDK). Please download the latest Java8 updates from <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">Oracle Website</a>, and use that Java version. If you don't switch, you may see spurious test failures in some of the performance tests in later labs.</p>
<p>**注意：**该类假定你使用的是Oracle官方发布的Java。这在 MacOS X 上是默认的，对于大多数 Windows Eclipse 安装来说也是如此；但许多 Linux 发行版默认使用其他 Java 运行时（如 OpenJDK）。请从 [Oracle 网站] (http://www.oracle.com/technetwork/java/javase/downloads/index.html) 下载最新的 Java8 更新，并使用该 Java 版本。如果你不切换，你可能会在后面的实验的一些性能测试中看到虚假的测试失败。</p>
<p><strong>Running Individual Unit and System Tests</strong></p>
<p><strong>运行单个单元和系统测试</strong>。</p>
<p>To run a unit test or system test (both are JUnit tests, and can be initialized the same way), go to the Package Explorer tab on the left side of your screen. Under the &quot;simple-db-hw&quot; project, open the &quot;test&quot; directory. Unit tests are found in the &quot;simpledb&quot; package, and system tests are found in the &quot;simpledb.systemtests&quot; package. To run one of these tests, select the test (they are all called *Test.java - don't select TestUtil.java or SystemTestUtil.java), right click on it, select &quot;Run As,&quot; and select &quot;JUnit Test.&quot;  This will bring up a JUnit tab, which will tell you the status of the individual tests within the JUnit test suite, and will show you exceptions and other errors that will help you debug problems.</p>
<p>要运行一个单元测试或系统测试（两者都是JUnit测试，可以用同样的方法初始化），去屏幕左边的Package Explorer标签。在 &quot;simple-db-hw &quot;项目下，打开 &quot;test &quot; catalog 。单元测试可以在 &quot;simpledb &quot;包中找到，系统测试可以在 &quot;simpledb.systemtests &quot;包中找到。要运行这些测试之一，选择测试（它们都被称为*Test.java - 不要选择TestUtil.java或SystemTestUtil.java），右击它，选择 &quot;运行为&quot;，并选择 &quot;JUnit测试&quot;。 这将弹出一个JUnit标签，它将告诉你JUnit测试套件中各个测试的状态，并将显示异常和其他错误，这将有助于你调试问题。</p>
<p><strong>Running Ant Build Targets</strong></p>
<p>If you want to run commands such as &quot;ant test&quot; or &quot;ant systemtest,&quot; right click on build.xml in the Package Explorer. Select &quot;Run As,&quot; and then &quot;Ant Build...&quot; (note: select the option with the ellipsis (...), otherwise you won't be presented with a set of build targets to run). Then, in the &quot;Targets&quot; tab of the next screen, check off the targets you want to run (probably &quot;dist&quot; and one of &quot;test&quot; or &quot;systemtest&quot;). This should run the build targets and show you the results in Eclipse's console window.</p>
<p>如果你想运行 &quot;ant test &quot;或 &quot;ant systemtest &quot;这样的命令，在软件包资源管理器中右击build.xml。选择 &quot;Run As&quot;，然后选择 &quot;Ant Build...&quot;（注意：选择带省略号（...）的选项，否则你将不会看到一组要运行的构建目标）。然后，在下一个屏幕的 &quot;目标 &quot;选项卡中，选中你想运行的目标（可能是 &quot;dist &quot;和 &quot;test &quot;或 &quot;systemtest &quot;中的一个）。这应该会运行构建目标，并在 Eclipse 的控制台窗口中显示结果。</p>
<p><strong>Setting the Lab Up in IntelliJ</strong></p>
<p>IntelliJ is a more modern Java IDE that is popular and more intuitive to use by some accounts. To use IntelliJ, first install it and open the application. Similar to Eclipse, under Projects, select Open and navigate to your project root. Double-click on the .project file (you may need to configure your operating system to reveal hidden files to see it), and click &quot;open as project&quot;. IntelliJ has tool window support with Ant that you may want to setup according to instructions <a href="https://www.jetbrains.com/help/idea/ant.html">here</a>, but this is not essential to development. You can find a detailed walkthrough of IntelliJ features <a href="https://www.jetbrains.com/help/idea/discover-intellij-idea.html">here</a></p>
<p>IntelliJ是一个更现代的Java集成开发环境，在一些人看来，它很受欢迎，使用起来也更直观。要使用IntelliJ，首先安装它并打开应用程序。与Eclipse类似，在Projects下，选择Open并导航到你的项目根。双击.project文件（你可能需要配置你的操作系统以显示隐藏的文件来查看它），然后点击 &quot;作为项目打开&quot;。IntelliJ有Ant的工具窗口支持，你可能想根据说明[这里]（https://www.jetbrains.com/help/idea/ant.html）进行设置，但这对开发来说并不是必不可少的。你可以找到一个关于IntelliJ功能的详细介绍<a href="https://www.jetbrains.com/help/idea/discover-intellij-idea.html">这里</a></p>
<h3 id="13-implementation-hints"><a class="header" href="#13-implementation-hints">1.3. Implementation hints</a></h3>
<p>Before beginning to write code, we <strong>strongly encourage</strong> you to read through this entire document to get a feel for the high-level design of SimpleDB.</p>
<p>在开始写代码之前，我们***强烈建议你阅读整个文档，以了解SimpleDB的顶层设计。</p>
<p>
<p>You will need to fill in any piece of code that is not implemented. It will be obvious where we think you should write code. You may need to add private methods and/or helper classes. You may change APIs, but make sure our <a href="6.830/cn/2-lab1.html#grading">grading</a> tests still run and make sure to mention, explain, and defend your decisions in your writeup.</p>
<p>你将需要填写任何没有实现的代码。我们认为你应该在哪里写代码，这将是显而易见的。你可能需要添加私有方法和/或辅助类。你可以改变API，但要确保我们的<a href="6.830/cn/2-lab1.html#%E8%AF%84%E5%88%86">评分</a>测试仍然运行，并确保在你的写法中提到、解释和辩护你的决定。</p>
<p>
<p>In addition to the methods that you need to fill out for this lab, the class interfaces contain numerous methods that you need not implement until subsequent labs. These will either be indicated per class:</p>
<p>除了本实验需要填写的方法外，类的接口还包含许多方法，你需要在以后的实验中才能实现。这些方法或者会在每个类中注明。</p>
<pre><code class="language-java">// Not necessary for lab1.
public class Insert implements DbIterator {
</code></pre>
<p>or per method:</p>
<p>或每个方法。</p>
<pre><code class="language-Java">public boolean deleteTuple(Tuple t)throws DbException{
        // some code goes here
        // not necessary for lab1
        return false;
        }
</code></pre>
<p>The code that you submit should compile without having to modify these methods.</p>
<p>你提交的代码应该在不修改这些方法的情况下进行编译。</p>
<p>
<p>We suggest exercises along this document to guide your implementation, but you may find that a different order makes more sense for you.</p>
<p>我们建议沿着这份文件进行练习，以指导你的实施，但你可能发现不同的顺序对你更有意义。</p>
<p><strong>Here's a rough outline of one way you might proceed with your SimpleDB implementation:</strong></p>
<p><strong>以下是你可能进行SimpleDB实现的一个粗略轮廓：</strong>。</p>
<hr />
<ul>
<li>Implement the classes to manage tuples, namely Tuple, TupleDesc. We have already implemented Field, IntField,
StringField, and Type for you. Since you only need to support integer and (fixed length) string fields and fixed
length tuples, these are straightforward.</li>
<li>Implement the Catalog (this should be very simple).</li>
<li>Implement the BufferPool constructor and the getPage() method.</li>
<li>Implement the access methods, HeapPage and HeapFile and associated ID classes. A good portion of these files has
already been written for you.</li>
<li>Implement the operator SeqScan.</li>
<li>At this point, you should be able to pass the ScanTest system test, which is the goal for this lab.</li>
</ul>
<hr />
<ul>
<li>实现管理Tuple的类，即Tuple、TupleDesc。 我们已经实现了Field、IntField。
StringField，和Type给你。因为你只需要支持整数和（固定长度的）字符串字段以及固定长度的 tuples 。
长度的 tuples，这些都是简单明了的。</li>
<li>实现 catalog （这应该非常简单）。</li>
<li>实现BufferPool构造函数和getPage()方法。</li>
<li>实现访问方法，HeapPage和HeapFile以及相关的ID类。这些文件的很大一部分已经
已经为你写好了。</li>
<li>实现操作符SeqScan。</li>
<li>在这一点上，你应该能够通过ScanTest系统测试，这是本实验的目标。</li>
</ul>
<p>Section 2 below walks you through these implementation steps and the unit tests corresponding to each one in more detail.</p>
<p>下面的第2节将引导你更详细地了解这些实现步骤和每个步骤所对应的单元测试。</p>
<h3 id="14-transactions-locking-and-recovery"><a class="header" href="#14-transactions-locking-and-recovery">1.4. Transactions, locking, and recovery</a></h3>
<p>As you look through the interfaces we have provided you, you will see a number of references to locking, transactions, and recovery. You do not need to support these features in this lab, but you should keep these parameters in the interfaces of your code because you will be implementing transactions and locking in a future lab. The test code we have provided you with generates a fake transaction ID that is passed into the operators of the query it runs; you should pass this transaction ID into other operators and the buffer pool.</p>
<p>当你浏览我们提供给你的接口时，你会看到许多对锁、事务和恢复的引用。你不需要在这个实验中支持这些功能，但是你应该在你的代码的接口中保留这些参数，因为你将在未来的实验中实现事务和锁定。我们为你提供的测试代码会生成一个假的事务ID，并将其传递给它所运行的查询的操作者；你应该将这个事务ID传递给其他操作者和缓冲池。</p>
<h2 id="2-simpledb-architecture-and-implementation-guide"><a class="header" href="#2-simpledb-architecture-and-implementation-guide">2. SimpleDB Architecture and Implementation Guide</a></h2>
<p>SimpleDB consists of:</p>
<ul>
<li>Classes that represent fields, tuples, and tuple schemas;</li>
<li>Classes that apply predicates and conditions to tuples;</li>
<li>One or more access methods (e.g., heap files) that store relations on disk and provide a way to iterate through tuples of those relations;</li>
<li>A collection of operator classes (e.g., select, join, insert, delete, etc.) that process tuples;</li>
<li>A buffer pool that caches active tuples and pages in memory and handles concurrency control and transactions (neither of which you need to worry about for this lab); and,</li>
<li>A catalog that stores information about available tables and their schemas.</li>
</ul>
<p>SimpleDB由以下部分组成：</p>
<ul>
<li>代表字段、Tuple和Tuple模式的类。</li>
<li>对Tuple应用谓词和条件的类。</li>
<li>一个或多个访问方法（例如，堆文件），将关系存储在磁盘上，并提供一种方法来遍历这些关系的Tuple。</li>
<li>一个操作者类的集合（例如，选择、连接、插入、删除等），用于处理Tuple。</li>
<li>一个缓冲池，用于缓存内存中的活动Tuple和页面，并处理并发控制和事务（在本实验中你不需要担心这两点）；以及。</li>
<li>一个 catalog ，用于存储关于可用表和它们的模式的信息。</li>
</ul>
<p>SimpleDB does not include many things that you may think of as being a part of a &quot;database.&quot;  In particular, SimpleDB does not have:</p>
<p>SimpleDB不包括许多你可能认为是 &quot;数据库 &quot;一部分的东西。 特别是，SimpleDB没有。</p>
<ul>
<li>(In this lab), a SQL front end or parser that allows you to type queries directly into SimpleDB. Instead, queries are built up by chaining a set of operators together into a hand-built query plan (see <a href="6.830/cn/2-lab1.html#query_walkthrough">Section 2.7</a>). We will provide a simple parser for use in later labs.</li>
<li>Views.</li>
<li>Data types except integers and fixed length strings.</li>
<li>(In this lab) Query optimizer.</li>
<li>(In this lab) Indices.</li>
</ul>
<p>*（在本实验中），一个SQL前端或分析器，允许你直接向SimpleDB输入查询。取而代之的是，查询是通过将一组运算符串联到一个手工建立的查询计划中来建立的（见<a href="6.830/cn/2-lab1.html#query_walkthrough">2.7节</a>）。我们将提供一个简单的解析器，在后面的实验中使用。</p>
<ul>
<li>视图。</li>
<li>数据类型，除了整数和固定长度的字符串。</li>
<li>（在本实验中）查询优化器。</li>
<li>（在本实验中）索引。</li>
</ul>
<p>
<p>In the rest of this Section, we describe each of the main components of SimpleDB that you will need to implement in this lab. You should use the exercises in this discussion to guide your implementation. This document is by no means a complete specification for SimpleDB; you will need to make decisions about how to design and implement various parts of the system. Note that for Lab 1 you do not need to implement any operators (e.g., select, join, project) except sequential scan. You will add support for additional operators in future labs.</p>
<p>在本节的其余部分，我们将描述你在本实验中需要实现的SimpleDB的每个主要组件。你应该使用本讨论中的练习来指导你的实现。本文档绝不是SimpleDB的完整规范；你将需要对如何设计和实现系统的各个部分做出决定。注意，对于实验1，除了顺序扫描，你不需要实现任何操作符（例如，选择、连接、项目）。你将在未来的实验中增加对其他运算符的支持。</p>
<p>
<h3 id="21-the-database-class"><a class="header" href="#21-the-database-class">2.1. The Database Class</a></h3>
<p>The Database class provides access to a collection of static objects that are the global state of the database. In particular, this includes methods to access the catalog (the list of all the tables in the database), the buffer pool ( the collection of database file pages that are currently resident in memory), and the log file. You will not need to worry about the log file in this lab. We have implemented the Database class for you. You should take a look at this file as you will need to access these objects.</p>
<p>数据库类提供了对静态对象集合的访问，这些对象是数据库的全局状态。特别是，这包括访问 catalog （数据库中所有表的列表）、缓冲池（当前驻留在内存中的数据库文件页的集合）和日志文件的方法。在本实验中，你不需要担心日志文件的问题。我们已经为你实现了数据库类。你应该看一下这个文件，因为你将需要访问这些对象。</p>
<h3 id="22-fields-and-tuples"><a class="header" href="#22-fields-and-tuples">2.2. Fields and Tuples</a></h3>
<p>Tuples in SimpleDB are quite basic.  They consist of a collection of <code>Field</code> objects, one per field in the <code>Tuple</code>. <code>Field</code> is an interface that different data types (e.g., integer, string) implement.  <code>Tuple</code> objects are created by the underlying access methods (e.g., heap files, or B-trees), as described in the next section.  Tuples also have a type (or schema), called a <em>tuple descriptor</em>, represented by a <code>TupleDesc</code> object.  This object consists of a collection of <code>Type</code> objects, one per field in the tuple, each of which describes the type of the corresponding field.</p>
<p>SimpleDB中的元组是非常基本的。 它们由 &quot;字段 &quot;对象的集合组成，在 &quot;Tuple &quot;中每个字段一个。<code>Field</code>是一个接口，不同的数据类型（例如，整数，字符串）都可以实现。 <code>Tuple</code>对象是由底层访问方法（例如，堆文件，或B-树）创建的，如下一节所述。 元组也有一个类型（或模式），称为_元组描述符_，由<code>TupleDesc</code>对象表示。 这个对象由 &quot;类型 &quot;对象的集合组成，元组中的每个字段都有一个，每个对象都描述了相应字段的类型。</p>
<h3 id="exercise-1-2"><a class="header" href="#exercise-1-2">Exercise 1</a></h3>
<p><strong>Implement the skeleton methods in:</strong></p>
<hr />
<ul>
<li>src/java/simpledb/storage/TupleDesc.java</li>
<li>src/java/simpledb/storage/Tuple.java</li>
</ul>
<hr />
<p>At this point, your code should pass the unit tests TupleTest and TupleDescTest. At this point, modifyRecordId() should fail because you havn't implemented it yet.</p>
<p>在这一点上，你的代码应该通过单元测试TupleTest和TupleDescTest。在这一点上，modifyRecordId()应该失败，因为你还没有实现它。</p>
<h3 id="23-catalog"><a class="header" href="#23-catalog">2.3. Catalog</a></h3>
<p>The catalog (class <code>Catalog</code> in SimpleDB) consists of a list of the tables and schemas of the tables that are currently in the database. You will need to support the ability to add a new table, as well as getting information about a particular table. Associated with each table is a <code>TupleDesc</code> object that allows operators to determine the types and number of fields in a table.</p>
<p>catalog （SimpleDB中的<code>Catalog</code>类）由当前数据库中的表和表的模式的列表组成。你需要支持添加一个新的表的能力，以及获得一个特定表的信息。与每个表相关的是一个<code>TupleDesc</code>对象，它允许操作者确定一个表的字段类型和数量。</p>
<p>The global catalog is a single instance of <code>Catalog</code> that is allocated for the entire SimpleDB process. The global catalog can be retrieved via the method <code>Database.getCatalog()</code>, and the same goes for the global buffer pool (using <code>Database.getBufferPool()</code>).</p>
<p>全局 catalog 是一个单一的<code>Catalog</code>实例，为整个SimpleDB进程分配。全局 catalog 可以通过<code>Database.getCatalog()</code>方法来检索，全局缓冲池也是如此（使用<code>Database.getBufferPool()</code>）。</p>
<h3 id="exercise-2-2"><a class="header" href="#exercise-2-2">Exercise 2</a></h3>
<p><strong>Implement the skeleton methods in:</strong></p>
<hr />
<ul>
<li>src/java/simpledb/common/Catalog.java</li>
</ul>
<hr />
<p>At this point, your code should pass the unit tests in CatalogTest.</p>
<p>在这一点上，你的代码应该通过CatalogTest的单元测试。</p>
<h3 id="24-bufferpool"><a class="header" href="#24-bufferpool">2.4. BufferPool</a></h3>
<p>The buffer pool (class <code>BufferPool</code> in SimpleDB) is responsible for caching pages in memory that have been recently read from disk. All operators read and write pages from various files on disk through the buffer pool. It consists of a fixed number of pages, defined by the <code>numPages</code> parameter to the <code>BufferPool</code> constructor. In later labs, you will implement an eviction policy. For this lab, you only need to implement the constructor and the <code>BufferPool.getPage()</code> method used by the SeqScan operator. The BufferPool should store up to <code>numPages</code> pages. For this lab, if more than <code>numPages</code> requests are made for different pages, then instead of implementing an eviction policy, you may throw a DbException. In future labs you will be required to implement an eviction policy.</p>
<p>缓冲池（SimpleDB中的<code>BufferPool</code>类）负责在内存中缓存最近从磁盘读取的页面。所有的操作者通过缓冲池从磁盘上的各种文件读写页面。它由固定数量的页面组成，由<code>BufferPool</code>构造函数的<code>numPages</code>参数定义。在后面的实验中，你将实现一个驱逐策略。对于这个实验，你只需要实现构造函数和SeqScan操作者使用的<code>BufferPool.getPage()</code>方法。BufferPool应该最多存储<code>numPages</code>页。对于这个实验，如果对不同页面的请求超过<code>numPages</code>，那么你可以抛出一个DbException，而不是实施驱逐策略。在未来的实验中，你将被要求实现一个驱逐策略。</p>
<p>The <code>Database</code> class provides a static method, <code>Database.getBufferPool()</code>, that returns a reference to the single BufferPool instance for the entire SimpleDB process.</p>
<p>数据库 &quot;类提供了一个静态方法，&quot;Database.getBufferPool()&quot;，用于返回整个SimpleDB进程的单个BufferPool实例的引用。</p>
<h3 id="exercise-3-3"><a class="header" href="#exercise-3-3">Exercise 3</a></h3>
<p><strong>Implement the <code>getPage()</code> method in:</strong></p>
<hr />
<ul>
<li>src/java/simpledb/storage/BufferPool.java</li>
</ul>
<hr />
<p>We have not provided unit tests for BufferPool. The functionality you implemented will be tested in the implementation of HeapFile below. You should use the <code>DbFile.readPage</code> method to access pages of a DbFile.</p>
<p>我们没有为 BufferPool 提供单元测试。你实现的功能将在下面HeapFile的实现中得到测试。你应该使用<code>DbFile.readPage</code>方法来访问DbFile的页面。</p>
<!--
When more than this many pages are in the buffer pool, one page should be evicted from the pool before the next is loaded.  The choice of eviction policy is up to you; it is not necessary to do something sophisticated.

当缓冲池中的页面超过这个数量时，在加载下一个页面之前，应该将一个页面从缓冲池中驱逐出去。 驱逐策略的选择由你决定；没有必要做一些复杂的事情。

-->
<!--
<p>

Notice that `BufferPool` asks you to implement a `flush_all_pages()` method.  This is not something you would ever need in a real implementation of a buffer pool.  However, we need this method for testing purposes.  You really should never call this method from anywhere in your code.

注意`BufferPool`要求你实现`flush_all_pages()`方法。 这不是你在真正实现缓冲池时需要的东西。 然而，我们需要这个方法用于测试。 你真的不应该在你的代码中的任何地方调用这个方法。

-->
<h3 id="25-heapfile-access-method"><a class="header" href="#25-heapfile-access-method">2.5. HeapFile access method</a></h3>
<p>Access methods provide a way to read or write data from disk that is arranged in a specific way. Common access methods include heap files (unsorted files of tuples) and B-trees; for this assignment, you will only implement a heap file access method, and we have written some of the code for you.</p>
<p>访问方法提供了一种从磁盘读取或写入以特定方式排列的数据的方法。常见的访问方法包括堆文件（未经排序的 tuple 文件）和 B 树；对于这项作业，你将只实现一个堆文件访问方法，我们已经为你写了一些代码。</p>
<p>
<p>A <code>HeapFile</code> object is arranged into a set of pages, each of which consists of a fixed number of bytes for storing tuples, (defined by the constant <code>BufferPool.DEFAULT_PAGE_SIZE</code>), including a header. In SimpleDB, there is one <code>HeapFile</code> object for each table in the database. Each page in a <code>HeapFile</code> is arranged as a set of slots, each of which can hold one tuple (tuples for a given table in SimpleDB are all of the same size). In addition to these slots, each page has a header that consists of a bitmap with one bit per tuple slot. If the bit corresponding to a particular tuple is 1, it indicates that the tuple is valid; if it is 0, the tuple is invalid (e.g., has been deleted or was never initialized.)  Pages of <code>HeapFile</code> objects are of type <code>HeapPage</code> which implements the <code>Page</code> interface. Pages are stored in the buffer pool but are read and written by the <code>HeapFile</code> class.</p>
<p>一个<code>HeapFile</code>对象被安排成一组页面，每个页面由固定数量的字节组成，用于存储 tuple ，（由常数<code>BufferPool.DEFAULT_PAGE_SIZE</code>定义），包括一个头。在SimpleDB中，数据库中每个表都有一个<code>HeapFile</code>对象。<code>HeapFile</code>中的每个页面被安排为一组槽，每个槽可以容纳一个元组（SimpleDB中一个给定的表的元组都是相同大小的）。除了这些槽之外，每个页面都有一个头，由一个位图组成，每个元组槽有一个位。如果某个元组对应的位是1，表示该元组是有效的；如果是0，表示该元组是无效的（例如，已经被删除或者从未被初始化）。 <code>HeapFile</code>对象的页是<code>HeapPage</code>类型，实现了<code>Page</code>接口。页被存储在缓冲池中，但由<code>HeapFile</code>类来读写。</p>
<p>
<p>SimpleDB stores heap files on disk in more or less the same format they are stored in memory. Each file consists of page data arranged consecutively on disk. Each page consists of one or more bytes representing the header, followed by the _ page size_ bytes of actual page content. Each tuple requires <em>tuple size</em> * 8 bits for its content and 1 bit for the header. Thus, the number of tuples that can fit in a single page is:</p>
<p>SimpleDB在磁盘上存储堆文件的格式或多或少与它们在内存中的存储格式相同。每个文件由磁盘上连续排列的页面数据组成。每个页面由一个或多个代表头的字节组成，然后是实际页面内容的_页面大小_字节。每个元组的内容需要_元组大小_*8位，页眉需要1位。因此，一个页面中可以容纳的 tuple 数量是。</p>
<p>
<p><code>_tuples per page_ = floor((_page size_ * 8) / (_tuple size_ * 8 + 1))</code></p>
<p>
<p>Where <em>tuple size</em> is the size of a tuple in the page in bytes. The idea here is that each tuple requires one additional bit of storage in the header. We compute the number of bits in a page (by mulitplying page size by 8), and divide this quantity by the number of bits in a tuple (including this extra header bit) to get the number of tuples per page. The floor operation rounds down to the nearest integer number of tuples (we don't want to store partial tuples on a page!)</p>
<p>其中_tuple size_是页面中一个元组的大小，单位是字节。这里的想法是，每个元组需要在头中增加一个比特的存储。我们计算一个页面中的比特数（通过将页面大小乘以8），然后用这个数量除以元组中的比特数（包括这个额外的头部比特），得到每页的元组数。下限操作将四舍五入到最接近的 tuple 数（我们不想在一个页面上存储部分 tuple ！）。</p>
<p>
<p>Once we know the number of tuples per page, the number of bytes required to store the header is simply:</p>
<p>一旦我们知道了每页的 tuple 数，存储页眉所需的字节数就简单了。</p>
<p>
<p><code>headerBytes = ceiling(tupsPerPage/8)</code></p>
<p>
<p>The ceiling operation rounds up to the nearest integer number of bytes (we never store less than a full byte of header information.)</p>
<p>上限操作四舍五入到最接近的整数字节（我们永远不会存储少于一个完整字节的头信息）。</p>
<p>
<p>The low (least significant) bits of each byte represents the status of the slots that are earlier in the file. Hence, the lowest bit of the first byte represents whether or not the first slot in the page is in use. The second lowest bit of the first byte represents whether or not the second slot in the page is in use, and so on. Also, note that the high-order bits of the last byte may not correspond to a slot that is actually in the file, since the number of slots may not be a multiple of 8. Also note that all Java virtual machines are <a href="http://en.wikipedia.org/wiki/Endianness">big-endian</a>.</p>
<p>每个字节的低位（最小有效位）代表文件中较早的槽位的状态。因此，第一个字节的最低位代表页面中的第一个槽是否正在使用。第一个字节的第二个最低位代表页面中的第二个槽是否在使用中，以此类推。另外，请注意，最后一个字节的高阶位可能不对应于文件中实际存在的槽，因为槽的数量可能不是8的倍数。还要注意，所有的Java虚拟机都是<a href="http://en.wikipedia.org/wiki/Endianness">big-endian</a>。</p>
<p>
<h3 id="exercise-4-3"><a class="header" href="#exercise-4-3">Exercise 4</a></h3>
<p><strong>Implement the skeleton methods in:</strong></p>
<hr />
<ul>
<li>src/java/simpledb/storage/HeapPageId.java</li>
<li>src/java/simpledb/storage/RecordId.java</li>
<li>src/java/simpledb/storage/HeapPage.java</li>
</ul>
<hr />
<p>Although you will not use them directly in Lab 1, we ask you to implement <code>getNumEmptySlots()</code> and <code>isSlotUsed()</code> in HeapPage. These require pushing around bits in the page header. You may find it helpful to look at the other methods that have been provided in HeapPage or in <code>src/simpledb/HeapFileEncoder.java</code> to understand the layout of pages.</p>
<p>尽管你不会在实验1中直接使用它们，但我们要求你在HeapPage中实现<code>getNumEmptySlots()</code>和<code>isSlotUsed()</code>。这些都需要在页头中推送一些位。你可能会发现查看HeapPage或<code>src/simpledb/HeapFileEncoder.java</code>中提供的其他方法对理解页面的布局有帮助。</p>
<p>You will also need to implement an Iterator over the tuples in the page, which may involve an auxiliary class or data structure.</p>
<p>你还需要在页面中的 tuple 上实现一个迭代器，这可能涉及一个辅助类或数据结构。</p>
<p>At this point, your code should pass the unit tests in HeapPageIdTest, RecordIDTest, and HeapPageReadTest.</p>
<p>在这一点上，你的代码应该通过HeapPageIdTest、RecordIDTest和HeapPageReadTest的单元测试。</p>
<p> 
<p>After you have implemented <code>HeapPage</code>, you will write methods for <code>HeapFile</code> in this lab to calculate the number of pages in a file and to read a page from the file. You will then be able to fetch tuples from a file stored on disk.</p>
<p>在你实现了 &quot;HeapPage &quot;之后，你将在本实验中为 &quot;HeapFile &quot;编写方法，以计算文件中的页数，并从文件中读取一个页。然后你将能够从存储在磁盘上的文件中获取 tuple 。</p>
<h3 id="exercise-5-3"><a class="header" href="#exercise-5-3">Exercise 5</a></h3>
<p><strong>Implement the skeleton methods in:</strong></p>
<hr />
<ul>
<li>src/java/simpledb/storage/HeapFile.java</li>
</ul>
<hr />
<p>To read a page from disk, you will first need to calculate the correct offset in the file. </p>
<p>要从磁盘上读取一个页面，你首先需要计算出文件中的正确偏移量。</p>
<p>Hint: you will need random access to the file in order to read and write pages at arbitrary offsets. You should not call BufferPool methods when reading a page from disk.</p>
<p>提示：你需要对文件进行随机访问，以便在任意的偏移量上读写页面。当从磁盘上读取一个页面时，你不应该调用BufferPool方法。</p>
<p> 
<p>You will also need to implement the <code>HeapFile.iterator()</code> method, which should iterate through through the tuples of each page in the HeapFile. The iterator must use the <code>BufferPool.getPage()</code> method to access pages in the <code>HeapFile</code>. This method loads the page into the buffer pool and will eventually be used (in a later lab) to implement locking-based concurrency control and recovery.  Do not load the entire table into memory on the open() call -- this will cause an out of memory error for very large tables.</p>
<p>你还需要实现<code>HeapFile.iterator()</code>方法，它应该遍历HeapFile中每个页面的 tuple 。迭代器必须使用<code>BufferPool.getPage()</code>方法来访问<code>HeapFile</code>中的页面。这个方法将页面加载到缓冲池中，最终将被用于（在后面的实验中）实现基于锁的并发控制和恢复。 不要在open()调用时将整个表加载到内存中 -- 这将导致非常大的表出现内存不足的错误。</p>
<p>
<p>At this point, your code should pass the unit tests in HeapFileReadTest.</p>
<p>在这一点上，你的代码应该通过HeapFileReadTest的单元测试。</p>
<h3 id="26-operators"><a class="header" href="#26-operators">2.6. Operators</a></h3>
<p>Operators are responsible for the actual execution of the query plan. They implement the operations of the relational algebra. In SimpleDB, operators are iterator based; each operator implements the <code>DbIterator</code> interface.</p>
<p>操作员负责查询计划的实际执行。他们实现了关系代数的操作。在SimpleDB中，操作符是基于迭代器的；每个操作符实现了`DbIterator'接口。</p>
<p>
<p>Operators are connected together into a plan by passing lower-level operators into the constructors of higher-level operators, i.e., by 'chaining them together.' Special access method operators at the leaves of the plan are responsible for reading data from the disk (and hence do not have any operators below them).</p>
<p>操作符通过将低级别的操作符传递到高级别的操作符的构造器中，即通过 &quot;连锁 &quot;将它们连接到一个计划中。在计划叶子上的特殊访问方法运算符负责从磁盘上读取数据（因此没有下面的任何运算符）。</p>
<p>
<p>At the top of the plan, the program interacting with SimpleDB simply calls <code>getNext</code> on the root operator; this operator then calls <code>getNext</code> on its children, and so on, until these leaf operators are called. They fetch tuples from disk and pass them up the tree (as return arguments to <code>getNext</code>); tuples propagate up the plan in this way until they are output at the root or combined or rejected by another operator in the plan.</p>
<p>在计划的顶部，与SimpleDB交互的程序只需在根操作符上调用<code>getNext</code>；这个操作符接着在其子操作符上调用<code>getNext</code>，以此类推，直到这些叶操作符被调用。他们从磁盘中获取 tuple ，并将其传递到树上（作为<code>getNext</code>的返回参数）； tuple 以这种方式在计划中传播，直到它们在根部输出或被计划中的另一个运算符合并或拒绝。</p>
<p>
<!--

For plans that implement `INSERT` and `DELETE` queries, the top-most operator is a special `Insert` or `Delete` operator that modifies the pages on disk.  These operators return a tuple containing the count of the number of affected tuples to the user-level program.

对于实现`INSERT'和`DELETE'查询的计划，最上面的运算符是一个特殊的`Insert'或`Delete'运算符，它修改了磁盘上的页面。 这些操作符向用户级程序返回一个包含受影响 tuple 数量的计数。

<p>
-->
<p>For this lab, you will only need to implement one SimpleDB operator.</p>
<p>对于这个实验，你只需要实现一个SimpleDB操作符。</p>
<h3 id="exercise-6-1"><a class="header" href="#exercise-6-1">Exercise 6.</a></h3>
<p><strong>Implement the skeleton methods in:</strong></p>
<hr />
<ul>
<li>src/java/simpledb/execution/SeqScan.java</li>
</ul>
<hr />
<p>This operator sequentially scans all of the tuples from the pages of the table specified by the <code>tableid</code> in the constructor. This operator should access tuples through the <code>DbFile.iterator()</code> method.</p>
<p>这个操作者从构造函数中的<code>tableid</code>指定的表中的页面中顺序扫描所有 tuple 。这个操作符应该通过<code>DbFile.iterator()</code>方法访问 tuple 。</p>
<p>At this point, you should be able to complete the ScanTest system test. Good work!</p>
<p>在这一点上，你应该能够完成ScanTest系统测试。干得好!</p>
<p>You will fill in other operators in subsequent labs.</p>
<p>你将在随后的实验中填写其他 operators 。</p>
<p><a name="query_walkthrough"></a></p>
<h3 id="27-a-simple-query"><a class="header" href="#27-a-simple-query">2.7. A simple query</a></h3>
<p>The purpose of this section is to illustrate how these various components are connected together to process a simple query.</p>
<p>本节的目的是说明这些不同的组件是如何连接在一起以处理一个简单的查询。</p>
<p>Suppose you have a data file, &quot;some_data_file.txt&quot;, with the following contents:</p>
<p>假设你有一个数据文件，&quot;some_data_file.txt&quot;，其内容如下。</p>
<pre><code>1,1,1
2,2,2 
3,4,4
</code></pre>
<p>
You can convert this into a binary file that SimpleDB can query as follows:
<p>你可以将其转换成SimpleDB可以查询的二进制文件，如下所示。</p>
<p>
```java -jar dist/simpledb.jar convert some_data_file.txt 3```
<p>
Here, the argument "3" tells conver that the input has 3 columns.
<p>这里，参数 &quot;3 &quot;告诉Conver，输入有3列。</p>
<p>
The following code implements a simple selection query over this file. This code is equivalent to the SQL statement `SELECT * FROM some_data_file`.
<p>下面的代码在这个文件上实现了一个简单的选择查询。这段代码等同于SQL语句<code>SELECT * FROM some_data_file</code>。</p>
<pre><code>package simpledb;
import java.io.*;

public class test {

    public static void main(String[] argv) {

        // construct a 3-column table schema
        Type types[] = new Type[]{ Type.INT_TYPE, Type.INT_TYPE, Type.INT_TYPE };
        String names[] = new String[]{ &quot;field0&quot;, &quot;field1&quot;, &quot;field2&quot; };
        TupleDesc descriptor = new TupleDesc(types, names);

        // create the table, associate it with some_data_file.dat
        // and tell the catalog about the schema of this table.
        HeapFile table1 = new HeapFile(new File(&quot;some_data_file.dat&quot;), descriptor);
        Database.getCatalog().addTable(table1, &quot;test&quot;);

        // construct the query: we use a simple SeqScan, which spoonfeeds
        // tuples via its iterator.
        TransactionId tid = new TransactionId();
        SeqScan f = new SeqScan(tid, table1.getId());

        try {
            // and run it
            f.open();
            while (f.hasNext()) {
                Tuple tup = f.next();
                System.out.println(tup);
            }
            f.close();
            Database.getBufferPool().transactionComplete(tid);
        } catch (Exception e) {
            System.out.println (&quot;Exception : &quot; + e);
        }
    }

}
</code></pre>
<p>The table we create has three integer fields. To express this, we create a <code>TupleDesc</code> object and pass it an array of <code>Type</code> objects, and optionally an array of <code>String</code> field names. Once we have created this <code>TupleDesc</code>, we initialize a <code>HeapFile</code> object representing the table stored in <code>some_data_file.dat</code>. Once we have created the table, we add it to the catalog. If this were a database server that was already running, we would have this catalog information loaded. We need to load it explicitly to make this code self-contained.</p>
<p>我们创建的表有三个整数字段。为了表达这一点，我们创建了一个<code>TupleDesc</code>对象，并传递给它一个<code>Type</code>对象数组，还有一个<code>String</code>字段名数组。一旦我们创建了这个<code>TupleDesc</code>，我们就初始化一个<code>HeapFile</code>对象，代表存储在<code>some_data_file.dat</code>的表。一旦我们创建了这个表，我们就把它添加到 catalog 中。如果这是一个已经在运行的数据库服务器，我们会加载这个 catalog 信息。我们需要明确地加载它，使这段代码自成一体。</p>
<p>Once we have finished initializing the database system, we create a query plan. Our plan consists only of the <code>SeqScan</code> operator that scans the tuples from disk. In general, these operators are instantiated with references to the appropriate table (in the case of <code>SeqScan</code>) or child operator (in the case of e.g. Filter). The test program then repeatedly calls <code>hasNext</code> and <code>next</code> on the <code>SeqScan</code> operator. As tuples are output from the <code>SeqScan</code>, they are printed out on the command line.</p>
<p>一旦我们完成了数据库系统的初始化，我们就创建一个查询计划。我们的计划只由<code>SeqScan</code>操作符组成，它从磁盘上扫描 tuple 。一般来说，这些操作符的实例化需要引用相应的表（在<code>SeqScan</code>的情况下）或子操作符（在例如Filter的情况下）。然后测试程序在<code>SeqScan</code>运算符上反复调用<code>hasNext</code>和<code>next</code>。当 tuple 从<code>SeqScan</code>中输出时，它们会在命令行中打印出来。</p>
<p>We <strong>strongly recommend</strong> you try this out as a fun end-to-end test that will help you get experience writing your own test programs for simpledb. You should create the file &quot;test.java&quot; in the src/java/simpledb directory with the code above,  and you should add some &quot;import&quot; statement above the code,  and place the <code>some_data_file.dat</code> file in the top level directory. Then run:</p>
<p>我们***强烈建议你尝试一下，作为一个有趣的端到端测试，它将帮助你获得为simpledb编写自己的测试程序的经验。你应该在 src/java/simpledb  catalog 中用上面的代码创建 &quot;test.java &quot;文件，你应该在代码上方添加一些 &quot;import &quot;语句，并将 <code>some_data_file.dat</code>文件放在顶层 catalog 中。然后运行</p>
<pre><code>ant
java -classpath dist/simpledb.jar simpledb.test
</code></pre>
<p>Note that <code>ant</code> compiles <code>test.java</code> and generates a new jarfile that contains it.</p>
<p>注意，<code>ant</code>编译<code>test.java</code>并生成一个包含它的新jarfile。</p>
<h2 id="3-logistics"><a class="header" href="#3-logistics">3. Logistics</a></h2>
<p>You must submit your code (see below) as well as a short (2 pages, maximum) writeup describing your approach. This writeup should:</p>
<p>你必须提交你的代码（见下文），以及描述你的方法的简短（最多两页）的文章。这篇报告应该</p>
<ul>
<li>
<p>Describe any design decisions you made. These may be minimal for Lab 1.</p>
</li>
<li>
<p>Discuss and justify any changes you made to the API.</p>
</li>
<li>
<p>Describe any missing or incomplete elements of your code.</p>
</li>
<li>
<p>Describe how long you spent on the lab, and whether there was anything you found particularly difficult or confusing.</p>
</li>
<li>
<p>描述你做出的任何设计决定。这些可能是实验1的最低限度。</p>
</li>
<li>
<p>讨论并论证你对API所做的任何修改。</p>
</li>
<li>
<p>描述你的代码中任何缺失或不完整的元素。</p>
</li>
<li>
<p>描述你花了多长时间做这个实验，以及是否有任何你认为特别困难或困惑的事情。</p>
</li>
</ul>
<h3 id="31-collaboration"><a class="header" href="#31-collaboration">3.1. Collaboration</a></h3>
<p>This lab should be manageable for a single person, but if you prefer to work with a partner, this is also OK. Larger groups are not allowed. Please indicate clearly who you worked with, if anyone, on your individual writeup.</p>
<p>这个实验对一个人来说应该是可以应付的，但如果你喜欢和一个伙伴一起工作，这也是可以的。不允许有较大的团体。如果有的话，请在你的个人报告中明确指出你和谁一起工作。</p>
<h3 id="32-submitting-your-assignment"><a class="header" href="#32-submitting-your-assignment">3.2. Submitting your assignment</a></h3>
<!--

To submit your code, please create a `6.830-lab1.tar.gz` tarball (such that, untarred, it creates a `6.830-lab1/src/simpledb` directory with your code) and submit it on the [6.830 Stellar Site](https://stellar.mit.edu/S/course/6/sp13/6.830/index.html). You can use the `ant handin` target to generate the tarball.

要提交你的代码，请创建一个`6.830-lab1.tar.gz`的压缩包（这样，未经压缩的压缩包会创建一个`6.830-lab1/src/simpledb` catalog ，里面有你的代码），并提交到[6.830 Stellar Site]（https://stellar.mit.edu/S/course/6/sp13/6.830/index.html）。你可以使用`ant handin`目标来生成tarball。
-->
<p>We will be using gradescope to autograde all programming assignments. You should have all been invited to the class instance; if not, please check piazza for an invite code. If you are still having trouble, let us know and we can help you set up. You may submit your code multiple times before the deadline; we will use the latest version as determined by gradescope. Place the write-up in a file called lab1-writeup.txt with your submission. You also need to explicitly add any other files you create, such as new *.java files.</p>
<p>我们将使用gradescope对所有编程作业进行自动评分。你们应该都被邀请到班级实例中去了；如果没有，请在piazza上查询邀请码。如果你仍然有问题，请告诉我们，我们可以帮助你设置。你可以在截止日期前多次提交你的代码；我们将使用由gradescope确定的最新版本。把写好的东西放在一个叫lab1-writeup.txt的文件里，和你的提交一起。你还需要明确地添加你创建的任何其他文件，如新的*.java文件。</p>
<p>The easiest way to submit to gradescope is with <code>.zip</code> files containing your code. On Linux/MacOS, you can do so by running the following command:</p>
<p>向 gradescope 提交的最简单方法是使用包含你的代码的 <code>.zip</code> 文件。在Linux/MacOS上，你可以通过运行以下命令来实现。</p>
<pre><code class="language-bash">$ zip -r submission.zip src/ lab1-writeup.txt
</code></pre>
<h3 id="33-submitting-a-bug"><a class="header" href="#33-submitting-a-bug">3.3. Submitting a bug</a></h3>
<p>Please submit (friendly!) bug reports to <a href="mailto:6.830-staff@mit.edu">6.830-staff@mit.edu</a>. When you do, please try to include:</p>
<p>请提交（友好的！）错误报告到<a href="mailto:6.830-staff@mit.edu">6.830-staff@mit.edu</a>。当你这样做时，请尽量包括。</p>
<ul>
<li>
<p>A description of the bug.</p>
</li>
<li>
<p>A .java file we can drop in the test/simpledb directory, compile, and run.</p>
</li>
<li>
<p>A .txt file with the data that reproduces the bug. We should be able to convert it to a .dat file using
HeapFileEncoder.</p>
</li>
<li>
<p>一个关于该错误的描述。</p>
</li>
<li>
<p>一个.java文件，我们可以把它放到test/simpledb catalog 中，编译并运行。</p>
</li>
<li>
<p>一个带有再现该错误的数据的.txt文件。我们应该能够使用HeapFileEncoder将其转换为一个.dat文件。
HeapFileEncoder.</p>
</li>
</ul>
<p>If you are the first person to report a particular bug in the code, we will give you a candy bar!</p>
<p>如果你是第一个报告代码中某一特定错误的人，我们将给你一个糖果棒!</p>
<!--The latest bug reports/fixes can be found [here](bugs.html).-->
<p><a name="grading"></a></p>
<h3 id="34-grading"><a class="header" href="#34-grading">3.4 Grading</a></h3>
<p>
<p>75% of your grade will be based on whether or not your code passes the system test suite we will run over it. </p>
<p>你的成绩的75%将基于你的代码是否通过我们将对其进行的系统测试套件。</p>
<p>These tests will be a superset of the tests we have provided. Before handing in your code, you should make sure it produces no errors (passes all of the tests) from both  <code>ant test</code> and <code>ant systemtest</code>.</p>
<p>这些测试将是我们提供的测试的超集。在提交你的代码之前，你应该确保它在<code>ant test</code>和<code>ant systemtest</code>中没有产生错误（通过所有的测试）。</p>
<p><strong>Important:</strong> before testing, gradescope will replace your <code>build.xml</code> and the entire contents of the <code>test</code> directory with our version of these files. This means you cannot change the format of <code>.dat</code> files!  You should also be careful changing our APIs. You should test that your code compiles the unmodified tests.</p>
<p>**重要的是：**在测试之前，gradescope将用我们的这些文件的版本替换你的<code>build.xml</code>和<code>test</code> catalog 中的全部内容。这意味着你不能改变<code>.dat</code>文件的格式!  你也应该小心改变我们的API。你应该测试你的代码是否能编译未修改的测试。</p>
<p>You should get immediate feedback and error outputs for failed tests (if any) from gradescope after submission. The score given will be your grade for the autograded portion of the assignment. An additional 25% of your grade will be based on the quality of your writeup and our subjective evaluation of your code. This part will also be published on gradescope after we finish grading your assignment.</p>
<p>在提交后，你应该从gradescope获得即时反馈和失败测试的错误输出（如果有的话）。给出的分数将是你在作业的自动评分部分的成绩。另外25%的分数将基于你的写作质量和我们对你代码的主观评价。这一部分也将在我们完成作业评分后公布在gradescope上。</p>
<p>We had a lot of fun designing this assignment, and we hope you enjoy hacking on it!</p>
<p>我们在设计这项任务时有很多乐趣，我们希望你喜欢在这上面 hacking。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-2-翻译"><a class="header" href="#lab-2-翻译">Lab 2 翻译</a></h1>
<p><strong>Assigned: Tue, Mar 9, 2021</strong><br>
<strong>Due: Fri, Mar 19, 2021 11:59 PM EDT</strong></p>
<!--
Version History:


3/1/12 : Initial version
-->
<p>In this lab assignment, you will write a set of operators for SimpleDB to implement table modifications (e.g., insert and delete records), selections, joins, and aggregates. These will build on top of the foundation that you wrote in Lab 1 to provide you with a database system that can perform simple queries over multiple tables.</p>
<p>在这个实验任务中，你将为 SimpleDB 编写一组操作符，以实现表的修改（如插入和删除记录）、选择、连接和聚合。这些将建立在你在实验1中编写的基础之上，为你提供一个可以对多个表进行简单查询的数据库系统。</p>
<p>Additionally, we ignored the issue of buffer pool management in Lab 1: we have not dealt with the problem that arises when we reference more pages than we can fit in memory over the lifetime of the database. In Lab 2, you will design an eviction policy to flush stale pages from the buffer pool.</p>
<p>此外，我们在实验1中忽略了缓冲池管理的问题：我们没有处理当我们引用的页面超过了数据库生命周期内所能容纳的内存时出现的问题。在实验2中，你将设计一个驱逐策略，从缓冲池中冲走陈旧的页面。</p>
<p>You do not need to implement transactions or locking in this lab.</p>
<p>你不需要在这个实验中实现事务或锁定。</p>
<p>The remainder of this document gives some suggestions about how to start coding, describes a set of exercises to help you work through the lab, and discusses how to hand in your code. This lab requires you to write a fair amount of code, so we encourage you to <strong>start early</strong>!</p>
<p>本文件的其余部分给出了一些关于如何开始编码的建议，描述了一组练习，以帮助你完成实验的工作，并讨论了如何交出你的代码。这个实验需要你写相当数量的代码，所以我们鼓励你<strong>早开始</strong>!</p>
<p><a name="starting"></a></p>
<h2 id="1-getting-started-1"><a class="header" href="#1-getting-started-1">1. Getting started</a></h2>
<p>You should begin with the code you submitted for Lab 1 (if you did not submit code for Lab 1, or your solution didn't work properly, contact us to discuss options).  Additionally, we are providing extra source and test files for this lab that are not in the original code distribution you received.</p>
<p>你应该从你为实验 1 提交的代码开始（如果你没有为实验1提交代码，或者你的解决方案没有正常工作，请与我们联系，讨论各种选择）。 此外，我们还为这个实验提供了额外的源文件和测试文件，这些文件不在你收到的原始代码分发中。</p>
<h3 id="11-getting-lab-2"><a class="header" href="#11-getting-lab-2">1.1. Getting Lab 2</a></h3>
<p>You will need to add these new files to your release. The easiest way to do this is to navigate to your project directory (probably called simple-db-hw) and pull from the master GitHub repository:</p>
<p>你将需要把这些新文件添加到你的版本中。最简单的方法是导航到你的项目目录（可能叫simple-db-hw），然后从GitHub的主仓库拉出。</p>
<pre><code>$ cd simple-db-hw
$ git pull upstream master
</code></pre>
<p><strong>IDE users</strong> will have update their project dependency to include the new library jars. For an easy solution, run</p>
<p><strong>IDE用户</strong>将不得不更新他们的项目依赖关系，以包括新的库的jars。对于一个简单的解决方案，运行</p>
<pre><code>ant eclipse
</code></pre>
<p>again, and reopen the project with either Eclipse or IntelliJ. </p>
<p>再一次，用Eclipse或IntelliJ重新打开项目。</p>
<p>If you have made other changes to your project setup and do not want to lose them, you can also add the dependencies manually. For eclipse, under the package explorer, right click the project name (probably <code>simple-db-hw</code>),  and select <strong>Properties</strong>.  Choose <strong>Java Build Path</strong> on the left-hand-side, and click on the <strong>Libraries</strong> tab on the right-hand-side.  Push the <strong>Add JARs...</strong> button, select <strong>zql.jar</strong> and <strong>jline-0.9.94.jar</strong>, and push <strong>OK</strong>, followed by <strong>OK</strong>.  Your code should now compile. For IntelliJ, go to <strong>Project Structure</strong> under <strong>File</strong>, and under <strong>Modules</strong>, select the <code>simpledb</code> project, and navigate to the <strong>Dependencies</strong> tab. On the bottom of the pane, click on the <code>+</code> icon to add the jars as compile-time dependencies. </p>
<p>如果你已经对你的项目设置做了其他的修改，并且不想失去它们，你也可以手动添加依赖关系。对于eclipse，在包资源管理器下，右击项目名称（可能是<code>simple-db-hw</code>），并选择<strong>属性</strong>。 在左侧选择<strong>Java Build Path</strong>，并点击右侧的<strong>Libraries</strong>标签。 按下<strong>添加JARs...<strong>按钮，选择</strong>zql.jar</strong>和<strong>jline-0.9.94.jar</strong>，然后按下<strong>OK</strong>，接着按下<strong>OK</strong>。 你的代码现在应该可以编译了。对于IntelliJ，进入<strong>文件下的</strong>项目结构，在<strong>模块下，选择<code>simpledb</code>项目，并导航到</strong>依赖关系**标签。在窗格的底部，点击 &quot;+&quot;图标，将罐子添加为编译时的依赖项。</p>
<h3 id="12-implementation-hints"><a class="header" href="#12-implementation-hints">1.2. Implementation hints</a></h3>
<p>As before, we <strong>strongly encourage</strong> you to read through this entire document to get a feel for the high-level design of SimpleDB before you write code.</p>
<p>和以前一样，我们<strong>强烈建议</strong>你在写代码之前通读整个文档以了解SimpleDB的顶层设计。</p>
<p>We suggest exercises along this document to guide your implementation, but you may find that a different order makes more sense for you. As before, we will grade your assignment by looking at your code and verifying that you have passed the test for the ant targets <code>test</code> and <code>systemtest</code>. Note the code only needs to pass the tests we indicate in this lab, not all of unit and system tests. See Section 3.4 for a complete discussion of grading and list of the tests you will need to pass.</p>
<p>我们建议沿着这份文件进行练习，以指导你的实施，但你可能会发现不同的顺序对你更有意义。和以前一样，我们将通过查看你的代码并验证你是否通过了 ant 目标<code>test</code>和<code>systemtest</code>的测试来给你的作业评分。请注意，代码只需要通过我们在这个实验中指出的测试，而不是所有的单元和系统测试。关于分级的完整讨论和你需要通过的测试列表，见第3.4节。</p>
<p>Here's a rough outline of one way you might proceed with your SimpleDB implementation; more details on the steps in this outline, including exercises, are given in Section 2 below.</p>
<p>下面是你可能进行SimpleDB实现的一个粗略的大纲；关于这个大纲中的步骤的更多细节，包括练习，在下面第2节中给出。</p>
<ul>
<li>Implement the operators <code>Filter</code> and <code>Join</code> and verify that their corresponding tests work. The Javadoc comments for these operators contain details about how they should work. We have given you implementations of <code>Project</code> and <code>OrderBy</code> which may help you understand how other operators work.</li>
</ul>
<p>实现运算符<code>Filter</code>和<code>Join</code>，并验证其相应的测试是否有效。这些操作符的 Javadoc 注释包含了关于它们如何工作的细节。我们已经给你提供了 <code>Project</code> 和 <code>OrderBy</code> 的实现，这可能有助于你理解其他操作符的工作。</p>
<ul>
<li>Implement <code>IntegerAggregator</code> and <code>StringAggregator</code>. Here, you will write the logic that actually computes an aggregate over a particular field across multiple groups in a sequence of input tuples. Use integer division for computing the average, since SimpleDB only supports integers. StringAggegator only needs to support the COUNT aggregate, since the other operations do not make sense for strings.</li>
</ul>
<p>实现 <code>IntegerAggregator</code> 和 <code>StringAggregator</code> 。在这里，你将编写一个逻辑，实际计算一个特定字段在输入 tuple 序列的多个组中的聚合。使用整数除法来计算平均数，因为 SimpleDB 只支持整数。StringAggegator 只需要支持 COUNT 聚合，因为其他操作对字符串没有意义。</p>
<ul>
<li>Implement the <code>Aggregate</code> operator. As with other operators, aggregates implement the <code>OpIterator</code> interface so that they can be placed in SimpleDB query plans. Note that the output of an <code>Aggregate</code> operator is an aggregate value of an entire group for each call to <code>next()</code>, and that the aggregate constructor takes the aggregation and grouping fields.</li>
</ul>
<p>实现<code>Aggregate</code>操作符。和其他运算符一样，聚合运算符实现了 <code>OpIterator</code> 接口，这样它们就可以放在 SimpleDB 查询计划中。注意<code>Aggregate</code>运算符的输出是每次调用<code>next()</code>时整个组的聚合值，并且聚合构造器需要聚合和分组字段。</p>
<ul>
<li>Implement the methods related to tuple insertion, deletion, and page eviction in <code>BufferPool</code>. You do not need to worry about transactions at this point.</li>
</ul>
<p>在 <code>BufferPool</code> 中实现与元组插入、删除和页面驱逐有关的方法。在这一点上，你不需要担心 transactions 的问题。</p>
<ul>
<li>Implement the <code>Insert</code> and <code>Delete</code> operators. Like all operators,  <code>Insert</code> and <code>Delete</code> implement <code>OpIterator</code>, accepting a stream of tuples to insert or delete and outputting a single tuple with an integer field that indicates the number of tuples inserted or deleted. These operators will need to call the appropriate methods in <code>BufferPool</code> that actually modify the pages on disk. Check that the tests for inserting and deleting tuples work properly.</li>
</ul>
<p>实现<code>插入</code>和<code>删除</code>操作符。像所有的操作符一样，<code>Insert</code>和<code>Delete</code>实现了<code>OpIterator</code>，接受一个要插入或删除的 tuple 流，并输出一个带有整数字段的单一 tuple ，表示插入或删除的 tuple 数量。这些操作者将需要调用<code>BufferPool</code>中的适当方法，这些方法实际上是修改磁盘上的页面。检查插入和删除 tuple 的测试是否正常工作。</p>
<p>Note that SimpleDB does not implement any kind of consistency or integrity checking, so it is possible to insert duplicate records into a file and there is no way to enforce primary or foreign key constraints.</p>
<p>请注意，SimpleDB没有实现任何类型的一致性或完整性检查，所以有可能在文件中插入重复的记录，也没有办法强制执行主键或外键约束。</p>
<p>At this point you should be able to pass the tests in the ant <code>systemtest</code> target, which is the goal of this lab.</p>
<p>在这一点上，你应该能够通过ant <code>systemtest</code>目标中的测试，这就是本实验的目标。</p>
<p>You'll also be able to use the provided SQL parser to run SQL queries against your database!  See <a href="6.830/cn/3-lab2.html#parser">Section 2.7</a> for a brief tutorial.</p>
<p>你还可以使用所提供的SQL解析器来对你的数据库运行SQL查询!  请参阅<a href="6.830/cn/3-lab2.html#parser">第2.7节</a>，了解一个简短的教程。</p>
<p>Finally, you might notice that the iterators in this lab extend the <code>Operator</code> class instead of implementing the OpIterator interface. Because the implementation of <code>next</code> <code>hasNext</code> is often repetitive, annoying, and error-prone, <code>Operator</code> implements this logic generically, and only requires that you implement a simpler <code>readNext</code>. Feel free to use this style of implementation, or just implement the <code>OpIterator</code> interface if you prefer. To implement the OpIterator interface, remove <code>extends Operator</code> from iterator classes, and in its place put <code>implements OpIterator</code>.</p>
<p>最后，你可能注意到本实验的迭代器扩展了<code>Operator</code>类，而不是实现OpIterator接口。因为<code>next``hasNext</code>的实现往往是重复的、烦人的和容易出错的，<code>Operator</code>通用地实现了这个逻辑，只要求你实现一个更简单的<code>readNext</code>。请随意使用这种实现方式，如果你愿意，也可以直接实现<code>OpIterator</code>接口。要实现OpIterator接口，请从迭代器类中删除<code>extends Operator</code>，并在其位置上加上<code>implements OpIterator</code>。</p>
<h2 id="2-simpledb-architecture-and-implementation-guide-1"><a class="header" href="#2-simpledb-architecture-and-implementation-guide-1">2. SimpleDB Architecture and Implementation Guide</a></h2>
<h3 id="21-filter-and-join"><a class="header" href="#21-filter-and-join">2.1. Filter and Join</a></h3>
<p>Recall that SimpleDB OpIterator classes implement the operations of the relational algebra. You will now implement two operators that will enable you to perform queries that are slightly more interesting than a table scan.</p>
<p>记得SimpleDB OpIterator类实现了关系代数的操作。现在你将实现两个运算符，使你能够执行比表扫描更有趣的查询。</p>
<ul>
<li><em>Filter</em>: This operator only returns tuples that satisfy a <code>Predicate</code> that is specified as part of its constructor. Hence, it filters out any tuples that do not match the predicate.</li>
</ul>
<p><em>过滤器</em>。这个操作符只返回满足 &quot;谓词 &quot;的 tuple ，&quot;谓词 &quot;是作为其构造函数的一部分指定的。因此，它过滤掉任何不符合谓词的 tuple 。</p>
<ul>
<li><em>Join</em>: This operator joins tuples from its two children according to a <code>JoinPredicate</code> that is passed in as part of its constructor. We only require a simple nested loops join, but you may explore more interesting join implementations. Describe your implementation in your lab writeup.</li>
</ul>
<p><em>Join</em>: 这个操作符根据作为其构造函数一部分传入的 &quot;JoinPredicate &quot;来连接其两个子代的 tuple 。我们只需要一个简单的嵌套循环连接，但你可以探索更有趣的连接实现。在你的实验报告中描述你的实现。</p>
<p><strong>Exercise 1.</strong></p>
<p>Implement the skeleton methods in:</p>
<hr />
<ul>
<li>src/java/simpledb/execution/Predicate.java</li>
<li>src/java/simpledb/execution/JoinPredicate.java</li>
<li>src/java/simpledb/execution/Filter.java</li>
<li>src/java/simpledb/execution/Join.java</li>
</ul>
<hr />
<p>At this point, your code should pass the unit tests in PredicateTest, JoinPredicateTest, FilterTest, and JoinTest. Furthermore, you should be able to pass the system tests FilterTest and JoinTest.</p>
<p>在这一点上，你的代码应该通过 PredicateTest、JoinPredicateTest、FilterTest 和 JoinTest 中的单元测试。此外，你应该能够通过系统测试 FilterTest 和 JoinTest。</p>
<h3 id="22-aggregates"><a class="header" href="#22-aggregates">2.2. Aggregates</a></h3>
<p>An additional SimpleDB operator implements basic SQL aggregates with a <code>GROUP BY</code> clause. You should implement the five SQL aggregates (<code>COUNT</code>, <code>SUM</code>, <code>AVG</code>, <code>MIN</code>, <code>MAX</code>) and support grouping. You only need to support aggregates over a single field, and grouping by a single field.</p>
<p>一个额外的SimpleDB操作符用<code>GROUP BY</code>子句实现了基本的SQL聚合。你应该实现五个SQL聚合（<code>COUNT</code>, <code>SUM</code>, <code>AVG</code>, <code>MIN</code>, <code>MAX</code>）并支持分组。你只需要支持单个字段的聚合，以及单个字段的分组。</p>
<p>In order to calculate aggregates, we use an <code>Aggregator</code> interface which merges a new tuple into the existing calculation of an aggregate. The <code>Aggregator</code> is told during construction what operation it should use for aggregation. Subsequently, the client code should call <code>Aggregator.mergeTupleIntoGroup()</code> for every tuple in the child iterator. After all tuples have been merged, the client can retrieve a OpIterator of aggregation results. Each tuple in the result is a pair of the form <code>(groupValue, aggregateValue)</code>, unless the value of the group by field was <code>Aggregator.NO_GROUPING</code>, in which case the result is a single tuple of the form <code>(aggregateValue)</code>.</p>
<p>为了计算聚合，我们使用一个<code>Aggregator</code>接口，将一个新元组合并到现有的聚合计算中。在构建过程中，<code>Aggregator</code>被告知它应该使用什么操作来进行聚合。随后，客户端代码应该为子迭代器中的每个元组调用<code>Aggregator.mergeTupleIntoGroup()</code>。在所有 tuple 被合并后，客户端可以检索到一个聚合结果的OpIterator。结果中的每个元组都是一对形式为<code>(groupValue, aggregateValue)</code>的元组，除非group by字段的值是<code>Aggregator.NO_GROUPING</code>，在这种情况下，结果是一个形式为<code>(aggregateValue)</code>的单一元组。</p>
<p>Note that this implementation requires space linear in the number of distinct groups. For the purposes of this lab, you do not need to worry about the situation where the number of groups exceeds available memory.</p>
<p>请注意，这个实现需要的空间与不同组的数量成线性关系。在本实验中，你不需要担心组的数量超过可用内存的情况。</p>
<p><strong>Exercise 2.</strong></p>
<p>Implement the skeleton methods in:</p>
<hr />
<ul>
<li>src/java/simpledb/execution/IntegerAggregator.java</li>
<li>src/java/simpledb/execution/StringAggregator.java</li>
<li>src/java/simpledb/execution/Aggregate.java</li>
</ul>
<hr />
<p>At this point, your code should pass the unit tests IntegerAggregatorTest, StringAggregatorTest, and AggregateTest. Furthermore, you should be able to pass the AggregateTest system test.</p>
<p>在这一点上，你的代码应该通过IntegerAggregatorTest、StringAggregatorTest和AggregateTest单元测试。此外，你应该能够通过AggregateTest的系统测试。</p>
<h3 id="23-heapfile-mutability"><a class="header" href="#23-heapfile-mutability">2.3. HeapFile Mutability</a></h3>
<p>Now, we will begin to implement methods to support modifying tables. We begin at the level of individual pages and files. There are two main sets of operations:  adding tuples and removing tuples.</p>
<p>现在，我们将开始实现支持修改表格的方法。我们从单个页面和文件的层面开始。有两组主要的操作：添加 tuple 和删除 tuple 。</p>
<p><strong>Removing tuples:</strong> To remove a tuple, you will need to implement <code>deleteTuple</code>. Tuples contain <code>RecordIDs</code> which allow you to find the page they reside on, so this should be as simple as locating the page a tuple belongs to and modifying the headers of the page appropriately.</p>
<p>**删除 tuple ：**要删除一个 tuple ，你需要实现<code>deleteTuple</code>。元组包含`记录ID'，允许你找到它们所在的页面，所以这应该很简单，只要找到元组所属的页面并适当地修改页面的标题。</p>
<p><strong>Adding tuples:</strong> The <code>insertTuple</code> method in <code>HeapFile.java</code> is responsible for adding a tuple to a heap file. To add a new tuple to a HeapFile, you will have to find a page with an empty slot. If no such pages exist in the HeapFile, you need to create a new page and append it to the physical file on disk. You will need to ensure that the RecordID in the tuple is updated correctly.</p>
<p><strong>添加元组：</strong> <code>HeapFile.java</code>中的<code>insertTuple</code>方法负责向一个堆文件添加元组。要向HeapFile添加一个新元组，你必须找到一个有空槽的页面。如果HeapFile中没有这样的页面存在，你需要创建一个新的页面并将其追加到磁盘上的物理文件中。你将需要确保元组中的RecordID被正确地更新。</p>
<p><strong>Exercise 3.</strong></p>
<p>Implement the remaining skeleton methods in:</p>
<hr />
<ul>
<li>src/java/simpledb/storage/HeapPage.java</li>
<li>src/java/simpledb/storage/HeapFile.java<br>
(Note that you do not necessarily need to implement writePage at this point).</li>
</ul>
<hr />
<p>To implement HeapPage, you will need to modify the header bitmap for methods such as <code>insertTuple()</code> and <code>deleteTuple()</code>. You may find that the <code>getNumEmptySlots()</code> and <code>isSlotUsed()</code> methods we asked you to implement in Lab 1 serve as useful abstractions. Note that there is a <code>markSlotUsed</code> method provided as an abstraction to modify the filled or cleared status of a tuple in the page header.</p>
<p>为了实现HeapPage，你需要为<code>insertTuple()</code>和<code>deleteTuple()</code>等方法修改标题位图。你可能会发现，我们在实验1中要求你实现的<code>getNumEmptySlots()</code>和<code>isSlotUsed()</code>方法可以作为有用的抽象方法。请注意，有一个<code>markSlotUsed</code>方法作为抽象，用来修改页眉中元组的填充或清除状态。</p>
<p>Note that it is important that the <code>HeapFile.insertTuple()</code> and <code>HeapFile.deleteTuple()</code> methods access pages using the <code>BufferPool.getPage()</code> method; otherwise, your implementation of transactions in the next lab will not work properly.</p>
<p>注意，重要的是，<code>HeapFile.insertTuple()</code>和<code>HeapFile.deleteTuple()</code>方法要使用<code>BufferPool.getPage()</code>方法访问页面；否则，你在下一个实验的事务实现将不能正常工作。</p>
<p>Implement the following skeleton methods in <tt>src/simpledb/BufferPool.java</tt>:</p>
<p>在<tt>src/simpledb/BufferPool.java</tt>中实现以下骨架方法。</p>
<hr />
<ul>
<li>insertTuple()</li>
<li>deleteTuple()</li>
</ul>
<hr />
<p>These methods should call the appropriate methods in the HeapFile that belong to the table being modified (this extra level of indirection is needed to support other types of files — like indices — in the future).</p>
<p>这些方法应该调用HeapFile中属于被修改的表的适当方法（这个额外的间接层次是需要的，以便在未来支持其他类型的文件— 像索引— ）。</p>
<p>At this point, your code should pass the unit tests in HeapPageWriteTest and HeapFileWriteTest, as well as BufferPoolWriteTest.</p>
<p>在这一点上，你的代码应该通过HeapPageWriteTest和HeapFileWriteTest以及BufferPoolWriteTest的单元测试。</p>
<h3 id="24-insertion-and-deletion"><a class="header" href="#24-insertion-and-deletion">2.4. Insertion and deletion</a></h3>
<p>Now that you have written all of the HeapFile machinery to add and remove tuples, you will implement the <code>Insert</code> and <code>Delete</code> operators.</p>
<p>现在你已经写好了所有用于添加和删除 tuple 的HeapFile机器，你将实现<code>Insert'和</code>Delete'操作。</p>
<p>For plans that implement <code>insert</code> and <code>delete</code> queries, the top-most operator is a special <code>Insert</code> or <code>Delete</code> operator that modifies the pages on disk. These operators return the number of affected tuples. This is implemented by returning a single tuple with one integer field, containing the count.</p>
<p>对于实现 &quot;插入 &quot;和 &quot;删除 &quot;查询的计划，最上面的运算符是一个特殊的 &quot;插入 &quot;或 &quot;删除 &quot;运算符，它修改了磁盘上的页面。这些操作符返回受影响 tuple 的数量。这是通过返回一个带有一个整数字段的单一元组来实现的，其中包含计数。</p>
<ul>
<li><em>Insert</em>: This operator adds the tuples it reads from its child operator to the <code>tableid</code> specified in its constructor. It should use the <code>BufferPool.insertTuple()</code> method to do this.</li>
</ul>
<p><em>插入</em>。这个操作符将它从其子操作符中读取的 tuple 添加到其构造函数中指定的<code>tableid'。它应该使用</code>BufferPool.insertTuple()`方法来做这件事。</p>
<ul>
<li><em>Delete</em>: This operator deletes the tuples it reads from its child operator from the <code>tableid</code> specified in its constructor. It should use the <code>BufferPool.deleteTuple()</code> method to do this.</li>
</ul>
<p><em>Delete</em>: 这个操作符从其构造函数中指定的<code>tableid'中删除它从其子操作符中读取的 tuple 。它应该使用</code>BufferPool.deleteTuple()`方法来做这件事。</p>
<p><strong>Exercise 4.</strong></p>
<p>Implement the skeleton methods in:</p>
<hr />
<ul>
<li>src/java/simpledb/execution/Insert.java</li>
<li>src/java/simpledb/execution/Delete.java</li>
</ul>
<hr />
<p>At this point, your code should pass the unit tests in InsertTest. We have not provided unit tests for <code>Delete</code>. Furthermore, you should be able to pass the InsertTest and DeleteTest system tests.</p>
<p>在这一点上，你的代码应该通过InsertTest的单元测试。我们没有为<code>Delete</code>提供单元测试。此外，你应该能够通过 InsertTest 和 DeleteTest 的系统测试。</p>
<h3 id="25-page-eviction"><a class="header" href="#25-page-eviction">2.5. Page eviction</a></h3>
<p>In Lab 1, we did not correctly observe the limit on the maximum number of pages in the buffer pool defined by the constructor argument <code>numPages</code>. Now, you will choose a page eviction policy and instrument any previous code that reads or creates pages to implement your policy.</p>
<p>在实验1中，我们没有正确观察到由构造参数<code>numPages</code>定义的缓冲池中最大页数的限制。现在，你将选择一个页面驱逐策略，并对以前任何读取或创建页面的代码进行编程，以实现你的策略。</p>
<p>When more than <tt>numPages</tt> pages are in the buffer pool, one page should be evicted from the pool before the next is loaded. The choice of eviction policy is up to you; it is not necessary to do something sophisticated. Describe your policy in the lab writeup.</p>
<p>当缓冲池中的页面超过<tt>numPages</tt>时，在加载下一个页面之前，应该将一个页面从缓冲池中驱逐出去。驱逐策略的选择由你决定；没有必要做一些复杂的事情。在实验报告中描述一下你的策略。</p>
<p>Notice that <code>BufferPool</code> asks you to implement a <code>flushAllPages()</code> method. This is not something you would ever need in a real implementation of a buffer pool. However, we need this method for testing purposes. You should never call this method from any real code.</p>
<p>注意<code>BufferPool</code>要求你实现<code>flushAllPages()</code>方法。这不是你在真正实现缓冲池时需要的东西。然而，我们需要这个方法用于测试。你不应该在任何真正的代码中调用这个方法。</p>
<p>Because of the way we have implemented ScanTest.cacheTest, you will need to ensure that your flushPage and flushAllPages methods do no evict pages from the buffer pool to properly pass this test.</p>
<p>由于我们实现ScanTest.cacheTest的方式，你需要确保你的flushPage和flushAllPages方法不从缓冲池中驱逐页面，以正确通过这个测试。</p>
<p>flushAllPages should call flushPage on all pages in the BufferPool, and flushPage should write any dirty page to disk and mark it as not dirty, while leaving it in the BufferPool.</p>
<p>flushAllPages应该在BufferPool中的所有页面上调用flushPage，flushPage应该将任何脏页写入磁盘并标记为不脏，同时将其留在BufferPool中。</p>
<p>The only method which should remove page from the buffer pool is evictPage, which should call flushPage on any dirty page it evicts.</p>
<p>唯一应该从缓冲池中删除页面的方法是evictPage，它应该对它所驱逐的任何脏页面调用flushPage。</p>
<p><strong>Exercise 5.</strong></p>
<p>Fill in the <code>flushPage()</code> method and additional helper methods to implement page eviction in:</p>
<p>填写<code>flushPage()</code>方法和额外的辅助方法来实现页面驱逐。</p>
<hr />
<ul>
<li>src/java/simpledb/storage/BufferPool.java</li>
</ul>
<hr />
<p>If you did not implement <code>writePage()</code> in <tt>HeapFile.java</tt> above, you will also need to do that here. Finally, you should also implement <code>discardPage()</code> to remove a page from the buffer pool <em>without</em> flushing it to disk. We will not test <code>discardPage()</code> in this lab, but it will be necessary for future labs.</p>
<p>如果你没有在上面的<tt>HeapFile.java</tt>中实现<code>writePage()</code>，你也需要在这里实现它。最后，你还应该实现<code>discardPage()</code>，以便从缓冲池中删除一个页面，而不*冲到磁盘上。我们不会在本实验中测试<code>discardPage()</code>，但它在未来的实验中是必要的。</p>
<p>At this point, your code should pass the EvictionTest system test.</p>
<p>在这一点上，你的代码应该通过EvictionTest系统测试。</p>
<p>Since we will not be checking for any particular eviction policy, this test works by creating a BufferPool with 16 pages (NOTE: while DEFAULT_PAGES is 50, we are initializing the BufferPool with less!), scanning a file with many more than 16 pages, and seeing if the memory usage of the JVM increases by more than 5 MB. If you do not implement an eviction policy correctly, you will not evict enough pages, and will go over the size limitation, thus failing the test.</p>
<p>由于我们不会检查任何特定的驱逐策略，这个测试通过创建一个有16页的BufferPool（注意：虽然DEFAULT_PAGES是50，但我们初始化的BufferPool更少！），扫描一个超过16页的文件，看看JVM的内存使用率是否增加了5MB以上。如果你没有正确地实施驱逐策略，你将无法驱逐足够多的页面，并将超过大小限制，从而导致测试失败。</p>
<p>You have now completed this lab. Good work!</p>
<p>你现在已经完成了这个实验。干得好!</p>
<p><a name="query_walkthrough"></a></p>
<h3 id="26-query-walkthrough"><a class="header" href="#26-query-walkthrough">2.6. Query walkthrough</a></h3>
<p>The following code implements a simple join query between two tables, each consisting of three columns of integers.  (The file <code>some_data_file1.dat</code> and <code>some_data_file2.dat</code> are binary representation of the pages from this file). This code is equivalent to the SQL statement:</p>
<p>下面的代码实现了两个表之间的简单连接查询，每个表由三列整数组成。 (文件<code>some_data_file1.dat</code>和<code>some_data_file2.dat</code>是这个文件的页面的二进制表示）。这段代码等同于SQL语句。</p>
<pre><code class="language-sql">SELECT *
FROM some_data_file1,
     some_data_file2
WHERE some_data_file1.field1 = some_data_file2.field1
  AND some_data_file1.id &gt; 1
</code></pre>
<p>For more extensive examples of query operations, you may find it helpful to browse the unit tests for joins, filters, and aggregates.</p>
<p>对于更多的查询操作的例子，你可能会发现浏览连接、过滤器和聚合的单元测试是有帮助的。</p>
<pre><code class="language-java">package simpledb;

import java.io.*;

public class jointest {

    public static void main(String[] argv) {
        // construct a 3-column table schema
        Type types[] = new Type[]{Type.INT_TYPE, Type.INT_TYPE, Type.INT_TYPE};
        String names[] = new String[]{&quot;field0&quot;, &quot;field1&quot;, &quot;field2&quot;};

        TupleDesc td = new TupleDesc(types, names);

        // create the tables, associate them with the data files
        // and tell the catalog about the schema  the tables.
        HeapFile table1 = new HeapFile(new File(&quot;some_data_file1.dat&quot;), td);
        Database.getCatalog().addTable(table1, &quot;t1&quot;);

        HeapFile table2 = new HeapFile(new File(&quot;some_data_file2.dat&quot;), td);
        Database.getCatalog().addTable(table2, &quot;t2&quot;);

        // construct the query: we use two SeqScans, which spoonfeed
        // tuples via iterators into join
        TransactionId tid = new TransactionId();

        SeqScan ss1 = new SeqScan(tid, table1.getId(), &quot;t1&quot;);
        SeqScan ss2 = new SeqScan(tid, table2.getId(), &quot;t2&quot;);

        // create a filter for the where condition
        Filter sf1 = new Filter(
                new Predicate(0,
                        Predicate.Op.GREATER_THAN, new IntField(1)), ss1);

        JoinPredicate p = new JoinPredicate(1, Predicate.Op.EQUALS, 1);
        Join j = new Join(p, sf1, ss2);

        // and run it
        try {
            j.open();
            while (j.hasNext()) {
                Tuple tup = j.next();
                System.out.println(tup);
            }
            j.close();
            Database.getBufferPool().transactionComplete(tid);

        } catch (Exception e) {
            e.printStackTrace();
        }

    }

}
</code></pre>
<p>Both tables have three integer fields. To express this, we create a <code>TupleDesc</code> object and pass it an array of <code>Type</code> objects indicating field types and <code>String</code> objects indicating field names. Once we have created this <code>TupleDesc</code>, we initialize two <code>HeapFile</code> objects representing the tables. Once we have created the tables, we add them to the Catalog. (If this were a database server that was already running, we would have this catalog information loaded; we need to load this only for the purposes of this test).</p>
<p>两个表都有三个整数字段。为了表达这一点，我们创建了一个<code>TupleDesc</code>对象，并传递给它一个表示字段类型的<code>Type</code>对象和表示字段名的<code>String</code>对象的数组。一旦我们创建了这个<code>TupleDesc</code>，我们就初始化两个代表表的<code>HeapFile</code>对象。一旦我们创建了这些表，我们就把它们添加到目录中。(如果这是一个已经在运行的数据库服务器，我们将加载这个目录信息；我们只需要为这个测试的目的加载这个信息）。</p>
<p>Once we have finished initializing the database system, we create a query plan. Our plan consists of two <code>SeqScan</code> operators that scan the tuples from each file on disk, connected to a <code>Filter</code> operator on the first HeapFile, connected to a <code>Join</code> operator that joins the tuples in the tables according to the <code>JoinPredicate</code>. In general, these operators are instantiated with references to the appropriate table (in the case of SeqScan) or child operator (in the case of e.g., Join). The test program then repeatedly calls <code>next</code> on the <code>Join</code> operator, which in turn pulls tuples from its children. As tuples are output from the <code>Join</code>, they are printed out on the command line.</p>
<p>一旦我们完成了数据库系统的初始化，我们就创建一个查询计划。我们的计划由两个 &quot;SeqScan &quot;操作符组成，扫描磁盘上每个文件的 tuple ，与第一个HeapFile上的 &quot;Filter &quot;操作符相连，与一个 &quot;Join &quot;操作符相连，根据 &quot;JoinPredicate &quot;连接各表中的 tuple 。一般来说，这些运算符被实例化为对适当的表（在SeqScan的情况下）或子运算符（在例如Join的情况下）的引用。测试程序会重复调用 &quot;Join &quot;运算符的 &quot;next&quot;，然后从其子运算符中提取 tuple 。当 tuple 从 &quot;Join &quot;中输出时，它们被打印在命令行中。</p>
<p><a name="parser"></a></p>
<h3 id="27-query-parser"><a class="header" href="#27-query-parser">2.7. Query Parser</a></h3>
<p>We've provided you with a query parser for SimpleDB that you can use to write and run SQL queries against your database once you have completed the exercises in this lab.</p>
<p>我们已经为你提供了SimpleDB的查询分析器，一旦你完成了本实验的练习，你可以用它来编写和运行针对你的数据库的SQL查询。</p>
<p>The first step is to create some data tables and a catalog. Suppose you have a file <code>data.txt</code> with the following contents:</p>
<p>第一步是创建一些数据表和一个目录。假设你有一个文件<code>data.txt</code>，内容如下。</p>
<pre><code>1,10
2,20
3,30
4,40
5,50
5,50
</code></pre>
<p>You can convert this into a SimpleDB table using the <code>convert</code> command (make sure to type <tt>ant</tt> first!):</p>
<p>你可以使用<code>convert</code>命令将其转换为SimpleDB表（请确保先输入<tt>ant</tt>！）。</p>
<pre><code>java -jar dist/simpledb.jar convert data.txt 2 &quot;int,int&quot;
</code></pre>
<p>This creates a file <code>data.dat</code>. In addition to the table's raw data, the two additional parameters specify that each record has two fields and that their types are <code>int</code> and <code>int</code>.</p>
<p>这将创建一个文件<code>data.dat</code>。除了表的原始数据外，两个附加参数指定每条记录有两个字段，它们的类型是<code>int</code>和<code>int</code>。</p>
<p>Next, create a catalog file, <code>catalog.txt</code>, with the following contents:</p>
<p>接下来，创建一个目录文件，<code>catalog.txt</code>，其内容如下。</p>
<pre><code>data (f1 int, f2 int)
</code></pre>
<p>This tells SimpleDB that there is one table, <code>data</code> (stored in <code>data.dat</code>) with two integer fields named <code>f1</code> and <code>f2</code>.</p>
<p>这告诉SimpleDB有一个表，<code>data</code>（存储在<code>data.dat</code>中），有两个整数字段，名为<code>f1</code>和<code>f2</code>。</p>
<p>Finally, invoke the parser. You must run java from the command line (ant doesn't work properly with interactive targets.) From the <code>simpledb/</code> directory, type:</p>
<p>最后，调用解析器。你必须从命令行运行java(ant在交互式目标下不能正常工作。)从<code>simpledb/</code>目录下，输入。</p>
<pre><code>java -jar dist/simpledb.jar parser catalog.txt
</code></pre>
<p>You should see output like:</p>
<p>你应该看到这样的输出。</p>
<pre><code>Added table : data with schema INT(f1), INT(f2), 
SimpleDB&gt; 
</code></pre>
<p>Finally, you can run a query:</p>
<p>最后，你可以运行一个查询。</p>
<pre><code>SimpleDB&gt; select d.f1, d.f2 from data d;
Started a new transaction tid = 1221852405823
 ADDING TABLE d(data) TO tableMap
     TABLE HAS  tupleDesc INT(d.f1), INT(d.f2), 
1       10
2       20
3       30
4       40
5       50
5       50

 6 rows.
----------------
0.16 seconds

SimpleDB&gt; 
</code></pre>
<p>The parser is relatively full featured (including support for SELECTs, INSERTs, DELETEs, and transactions), but does have some problems and does not necessarily report completely informative error messages. Here are some limitations to bear in mind:</p>
<p>该分析器的功能相对齐全（包括对SELECTs、INSERTs、DELETEs和事务的支持），但确实存在一些问题，不一定能报告出完全有参考价值的错误信息。这里有一些需要记住的限制。</p>
<ul>
<li>You must preface every field name with its table name, even if the field name is unique (you can use table name aliases, as in the example above, but you cannot use the AS keyword.)</li>
</ul>
<p>你必须在每个字段名前加上其表名，即使字段名是唯一的（你可以使用表名别名，如上面的例子，但你不能使用AS关键字）。</p>
<ul>
<li>Nested queries are supported in the WHERE clause, but not the FROM clause.</li>
</ul>
<p>在WHERE子句中支持嵌套查询，但不支持FROM子句。</p>
<ul>
<li>No arithmetic expressions are supported (for example, you can't take the sum of two fields.)</li>
</ul>
<p>不支持算术表达式（例如，你不能取两个字段的总和）。</p>
<ul>
<li>At most one GROUP BY and one aggregate column are allowed.</li>
</ul>
<p>最多允许一个GROUP BY和一个聚合列。</p>
<ul>
<li>Set-oriented operators like IN, UNION, and EXCEPT are not allowed.</li>
</ul>
<p>不允许使用面向集合的操作符，如IN、UNION和EXCEPT。</p>
<ul>
<li>Only AND expressions in the WHERE clause are allowed.</li>
</ul>
<p>只允许在WHERE子句中使用AND表达。</p>
<ul>
<li>UPDATE expressions are not supported.</li>
</ul>
<p>不支持UPDATE表达式。</p>
<ul>
<li>The string operator LIKE is allowed, but must be written out fully (that is, the Postgres tilde [~] shorthand is not allowed.)</li>
</ul>
<p>允许使用字符串操作符LIKE，但是必须完全写出来（也就是说，不允许使用Postgres的tilde [~]短语）。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-3-翻译"><a class="header" href="#lab-3-翻译">Lab 3 翻译</a></h1>
<p>Assigned: Wednesday, Mar 17, 2021
Due: Tuesday, Apr 6, 2021</p>
<p>In this lab, you will implement a query optimizer on top of SimpleDB. The main tasks include implementing a selectivity estimation framework and a cost-based optimizer. You have freedom as to exactly what you implement, but we recommend using something similar to the Selinger cost-based optimizer discussed in class (Lecture 9).</p>
<p>在这个实室中，你将在SimpleDB之上实现一个查询优化器。主要任务包括实现一个选择性估计框架和一个基于成本的优化器。你可以自由选择具体的实现方式，但我们建议使用类似于课堂上讨论的Selinger基于成本的优化器（第9讲）。</p>
<p>The remainder of this document describes what is involved in adding optimizer support and provides a basic outline of how you do so.</p>
<p>本文件的其余部分描述了添加优化器支持所涉及的内容，并提供了一个关于如何添加优化器的基本概要。</p>
<p>As with the previous lab, we recommend that you start as early as possible.</p>
<p>与前一个实室一样，我们建议你尽可能早地开始。</p>
<h1 id="1-getting-started-2"><a class="header" href="#1-getting-started-2">1. Getting started</a></h1>
<p>You should begin with the code you submitted for Lab 2. (If you did not submit code for Lab 2, or your solution didn't work properly, contact us to discuss options.)</p>
<p>你应该从你为实室2提交的代码开始。（如果你没有为实室2提交代码，或者你的解决方案没有正常工作，请与我们联系，讨论各种方案。）</p>
<p>We have provided you with extra test cases as well as source code files for this lab that are not in the original code distribution you received. We again encourage you to develop your own test suite in addition to the ones we have provided.</p>
<p>我们为这个实室提供了额外的测试案例以及源代码文件，这些文件不在你收到的原始代码分发中。我们再次鼓励你在我们提供的测试案例之外，开发你自己的测试套件。</p>
<p>You will need to add these new files to your release. The easiest way to do this is to change to your project directory (probably called simple-db-hw) and pull from the master GitHub repository:</p>
<p>你将需要把这些新文件添加到你的版本中。最简单的方法是换到你的项目目录（可能叫simple-db-hw），然后从GitHub的主仓库拉出。</p>
<p>$ cd simple-db-hw
$ git pull upstream master</p>
<h2 id="11-implementation-hints"><a class="header" href="#11-implementation-hints">1.1. Implementation hints</a></h2>
<p>We suggest exercises along this document to guide your implementation, but you may find that a different order makes more sense for you. As before, we will grade your assignment by looking at your code and verifying that you have passed the test for the ant targets test and systemtest. See Section 3.4 for a complete discussion of grading and the tests you will need to pass.</p>
<p>我们建议沿着这份文件进行练习，以指导你的实施，但你可能会发现不同的顺序对你更有意义。和以前一样，我们将通过查看你的代码并验证你是否通过了蚂蚁目标测试和systemtest的测试来给你的作业评分。关于评分和你需要通过的测试的完整讨论见第3.4节。</p>
<p>Here's a rough outline of one way you might proceed with this lab. More details on these steps are given in Section 2 below.</p>
<p>下面是你可能进行这个实验的一个粗略大纲。关于这些步骤的更多细节将在下文第2节给出。</p>
<p>Implement the methods in the TableStats class that allow it to estimate selectivities of filters and cost of scans, using histograms (skeleton provided for the IntHistogram class) or some other form of statistics of your devising.</p>
<p>实现TableStats类中的方法，使其能够使用直方图（IntHistogram类提供的骨架）或你设计的其他形式的统计数据来估计过滤器的选择性和扫描的成本。</p>
<p>Implement the methods in the JoinOptimizer class that allow it to estimate the cost and selectivities of joins.</p>
<p>实现JoinOptimizer类中的方法，使其能够估计 join 的成本和选择性。</p>
<p>Write the orderJoins method in JoinOptimizer. This method must produce an optimal ordering for a series of joins (likely using the Selinger algorithm), given statistics computed in the previous two steps.</p>
<p>编写JoinOptimizer中的orderJoins方法。这个方法必须为一系列的连接产生一个最佳的顺序（可能使用Selinger算法），给定前两个步骤中计算的统计数据。</p>
<h1 id="2-optimizer-outline"><a class="header" href="#2-optimizer-outline">2. Optimizer outline</a></h1>
<p>Recall that the main idea of a cost-based optimizer is to:</p>
<p>回顾一下，基于成本的优化器的主要思想是：</p>
<p>Use statistics about tables to estimate &quot;costs&quot; of different query plans. Typically, the cost of a plan is related to the cardinalities of (number of tuples produced by) intermediate joins and selections, as well as the selectivity of filter and join predicates.</p>
<p>使用关于表的统计数据来估计不同查询计划的 &quot;成本&quot;。通常情况下，一个计划的成本与中间连接和选择的cardinalities（产生的 tuple 数量），以及过滤器和连接谓词的选择性有关。</p>
<p>Use these statistics to order joins and selections in an optimal way, and to select the best implementation for join algorithms from amongst several alternatives.
In this lab, you will implement code to perform both of these functions.</p>
<p>利用这些统计数据，以最佳方式排列连接和选择，并从几个备选方案中选择连接算法的最佳实现。
在本实室中，你将实现代码以执行这两项功能。</p>
<p>The optimizer will be invoked from simpledb/Parser.java. You may wish to review the lab 2 parser exercise before starting this lab. Briefly, if you have a catalog file catalog.txt describing your tables, you can run the parser by typing:</p>
<p>优化器将从simpledb/Parser.java调用。在开始这个实验之前，你可能希望回顾一下实验2的解析器练习。简而言之，如果你有一个描述你的表的目录文件catalog.txt，你可以通过输入来运行解析器。</p>
<p><code>java -jar dist/simpledb.jar parser catalog.txt</code></p>
<p>When the Parser is invoked, it will compute statistics over all of the tables (using statistics code you provide). When a query is issued, the parser will convert the query into a logical plan representation and then call your query optimizer to generate an optimal plan.</p>
<p>当解析器被调用时，它将对所有的表进行统计计算（使用你提供的统计代码）。当一个查询被发出时，解析器将把查询转换成逻辑计划表示，然后调用你的查询优化器来生成一个最佳计划。</p>
<h2 id="21-overall-optimizer-structure"><a class="header" href="#21-overall-optimizer-structure">2.1 Overall Optimizer Structure</a></h2>
<p>Before getting started with the implementation, you need to understand the overall structure of the SimpleDB optimizer. The overall control flow of the SimpleDB modules of the parser and optimizer is shown in Figure 1.</p>
<p>在开始实施之前，你需要了解SimpleDB优化器的整体结构。分析器和优化器的SimpleDB模块的整体控制流程如图1所示。</p>
<p><img src="6.830/cn/image/4-lab3/1644226360588.png" alt="" />
Figure 1: Diagram illustrating classes, methods, and objects used in the parser</p>
<p>图1：说明解析器中使用的类、方法和对象的图示</p>
<p>The key at the bottom explains the symbols; you will implement the components with double-borders. The classes and methods will be explained in more detail in the text that follows (you may wish to refer back to this diagram), but the basic operation is as follows:</p>
<p>底部的 key 解释了这些符号；你将实现带有双边框的组件。这些类和方法将在后面的文字中得到更详细的解释（你可能希望回过头来看看这个图），但基本操作如下。</p>
<p>Parser.java constructs a set of table statistics (stored in the statsMap container) when it is initialized. It then waits for a query to be input, and calls the method parseQuery on that query.</p>
<p>Parser.java在初始化时构建了一组表的统计数据（存储在statsMap容器中）。然后它等待一个查询的输入，并对该查询调用parseQuery方法。</p>
<p>parseQuery first constructs a LogicalPlan that represents the parsed query. parseQuery then calls the method physicalPlan on the LogicalPlan instance it has constructed. The physicalPlan method returns a DBIterator object that can be used to actually run the query.</p>
<p>parseQuery首先构建一个代表解析查询的LogicalPlan，然后在它构建的LogicalPlan实例上调用physicalPlan方法。physicalPlan方法返回一个DBIterator对象，可用于实际运行查询。</p>
<p>In the exercises to come, you will implement the methods that help physicalPlan devise an optimal plan.</p>
<p>在接下来的练习中，你将实施帮助physicalPlan设计一个最佳计划的方法。</p>
<h2 id="22-statistics-estimation"><a class="header" href="#22-statistics-estimation">2.2. Statistics Estimation</a></h2>
<p>Accurately estimating plan cost is quite tricky. In this lab, we will focus only on the cost of sequences of joins and base table accesses. We won't worry about access method selection (since we only have one access method, table scans) or the costs of additional operators (like aggregates).</p>
<p>准确地估计计划成本是相当棘手的。在这个实室中，我们将只关注连接序列和基本表访问的成本。我们不会担心访问方法的选择（因为我们只有一种访问方法，即表扫描），也不会担心额外运算符（如聚合）的成本。</p>
<p>You are only required to consider left-deep plans for this lab. See Section 2.3 for a description of additional &quot;bonus&quot; optimizer features you might implement, including an approach for handling bushy plans.</p>
<p>在这个实验中，你只需要考虑左深的计划。参见第2.3节，了解你可能实现的额外的 &quot;奖励 &quot;优化器特性，包括处理杂乱计划的方法。</p>
<h2 id="221-overall-plan-cost"><a class="header" href="#221-overall-plan-cost">2.2.1 Overall Plan Cost</a></h2>
<p>We will write join plans of the form p=t1 join t2 join ... tn, which signifies a left deep join where t1 is the left-most join (deepest in the tree). Given a plan like p, its cost can be expressed as:</p>
<p>我们将以p=t1 join t2 join ... tn的形式来写连接计划，这表示一个左深连接，其中t1是最左边的连接（树中最深的）。给定一个像p这样的计划，其成本可以表示为。</p>
<pre><code>scancost(t1) + scancost(t2) + joincost(t1 join t2) +
scancost(t3) + joincost((t1 join t2) join t3) +
... 
</code></pre>
<p>Here, scancost(t1) is the I/O cost of scanning table t1, joincost(t1,t2) is the CPU cost to join t1 to t2. To make I/O and CPU cost comparable, typically a constant scaling factor is used, e.g.:</p>
<p>这里，scancost(t1)是扫描表t1的I/O成本，joincost(t1,t2)是连接t1和t2的CPU成本。为了使I/O和CPU成本具有可比性，通常使用一个恒定的比例系数，例如。</p>
<pre><code>cost(predicate application) = 1
cost(pageScan) = SCALING_FACTOR x cost(predicate application)
</code></pre>
<p>For this lab, you can ignore the effects of caching (e.g., assume that every access to a table incurs the full cost of a scan) -- again, this is something you may add as an optional bonus extension to your lab in Section 2.3. Therefore, scancost(t1) is simply the number of pages in t1 x SCALING_FACTOR.</p>
<p>在这个实验中，你可以忽略缓存的影响（例如，假设对表的每一次访问都会产生全部的扫描成本）--同样，这也是你可以在第2.3节中作为一个可选的额外扩展添加到实验中的东西。因此，scancost(t1)只是t1的页数x SCALING_FACTOR。</p>
<h2 id="222-join-cost"><a class="header" href="#222-join-cost">2.2.2 Join Cost</a></h2>
<p>When using nested loops joins, recall that the cost of a join between two tables t1 and t2 (where t1 is the outer) is simply:</p>
<p>当使用嵌套循环连接时，记得两个表t1和t2（其中t1是外表）之间的连接成本是简单的。</p>
<pre><code>joincost(t1 join t2) = scancost(t1) + ntups(t1) x scancost(t2) //IO cost
                    + ntups(t1) x ntups(t2)  //CPU cost
</code></pre>
<p>Here, ntups(t1) is the number of tuples in table t1.</p>
<p>这里，ntups(t1)是表t1中 tuples 的数量。</p>
<h2 id="223-filter-selectivity"><a class="header" href="#223-filter-selectivity">2.2.3 Filter Selectivity</a></h2>
<p>ntups can be directly computed for a base table by scanning that table. Estimating ntups for a table with one or more selection predicates over it can be trickier -- this is the filter selectivity estimation problem. Here's one approach that you might use, based on computing a histogram over the values in the table:</p>
<p>ntups可以通过扫描一个基表直接计算出来。对于一个有一个或多个选择谓词的表来说，估计ntups可能比较棘手--这就是过滤器的选择性估计问题。下面是你可能使用的一种方法，基于计算表中的值的直方图。</p>
<ul>
<li>Compute the minimum and maximum values for every attribute in the table (by scanning it once).</li>
</ul>
<p>计算表中每个属性的最小值和最大值（通过扫描一次）。</p>
<ul>
<li>Construct a histogram for every attribute in the table. A simple approach is to use a fixed number of buckets NumB, with each bucket representing the number of records in a fixed range of the domain of the attribute of the histogram. For example, if a field f ranges from 1 to 100, and there are 10 buckets, then bucket 1 might contain the count of the number of records between 1 and 10, bucket 2 a count of the number of records between 11 and 20, and so on.</li>
</ul>
<p>为表中的每个属性构建一个直方图。一个简单的方法是使用一个固定数量的桶NumB，每个桶代表直方图属性领域的固定范围内的记录数。例如，如果一个字段f的范围是1到100，有10个桶，那么桶1可能包含1到10之间的记录数，桶2包含11到20之间的记录数，以此类推。</p>
<ul>
<li>Scan the table again, selecting out all of fields of all of the tuples and using them to populate the counts of the buckets in each histogram.</li>
</ul>
<p>再次扫描该表，选择出所有 tuples 的所有字段，用它们来填充每个直方图中的桶的计数。</p>
<ul>
<li>To estimate the selectivity of an equality expression, f=const, compute the bucket that contains value const. Suppose the width (range of values) of the bucket is w, the height (number of tuples) is h, and the number of tuples in the table is ntups. Then, assuming values are uniformly distributed throughout the bucket, the selectivity of the expression is roughly (h / w) / ntups, since (h/w) represents the expected number of tuples in the bin with value const.</li>
</ul>
<p>为了估计一个平等表达式f=const的选择性，计算包含值const的桶。假设桶的宽度（值的范围）是w，高度（ tuples 的数量）是h，而表中 tuples 的数量是ntups。那么，假设值在整个桶中是均匀分布的，表达式的选择性大致为(h/w)/ntups，因为(h/w)代表的是桶中含有值常数的 tuples 的预期数量。</p>
<ul>
<li>To estimate the selectivity of a range expression f&gt;const, compute the bucket b that const is in, with width w_b and height h_b. Then, b contains a fraction b_f = h_b / ntups of the total tuples. Assuming tuples are uniformly distributed throughout b, the fraction b_part of b that is &gt; const is (b_right - const) / w_b, where b_right is the right endpoint of b's bucket. Thus, bucket b contributes (b_f x b_part) selectivity to the predicate. In addition, buckets b+1...NumB-1 contribute all of their selectivity (which can be computed using a formula similar to b_f above). Summing the selectivity contributions of all the buckets will yield the overall selectivity of the expression. Figure 2 illustrates this process.</li>
</ul>
<p>为了估计一个范围表达式f&gt;const的选择性，计算const所在的桶b，其宽度为w_b，高度为h_b。那么，b包含了全部 tuples 中的一部分b_f = h_b / ntups。假设 tuples 均匀地分布在整个b中，b中大于const的部分b_part是（b_right - const）/ w_b，其中b_right是b的桶的右端点。因此，b桶对谓词贡献了（b_f x b_part）的选择性。此外，b+1...NumB-1桶贡献了它们所有的选择性（可以用类似于上面b_f的公式来计算）。将所有桶的选择性贡献相加，将产生表达式的整体选择性。图2说明了这个过程。</p>
<ul>
<li>Selectivity of expressions involving less than can be performed similar to the greater than case, looking at buckets down to 0.</li>
</ul>
<p>涉及小于的表达式的选择性可以类似于大于的情况下进行，看下到0的桶。</p>
<p><img src="6.830/cn//6.830/4-lab3/1644227082669.png" alt="" /></p>
<p>In the next two exercises, you will code to perform selectivity estimation of joins and filters.</p>
<p>在接下来的两个练习中，你将用代码来执行连接和过滤器的选择性估计。</p>
<h2 id="exercise-1-inthistogramjava-1"><a class="header" href="#exercise-1-inthistogramjava-1">Exercise 1: IntHistogram.java</a></h2>
<p>You will need to implement some way to record table statistics for selectivity estimation. We have provided a skeleton class, IntHistogram that will do this. Our intent is that you calculate histograms using the bucket-based method described above, but you are free to use some other method so long as it provides reasonable selectivity estimates.</p>
<p>你将需要实现一些方法来记录表的统计数据，以便进行选择性估计。我们提供了一个骨架类，IntHistogram，它可以做到这一点。我们的目的是让你使用上面描述的基于桶的方法来计算直方图，但你也可以自由地使用其他方法，只要它能提供合理的选择性估计。</p>
<p>We have provided a class StringHistogram that uses IntHistogram to compute selecitivites for String predicates. You may modify StringHistogram if you want to implement a better estimator, though you should not need to in order to complete this lab.</p>
<p>我们提供了一个StringHistogram类，它使用IntHistogram来计算字符串谓词的选取。如果你想实现一个更好的估计器，你可以修改StringHistogram，尽管你不需要为了完成这个实验而修改。</p>
<p>After completing this exercise, you should be able to pass the IntHistogramTest unit test (you are not required to pass this test if you choose not to implement histogram-based selectivity estimation).</p>
<p>完成这个练习后，你应该能够通过IntHistogramTest单元测试（如果你选择不实现基于直方图的选择性估计，你不需要通过这个测试）。</p>
<h2 id="exercise-2-tablestatsjava-1"><a class="header" href="#exercise-2-tablestatsjava-1">Exercise 2: TableStats.java</a></h2>
<p>The class TableStats contains methods that compute the number of tuples and pages in a table and that estimate the selectivity of predicates over the fields of that table. The query parser we have created creates one instance of TableStats per table, and passes these structures into your query optimizer (which you will need in later exercises).</p>
<p>TableStats类包含了计算一个表中 tuples 和页数的方法，以及估计该表字段上的谓词的选择性的方法。我们创建的查询分析器为每个表创建一个TableStats的实例，并将这些结构传递给你的查询优化器（在后面的练习中你会需要它）。</p>
<p>You should fill in the following methods and classes in TableStats:</p>
<p>你应该在TableStats中填写以下方法和类。</p>
<p>Implement the TableStats constructor: Once you have implemented a method for tracking statistics such as histograms, you should implement the TableStats constructor, adding code to scan the table (possibly multiple times) to build the statistics you need.</p>
<p>实现TableStats构造函数。一旦你实现了跟踪统计的方法，如直方图，你应该实现TableStats构造函数，添加代码来扫描表（可能是多次）以建立你需要的统计。</p>
<p>Implement estimateSelectivity(int field, Predicate.Op op, Field constant): Using your statistics (e.g., an IntHistogram or StringHistogram depending on the type of the field), estimate the selectivity of predicate field op constant on the table.</p>
<p>实现 estimateSelectivity(int field, Predicate.Op op, Field constant)。使用你的统计数据（例如，根据字段的类型，使用IntHistogram或StringHistogram），估计predicate字段op常量对表的选择性。</p>
<p>Implement estimateScanCost(): This method estimates the cost of sequentially scanning the file, given that the cost to read a page is costPerPageIO. You can assume that there are no seeks and that no pages are in the buffer pool. This method may use costs or sizes you computed in the constructor.</p>
<p>实现 estimateScanCost()。这个方法估计顺序扫描文件的成本，考虑到读取一个页面的成本是costPerPageIO。你可以假设没有寻道，也没有页面在缓冲池中。这个方法可以使用你在构造函数中计算的成本或大小。</p>
<p>Implement estimateTableCardinality(double selectivityFactor): This method returns the number of tuples in the relation, given that a predicate with selectivity selectivityFactor is applied. This method may use costs or sizes you computed in the constructor.</p>
<p>实现 estimateTableCardinality(double selectivityFactor)。该方法返回关系中 tuples 的数量，考虑到应用了具有选择性的selectivityFactor的谓词。这个方法可以使用你在构造函数中计算的成本或大小。</p>
<p>You may wish to modify the constructor of TableStats.java to, for example, compute histograms over the fields as described above for purposes of selectivity estimation.</p>
<p>你可能希望修改TableStats.java的构造函数，例如，为了选择性估计的目的，计算上述字段的直方图。</p>
<p>After completing these tasks you should be able to pass the unit tests in TableStatsTest.</p>
<p>完成这些任务后，你应该能够通过TableStatsTest的单元测试。</p>
<h2 id="224-join-cardinality"><a class="header" href="#224-join-cardinality">2.2.4 Join Cardinality</a></h2>
<p>Finally, observe that the cost for the join plan p above includes expressions of the form joincost((t1 join t2) join t3). To evaluate this expression, you need some way to estimate the size (ntups) of t1 join t2. This join cardinality estimation problem is harder than the filter selectivity estimation problem. In this lab, you aren't required to do anything fancy for this, though one of the optional excercises in Section 2.4 includes a histogram-based method for join selectivity estimation.</p>
<p>最后，观察一下，上面的连接计划p的成本包括形式为joincost((t1 join t2) join t3)的表达。为了评估这个表达式，你需要一些方法来估计t1 join t2的大小（ntups）。这个连接cardinality估计问题比过滤器的选择性估计问题更难。在这个实验中，你不需要为此做任何花哨的事情，尽管第2.4节中的一个可选的练习包括一个基于直方图的连接选择性估计的方法。</p>
<p>While implementing your simple solution, you should keep in mind the following:</p>
<p>在实施你的简单解决方案时，你应该牢记以下几点。</p>
<p>For equality joins, when one of the attributes is a primary key, the number of tuples produced by the join cannot be larger than the cardinality of the non-primary key attribute.</p>
<p>对于等价连接，当其中一个属性是主键时，由连接产生的 tuples 的数量不能大于非主键属性的cardinality。</p>
<p>For equality joins when there is no primary key, it's hard to say much about what the size of the output is -- it could be the size of the product of the cardinalities of the tables (if both tables have the same value for all tuples) -- or it could be 0. It's fine to make up a simple heuristic (say, the size of the larger of the two tables).</p>
<p>对于没有主键的等价连接，很难说输出的大小是什么--它可能是表的cardinalities的乘积的大小（如果两个表的所有 tuples 都有相同的值）--或者它可能是0。</p>
<p>For range scans, it is similarly hard to say anything accurate about sizes. The size of the output should be proportional to the sizes of the inputs. It is fine to assume that a fixed fraction of the cross-product is emitted by range scans (say, 30%). In general, the cost of a range join should be larger than the cost of a non-primary key equality join of two tables of the same size.</p>
<p>对于范围扫描，同样也很难对尺寸说得准确。输出的大小应该与输入的大小成正比。假设交叉产物的一个固定部分是由范围扫描发出的（比如，30%），是可以的。一般来说，范围连接的成本应该大于相同大小的两个表的非主键平等连接的成本。</p>
<h2 id="exercise-3-join-cost-estimation-1"><a class="header" href="#exercise-3-join-cost-estimation-1">Exercise 3: Join Cost Estimation</a></h2>
<p>The class JoinOptimizer.java includes all of the methods for ordering and computing costs of joins. In this exercise, you will write the methods for estimating the selectivity and cost of a join, specifically:</p>
<p>JoinOptimizer.java类包括所有用于排序和计算连接成本的方法。在这个练习中，你将写出用于估计 join 的 selectivity 和 cost 的方法，特别是：</p>
<p>Implement estimateJoinCost(LogicalJoinNode j, int card1, int card2, double cost1, double cost2): This method estimates the cost of join j, given that the left input is of cardinality card1, the right input of cardinality card2, that the cost to scan the left input is cost1, and that the cost to access the right input is card2. You can assume the join is an NL join, and apply the formula mentioned earlier.</p>
<p>实现 estimateJoinCost(LogicalJoinNode j, int card1, int card2, double cost1, double cost2) 。这个方法估计了连接j的成本，考虑到左边的输入是cardinality card1，右边的输入是cardinality card2，扫描左边输入的成本是cost1，访问右边输入的成本是card2。你可以假设这个连接是一个NL连接，并应用前面提到的公式。</p>
<p>Implement estimateJoinCardinality(LogicalJoinNode j, int card1, int card2, boolean t1pkey, boolean t2pkey): This method estimates the number of tuples output by join j, given that the left input is size card1, the right input is size card2, and the flags t1pkey and t2pkey that indicate whether the left and right (respectively) field is unique (a primary key).</p>
<p>实现 estimateJoinCardinality(LogicalJoinNode j, int card1, int card2, boolean t1pkey, boolean t2pkey) 。这个方法估计了j连接输出的 tuples 数，给定左边的输入是大小为card1，右边的输入是大小为card2，以及指示左边和右边（分别）字段是否唯一（主键）的标志t1pkey和t2pkey。</p>
<p>After implementing these methods, you should be able to pass the unit tests estimateJoinCostTest and estimateJoinCardinality in JoinOptimizerTest.java.</p>
<p>实现这些方法后，你应该能够通过JoinOptimizerTest.java中的单元测试 estimateJoinCostTest 和 estimateJoinCardinality。</p>
<h2 id="23-join-ordering"><a class="header" href="#23-join-ordering">2.3 Join Ordering</a></h2>
<p>Now that you have implemented methods for estimating costs, you will implement the Selinger optimizer. For these methods, joins are expressed as a list of join nodes (e.g., predicates over two tables) as opposed to a list of relations to join as described in class.</p>
<p>现在你已经实现了估计成本的方法，你将实现Selinger优化器。对于这些方法，连接被表达为一个连接节点的列表（例如，对两个表的谓词），而不是课堂上描述的连接关系的列表。</p>
<p>Translating the algorithm given in lecture to the join node list form mentioned above, an outline in pseudocode would be:</p>
<p>将讲座中给出的算法转化为上述的连接节点列表形式，伪代码的概要是：。</p>
<pre><code class="language-java">1. j = set of join nodes
2. for (i in 1...|j|):
3.     for s in {all length i subsets of j}
4.       bestPlan = {}
5.       for s' in {all length d-1 subsets of s}
6.            subplan = optjoin(s')
7.            plan = best way to join (s-s') to subplan
8.            if (cost(plan) &lt; cost(bestPlan))
9.               bestPlan = plan
10.      optjoin(s) = bestPlan
11. return optjoin(j)
</code></pre>
<p>To help you implement this algorithm, we have provided several classes and methods to assist you. First, the method enumerateSubsets(List v, int size) in JoinOptimizer.java will return a set of all of the subsets of v of size size. This method is VERY inefficient for large sets; you can earn extra credit by implementing a more efficient enumerator (hint: consider using an in-place generation algorithm and a lazy iterator (or stream) interface to avoid materializing the entire power set).</p>
<p>为了帮助你实现这个算法，我们提供了几个类和方法来帮助你。首先，JoinOptimizer.java中的enumerateSubsets(List v, int size)方法将返回一个大小为v的所有子集的集合。这个方法对于大型集合来说效率非常低；你可以通过实现一个更有效的枚举器来获得额外的分数（提示：考虑使用原地生成算法和懒惰迭代器（或流）接口来避免物化整个幂集）。</p>
<p>Second, we have provided the method:</p>
<p>第二，我们提供了方法。</p>
<pre><code class="language-java">    private CostCard computeCostAndCardOfSubplan(Map&lt;String, TableStats&gt; stats, 
                                                Map&lt;String, Double&gt; filterSelectivities, 
                                                LogicalJoinNode joinToRemove,  
                                                Set&lt;LogicalJoinNode&gt; joinSet,
                                                double bestCostSoFar,
                                                PlanCache pc) 
</code></pre>
<p>Given a subset of joins (joinSet), and a join to remove from this set (joinToRemove), this method computes the best way to join joinToRemove to joinSet - {joinToRemove}. It returns this best method in a CostCard object, which includes the cost, cardinality, and best join ordering (as a list). computeCostAndCardOfSubplan may return null, if no plan can be found (because, for example, there is no left-deep join that is possible), or if the cost of all plans is greater than the bestCostSoFar argument. The method uses a cache of previous joins called pc (optjoin in the psuedocode above) to quickly lookup the fastest way to join joinSet - {joinToRemove}. The other arguments (stats and filterSelectivities) are passed into the orderJoins method that you must implement as a part of Exercise 4, and are explained below. This method essentially performs lines 6--8 of the psuedocode described earlier.</p>
<p>给出一个连接的子集（joinSet），以及一个要从这个子集中移除的连接（joinToRemove），这个方法计算出将joinToRemove连接到joinSet的最佳方法--{joinToRemove}。它在一个CostCard对象中返回这个最佳方法，其中包括成本、cardinality和最佳连接顺序（作为一个列表）。如果找不到计划（因为，例如，没有可能的左深连接），或者如果所有计划的成本都大于bestCostSoFar参数，computeCostAndCardOfSubplan可能返回null。该方法使用了一个叫做pc（上面的psuedocode中的optjoin）的先前连接的缓存来快速查找joinSet的最快方式--{joinToRemove}。其他参数（stats和filterSelectivities）被传递到你必须实现的orderJoins方法中，作为练习4的一部分，下面会有解释。这个方法基本上是执行前面描述的假代码的第6-8行。</p>
<p>Third, we have provided the method:</p>
<p>第三，我们提供了方法。</p>
<pre><code class="language-java">    private void printJoins(List&lt;LogicalJoinNode&gt; js, 
                           PlanCache pc,
                           Map&lt;String, TableStats&gt; stats,
                           Map&lt;String, Double&gt; selectivities)
</code></pre>
<p>This method can be used to display a graphical representation of a join plan (when the &quot;explain&quot; flag is set via the &quot;-explain&quot; option to the optimizer, for example).</p>
<p>这种方法可以用来显示连接计划的图形表示（例如，当通过优化器的&quot;-explain &quot;选项设置 &quot;explain &quot;标志时）。</p>
<p>Fourth, we have provided a class PlanCache that can be used to cache the best way to join a subset of the joins considered so far in your implementation of Selinger (an instance of this class is needed to use computeCostAndCardOfSubplan).</p>
<p>第四，我们提供了一个PlanCache类，可以用来缓存到目前为止在你的Selinger实现中所考虑的连接子集的最佳方式（使用computeCostAndCardOfSubplan需要这个类的一个实例）。</p>
<h2 id="exercise-4-join-ordering-1"><a class="header" href="#exercise-4-join-ordering-1">Exercise 4: Join Ordering</a></h2>
<p>In JoinOptimizer.java, implement the method:</p>
<p>在JoinOptimizer.java中，实现这个方法。</p>
<pre><code class="language-java">  List&lt;LogicalJoinNode&gt; orderJoins(Map&lt;String, TableStats&gt; stats, 
                   Map&lt;String, Double&gt; filterSelectivities,  
                   boolean explain)
</code></pre>
<p>This method should operate on the joins class member, returning a new List that specifies the order in which joins should be done. Item 0 of this list indicates the left-most, bottom-most join in a left-deep plan. Adjacent joins in the returned list should share at least one field to ensure the plan is left-deep. Here stats is an object that lets you find the TableStats for a given table name that appears in the FROM list of the query. filterSelectivities allows you to find the selectivity of any predicates over a table; it is guaranteed to have one entry per table name in the FROM list. Finally, explain specifies that you should output a representation of the join order for informational purposes.</p>
<p>这个方法应该在joins类成员上操作，返回一个新的List，这个List指定了应该进行的连接的顺序。这个列表中的第0项表示左深计划中最左、最底的连接。返回的列表中相邻的连接应该至少共享一个字段，以确保计划是左深的。这里stats是一个对象，让你找到出现在查询的FROM列表中的给定表名的TableStats。 filterSelectivities让你找到表的任何谓词的选择性；它保证在FROM列表中的每个表名有一个条目。最后，explain指定了你应该输出一个连接顺序的表示，以供参考。</p>
<p>You may wish to use the helper methods and classes described above to assist in your implementation. Roughly, your implementation should follow the psuedocode above, looping through subset sizes, subsets, and sub-plans of subsets, calling computeCostAndCardOfSubplan and building a PlanCache object that stores the minimal-cost way to perform each subset join.</p>
<p>你可能希望使用上面描述的辅助方法和类来帮助你实现。大致上，你的实现应该遵循上面的假设代码，通过子集大小、子集和子集的子计划进行循环，调用computeCostAndCardOfSubplan并建立一个PlanCache对象来存储执行每个子集连接的最小成本方式。</p>
<p>After implementing this method, you should be able to pass all the unit tests in JoinOptimizerTest. You should also pass the system test QueryTest.</p>
<p>实现这个方法后，你应该能够通过JoinOptimizerTest的所有单元测试。你还应该通过系统测试QueryTest。</p>
<h1 id="24-extra-credit"><a class="header" href="#24-extra-credit">2.4 Extra Credit</a></h1>
<p>In this section, we describe several optional excercises that you may implement for extra credit. These are less well defined than the previous exercises but give you a chance to show off your mastery of query optimization! Please clearly mark which ones you have chosen to complete in your report, and briefly explain your implementation and present your results (benchmark numbers, experience reports, etc.)</p>
<p>在这一节中，我们描述了几个可选的练习，你可以实施这些练习来获得额外的分数。这些练习没有前面的练习那么明确，但可以让你有机会展示你对查询优化的掌握程度 请在你的报告中清楚地标出你选择完成的练习，并简要地解释你的执行情况和介绍你的结果（基准数字、经验报告等）。</p>
<p>Bonus Exercises. Each of these bonuses is worth up to 5% extra credit:</p>
<p>奖励练习。这些奖金中的每一个都价值高达5%的额外信用。</p>
<p>Add code to perform more advanced join cardinality estimation. Rather than using simple heuristics to estimate join cardinality, devise a more sophisticated algorithm.</p>
<p>添加代码以执行更高级的连接心率估计。与其使用简单的启发式方法来估计连接的cardinality，不如设计一个更复杂的算法。</p>
<p>One option is to use joint histograms between every pair of attributes a and b in every pair of tables t1 and t2. The idea is to create buckets of a, and for each bucket A of a, create a histogram of b values that co-occur with a values in A.</p>
<p>一种选择是在每对表t1和t2中的每对属性a和b之间使用联合直方图。这个想法是创建a的桶，对于a的每个桶A，创建一个与A中a值共同出现的b值的直方图。</p>
<p>Another way to estimate the cardinality of a join is to assume that each value in the smaller table has a matching value in the larger table. Then the formula for the join selectivity would be: 1/(Max(num-distinct(t1, column1), num-distinct(t2, column2))). Here, column1 and column2 are the join attributes. The cardinality of the join is then the product of the cardinalities of t1 and t2 times the selectivity.</p>
<p>另一种估计连接的cardinality的方法是假设小表中的每个值在大表中都有一个匹配的值。那么连接选择性的公式将是。1/(Max(num-distinct(t1, column1), num-distinct(t2, column2))）。这里，列1和列2是连接属性。连接的cardinality是t1和t2的cardinality乘以选择性的产物。</p>
<p>Improved subset iterator. Our implementation of enumerateSubsets is quite inefficient, because it creates a large number of Java objects on each invocation.</p>
<p>改进子集迭代器。我们对enumerateSubsets的实现是相当低效的，因为它在每次调用时都会创建大量的Java对象。</p>
<p>In this bonus exercise, you would improve the performance of enumerateSubsets so that your system could perform query optimization on plans with 20 or more joins (currently such plans takes minutes or hours to compute).</p>
<p>在这个奖励练习中，你将提高enumerateSubsets的性能，这样你的系统就可以对有20个或更多连接的计划进行查询优化（目前这样的计划需要几分钟或几小时来计算）。</p>
<p>A cost model that accounts for caching. The methods to estimate scan and join cost do not account for caching in the buffer pool. You should extend the cost model to account for caching effects. This is tricky because multiple joins are running simultaneously due to the iterator model, and so it may be hard to predict how much memory each will have access to using the simple buffer pool we have implemented in previous labs.</p>
<p>一个考虑到缓存的成本模型。估计扫描和连接成本的方法没有考虑到缓冲池中的缓存。你应该扩展成本模型以考虑到缓存效应。这很棘手，因为由于迭代器模型，多个连接是同时运行的，所以可能很难预测使用我们在以前的实验中实现的简单缓冲池，每个人可以获得多少内存。</p>
<p>Improved join algorithms and algorithm selection. Our current cost estimation and join operator selection algorithms (see instantiateJoin() in JoinOptimizer.java) only consider nested loops joins. Extend these methods to use one or more additional join algorithms (for example, some form of in memory hashing using a HashMap).</p>
<p>改进的连接算法和算法选择。我们目前的成本估算和连接运算符选择算法（见JoinOptimizer.java中的instantiateJoin()）只考虑嵌套循环的连接。扩展这些方法以使用一个或多个额外的连接算法（例如，使用HashMap的某种形式的内存散列）。</p>
<p>Bushy plans. Improve the provided orderJoins() and other helper methods to generate bushy joins. Our query plan generation and visualization algorithms are perfectly capable of handling bushy plans; for example, if orderJoins() returns the list (t1 join t2 ; t3 join t4 ; t2 join t3), this will correspond to a bushy plan with the (t2 join t3) node at the top.</p>
<p>忙碌的计划。改进所提供的orderJoins()和其他辅助方法，以生成bushy joins。我们的查询计划生成和可视化算法完全能够处理繁忙的计划；例如，如果orderJoins()返回列表(t1 join t2; t3 join t4; t2 join t3)，这将对应于一个繁忙的计划，(t2 join t3)节点在顶部。</p>
<p>You have now completed this lab. Good work!</p>
<p>你现在已经完成了这个实验。干得好!</p>
<h2 id="3-logistics-1"><a class="header" href="#3-logistics-1">3. Logistics</a></h2>
<p>You must submit your code (see below) as well as a short (2 pages, maximum) writeup describing your approach. This writeup should:</p>
<p>你必须提交你的代码（见下文）以及描述你的方法的简短（2页，最多）的文章。这篇报告应该</p>
<p>Describe any design decisions you made, including methods for selectivity estimation, join ordering, as well as any of the bonus exercises you chose to implement and how you implemented them (for each bonus exercise you may submit up to 1 additional page).
Discuss and justify any changes you made to the API.
Describe any missing or incomplete elements of your code.
Describe how long you spent on the lab, and whether there was anything you found particularly difficult or confusing.
Description of any extra credit implementation you have done.</p>
<p>描述你所做的任何设计决定，包括选择性估计的方法，连接排序，以及你选择实现的任何奖励练习和你如何实现它们（对于每个奖励练习，你可以提交多达1页的额外内容）。
讨论并证明你对API所作的任何修改。
描述你的代码中任何缺失或不完整的元素。
描述你花了多长时间做这个实验，以及是否有任何你认为特别困难或困惑的地方。
描述你所做的任何额外功劳的实现。</p>
<h2 id="31-collaboration-1"><a class="header" href="#31-collaboration-1">3.1. Collaboration</a></h2>
<p>This lab should be manageable for a single person, but if you prefer to work with a partner, this is also OK. Larger groups are not allowed. Please indicate clearly who you worked with, if anyone, on your writeup.</p>
<p>这个实室对一个人来说应该是可以应付的，但如果你喜欢和一个伙伴一起工作，这也是可以的。不允许有较大的团体。如果有的话，请在你的报告中明确指出你和谁一起工作。</p>
<h2 id="32-submitting-your-assignment-1"><a class="header" href="#32-submitting-your-assignment-1">3.2. Submitting your assignment</a></h2>
<p>We will be using gradescope to autograde all programming assignments. You should have all been invited to the class instance; if not, please let us know and we can help you set up. You may submit your code multiple times before the deadline; we will use the latest version as determined by gradescope. Place the write-up in a file called lab3-writeup.txt with your submission. You also need to explicitly add any other files you create, such as new *.java files.</p>
<p>我们将使用gradescope对所有编程作业进行自动评分。你们应该都被邀请到班级实例中；如果没有，请告诉我们，我们可以帮助你们设置。你可以在截止日期前多次提交你的代码；我们将使用由gradescope确定的最新版本。把写好的东西放在一个叫lab3-writeup.txt的文件里，和你的提交一起。你还需要明确地添加你创建的任何其他文件，如新的*.java文件。</p>
<p>The easiest way to submit to gradescope is with .zip files containing your code. On Linux/MacOS, you can do so by running the following command:</p>
<p>向 gradescope 提交的最简单方法是使用包含你的代码的 .zip 文件。在Linux/MacOS上，你可以通过运行以下命令来实现。</p>
<pre><code>$ zip -r submission.zip src/ lab3-writeup.txt
</code></pre>
<h2 id="33-submitting-a-bug-1"><a class="header" href="#33-submitting-a-bug-1">3.3. Submitting a bug</a></h2>
<p>SimpleDB is a relatively complex piece of code. It is very possible you are going to find bugs, inconsistencies, and bad, outdated, or incorrect documentation, etc.</p>
<p>SimpleDB是一个相对复杂的代码。你很可能会发现错误、不一致，以及糟糕的、过时的或不正确的文档等等。</p>
<p>We ask you, therefore, to do this lab with an adventurous mindset. Don't get mad if something is not clear, or even wrong; rather, try to figure it out yourself or send us a friendly email.</p>
<p>因此，我们要求你以一种冒险的心态来做这个实室。如果有不清楚的地方，甚至是错误的地方，不要生气；而是要自己尝试去弄清楚，或者给我们发一封友好的电子邮件。</p>
<p>Please submit (friendly!) bug reports to 6.830-staff@mit.edu. When you do, please try to include:</p>
<p>请提交（友好的！）错误报告到6.830-staff@mit.edu。当你这样做时，请尽量包括。</p>
<p>A description of the bug.
A .java file we can drop in the test/simpledb directory, compile, and run.
A .txt file with the data that reproduces the bug. We should be able to convert it to a .dat file using HeapFileEncoder.
You can also post on the class page on Piazza if you feel you have run into a bug.</p>
<p>一个关于该错误的描述。
一个.java文件，我们可以把它放到test/simpledb目录中，编译并运行。
一个包含再现该错误的数据的.txt文件。我们应该能够用HeapFileEncoder将其转换为.dat文件。
如果你觉得你遇到了一个bug，你也可以在Piazza的类页面上发帖。</p>
<h2 id="34-grading-1"><a class="header" href="#34-grading-1">3.4 Grading</a></h2>
<p>75% of your grade will be based on whether or not your code passes the system test suite we will run over it. These tests will be a superset of the tests we have provided. Before handing in your code, you should make sure it produces no errors (passes all of the tests) from both ant test and ant systemtest.</p>
<p>你的成绩的75%将基于你的代码是否通过我们将对其进行的系统测试套件。这些测试将是我们提供的测试的一个超集。在交出你的代码之前，你应该确保它在ant test和ant systemtest中没有产生错误（通过所有的测试）。</p>
<p>Important: before testing, gradescope will replace your build.xml, HeapFileEncoder.java and the entire contents of the test directory with our version of these files. This means you cannot change the format of .dat files! You should also be careful changing our APIs. You should test that your code compiles the unmodified tests.</p>
<p>重要的是：在测试之前，gradescope 会用我们的版本替换你的 build.xml、HeapFileEncoder.java 以及测试目录中的全部内容。这意味着你不能改变.dat文件的格式! 你也应该小心改变我们的API。你应该测试你的代码是否编译了未修改的测试。</p>
<p>You should get immediate feedback and error outputs for failed tests (if any) from gradescope after submission. The score given will be your grade for the autograded portion of the assignment. An additional 25% of your grade will be based on the quality of your writeup and our subjective evaluation of your code. This part will also be published on gradescope after we finish grading your assignment.</p>
<p>在提交后，你应该从 gradescope 得到即时反馈和失败测试的错误输出（如果有的话）。给出的分数将是你在作业的自动评分部分的成绩。另外25%的分数将基于你的写作质量和我们对你代码的主观评价。在我们给你的作业评分后，这部分也将在 gradescope 上公布。</p>
<p>We had a lot of fun designing this assignment, and we hope you enjoy hacking on it!</p>
<p>我们在设计这项作业时非常有趣，我们希望你能享受到黑客的乐趣!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-4-翻译"><a class="header" href="#lab-4-翻译">Lab 4 翻译</a></h1>
<p>Assigned: Monday, Apr 5, 2021
Due: Thursday, Apr 22, 2021 11:59 PM ET</p>
<p>In this lab, you will implement a simple locking-based transaction system in SimpleDB. You will need to add lock and unlock calls at the appropriate places in your code, as well as code to track the locks held by each transaction and grant locks to transactions as they are needed.</p>
<p>在这个实验中，你将在SimpleDB中实现一个简单的基于锁的事务系统。你将需要在代码中的适当位置添加锁和解锁调用，以及跟踪每个事务所持有的锁的代码，并在需要时授予事务锁。</p>
<p>The remainder of this document describes what is involved in adding transaction support and provides a basic outline of how you might add this support to your database.</p>
<p>本文档的其余部分描述了添加事务支持所涉及的内容，并提供了一个关于如何将这种支持添加到你的数据库的基本概要。</p>
<p>As with the previous lab, we recommend that you start as early as possible. Locking and transactions can be quite tricky to debug!</p>
<p>和前面的实验一样，我们建议你尽可能早地开始。锁定和事务可能是相当棘手的调试工作!</p>
<h2 id="1-getting-started-3"><a class="header" href="#1-getting-started-3">1. Getting started</a></h2>
<p>You should begin with the code you submitted for Lab 3 (if you did not submit code for Lab 3, or your solution didn't work properly, contact us to discuss options). Additionally, we are providing extra test cases for this lab that are not in the original code distribution you received. We reiterate that the unit tests we provide are to help guide your implementation along, but they are not intended to be comprehensive or to establish correctness.</p>
<p>你应该从你为实验3提交的代码开始（如果你没有为实验3提交代码，或者你的解决方案没有正常工作，请与我们联系，讨论各种方案）。此外，我们还为这个实验提供了额外的测试案例，这些案例不在你收到的原始代码分发中。我们重申，我们提供的单元测试是为了帮助指导你的实施，但它们并不打算是全面的或建立正确性。</p>
<p>You will need to add these new files to your release. The easiest way to do this is to change to your project directory (probably called simple-db-hw) and pull from the master GitHub repository:</p>
<p>你将需要把这些新文件添加到你的版本中。最简单的方法是换到你的项目目录（可能叫simple-db-hw），然后从GitHub的主仓库拉出。</p>
<pre><code>$ cd simple-db-hw
$ git pull upstream master
</code></pre>
<h2 id="2-transactions-locking-and-concurrency-control"><a class="header" href="#2-transactions-locking-and-concurrency-control">2. Transactions, Locking, and Concurrency Control</a></h2>
<p>Before starting, you should make sure you understand what a transaction is and how strict two-phase locking (which you will use to ensure isolation and atomicity of your transactions) works.</p>
<p>在开始之前，你应该确保你了解什么是事务，以及严格的两阶段锁定（你将使用它来确保事务的隔离性和原子性）是如何工作的。</p>
<p>In the remainder of this section, we briefly overview these concepts and discuss how they relate to SimpleDB.</p>
<p>在本节的剩余部分，我们简要地概述这些概念，并讨论它们与SimpleDB的关系。</p>
<h2 id="21-transactions"><a class="header" href="#21-transactions">2.1. Transactions</a></h2>
<p>A transaction is a group of database actions (e.g., inserts, deletes, and reads) that are executed atomically; that is, either all of the actions complete or none of them do, and it is not apparent to an outside observer of the database that these actions were not completed as a part of a single, indivisible action.</p>
<p>事务是一组原子执行的数据库操作（例如插入、删除和读取）；也就是说，要么所有的操作都完成了，要么都没有完成，而且对于数据库的外部观察者来说，这些操作没有作为一个单一的、不可分割的操作的一部分完成，这一点是不明显的。</p>
<h2 id="22-the-acid-properties"><a class="header" href="#22-the-acid-properties">2.2. The ACID Properties</a></h2>
<p>To help you understand how transaction management works in SimpleDB, we briefly review how it ensures that the ACID properties are satisfied:</p>
<p>为了帮助你理解SimpleDB中的事务管理是如何工作的，我们简单回顾一下它是如何确保ACID属性得到满足的。</p>
<p>Atomicity: Strict two-phase locking and careful buffer management ensure atomicity.</p>
<p>原子性：严格的两阶段锁定和谨慎的缓冲区管理确保了原子性。</p>
<p>Consistency: The database is transaction consistent by virtue of atomicity. Other consistency issues (e.g., key constraints) are not addressed in SimpleDB.</p>
<p>一致性：由于原子性，数据库是事务一致的。其他的一致性问题（例如，键约束）在SimpleDB中没有被解决。</p>
<p>Isolation: Strict two-phase locking provides isolation.</p>
<p>隔离：严格的两相锁定提供隔离。</p>
<p>Durability: A FORCE buffer management policy ensures durability (see Section 2.3 below).</p>
<p>持久性。FORCE的缓冲区管理政策确保了持久性（见下文2.3节）。</p>
<h2 id="23-recovery-and-buffer-management"><a class="header" href="#23-recovery-and-buffer-management">2.3. Recovery and Buffer Management</a></h2>
<p>To simplify your job, we recommend that you implement a NO STEAL/FORCE buffer management policy.</p>
<p>为了简化你的工作，我们建议你实施 &quot;不偷不抢 &quot;的缓冲区管理政策。</p>
<p>As we discussed in class, this means that:</p>
<p>正如我们在课堂上讨论的那样，这意味着。</p>
<p>You shouldn't evict dirty (updated) pages from the buffer pool if they are locked by an uncommitted transaction (this is NO STEAL).</p>
<p>你不应该从缓冲池中驱逐脏的（更新的）页面，如果它们被一个未提交的事务锁定（这不是偷窃）。</p>
<p>On transaction commit, you should force dirty pages to disk (e.g., write the pages out) (this is FORCE).</p>
<p>在事务提交时，你应该把脏页强制到磁盘上（例如，把页写出来）（这就是FORCE）。</p>
<p>To further simplify your life, you may assume that SimpleDB will not crash while processing a transactionComplete command. Note that these three points mean that you do not need to implement log-based recovery in this lab, since you will never need to undo any work (you never evict dirty pages) and you will never need to redo any work (you force updates on commit and will not crash during commit processing).</p>
<p>为了进一步简化你的生活，你可以假设SimpleDB在处理transactionComplete命令时不会崩溃。请注意，这三点意味着你不需要在这个实验中实现基于日志的恢复，因为你永远不需要撤销任何工作（你永远不会驱逐脏页），也不需要重做任何工作（你在提交时强制更新，不会在提交处理期间崩溃）。</p>
<h2 id="24-granting-locks"><a class="header" href="#24-granting-locks">2.4. Granting Locks</a></h2>
<p>You will need to add calls to SimpleDB (in BufferPool, for example), that allow a caller to request or release a (shared or exclusive) lock on a specific object on behalf of a specific transaction.</p>
<p>你将需要增加对SimpleDB的调用（例如在BufferPool中），允许调用者代表特定事务请求或释放特定对象的（共享或独占）锁。</p>
<p>We recommend locking at page granularity; please do not implement table-level locking (even though it is possible) for simplicity of testing. The rest of this document and our unit tests assume page-level locking.</p>
<p>我们建议以页为单位进行锁定；为了测试的简单性，请不要实现表级的锁定（尽管它是可能的）。本文档的其余部分和我们的单元测试都是假设页级锁的。</p>
<p>You will need to create data structures that keep track of which locks each transaction holds and check to see if a lock should be granted to a transaction when it is requested.</p>
<p>你将需要创建数据结构来跟踪每个事务持有哪些锁，并在事务被请求时检查是否应该授予其锁。</p>
<p>You will need to implement shared and exclusive locks; recall that these work as follows:</p>
<p>你将需要实现共享锁和独占锁；回顾一下，这些锁的工作方式如下。</p>
<p>Before a transaction can read an object, it must have a shared lock on it.</p>
<p>在一个事务可以读取一个对象之前，它必须有一个共享锁在上面。</p>
<p>Before a transaction can write an object, it must have an exclusive lock on it.</p>
<p>在一个事务可以写入一个对象之前，它必须有一个独占锁。</p>
<p>Multiple transactions can have a shared lock on an object.</p>
<p>多个事务可以在一个对象上拥有一个共享锁。</p>
<p>Only one transaction may have an exclusive lock on an object.</p>
<p>只有一个事务可以在一个对象上拥有一个独占锁。</p>
<p>If transaction t is the only transaction holding a shared lock on an object o, t may upgrade its lock on o to an exclusive lock.</p>
<p>如果事务t是唯一在对象o上持有共享锁的事务，t可以将其对o的锁升级为独占锁。</p>
<p>If a transaction requests a lock that cannot be immediately granted, your code should block, waiting for that lock to become available (i.e., be released by another transaction running in a different thread). Be careful about race conditions in your lock implementation --- think about how concurrent invocations to your lock may affect the behavior. (you way wish to read about Synchronization in Java).</p>
<p>如果一个事务请求一个不能立即授予的锁，你的代码应该阻塞，等待该锁变得可用（即，被另一个在不同线程中运行的事务释放）。在你的锁的实现中要小心竞争条件------考虑对你的锁的并发调用会如何影响你的行为。(你可以阅读关于Java中的同步的文章）。</p>
<h2 id="exercise-1-3"><a class="header" href="#exercise-1-3">Exercise 1.</a></h2>
<p>Write the methods that acquire and release locks in BufferPool. Assuming you are using page-level locking, you will need to complete the following:</p>
<p>编写BufferPool中获取和释放锁的方法。假设你使用的是页级锁，你将需要完成以下工作。</p>
<p>Modify getPage() to block and acquire the desired lock before returning a page.
Implement unsafeReleasePage(). This method is primarily used for testing, and at the end of transactions.
Implement holdsLock() so that logic in Exercise 2 can determine whether a page is already locked by a transaction.
You may find it helpful to define a LockManager class that is responsible for maintaining state about transactions and locks, but the design decision is up to you.</p>
<p>修改getPage()，使其在返回页面前阻塞并获得所需的锁。
实现unsafeReleasePage()。这个方法主要用于测试，以及在事务结束时使用。
实现 holdsLock()，以便练习2中的逻辑能够确定一个页面是否已经被事务锁定。
你可能会发现，定义一个LockManager类来负责维护事务和锁的状态是很有帮助的，但设计决定权在你。</p>
<p>You may need to implement the next exercise before your code passes the unit tests in LockingTest.</p>
<p>在你的代码通过LockingTest的单元测试之前，你可能需要实现下一个练习。</p>
<h2 id="25-lock-lifetime"><a class="header" href="#25-lock-lifetime">2.5. Lock Lifetime</a></h2>
<p>You will need to implement strict two-phase locking. This means that transactions should acquire the appropriate type of lock on any object before accessing that object and shouldn't release any locks until after the transaction commits.</p>
<p>你将需要实现严格的两阶段锁。这意味着事务在访问任何对象之前应该获得相应类型的锁，并且在事务提交之前不应该释放任何锁。</p>
<p>Fortunately, the SimpleDB design is such that it is possible to obtain locks on pages in BufferPool.getPage() before you read or modify them. So, rather than adding calls to locking routines in each of your operators, we recommend acquiring locks in getPage(). Depending on your implementation, it is possible that you may not have to acquire a lock anywhere else. It is up to you to verify this!</p>
<p>幸运的是，SimpleDB的设计是这样的：在你读取或修改页面之前，有可能在BufferPool.getPage()中获得页面的锁。因此，我们建议在getPage()中获取锁，而不是在你的每个操作中添加对锁程序的调用。根据你的实现，你有可能不需要在其他地方获取锁。这要靠你自己去验证!</p>
<p>You will need to acquire a shared lock on any page (or tuple) before you read it, and you will need to acquire an exclusive lock on any page (or tuple) before you write it. You will notice that we are already passing around Permissions objects in the BufferPool; these objects indicate the type of lock that the caller would like to have on the object being accessed (we have given you the code for the Permissions class.)</p>
<p>你需要在读取任何页面（或元组）之前获得一个共享锁，你需要在写入任何页面（或元组）之前获得一个独占锁。你会注意到，我们已经在BufferPool中传递了许可对象；这些对象表明调用者希望对被访问对象拥有的锁的类型（我们已经给了你许可类的代码。）</p>
<p>Note that your implementation of HeapFile.insertTuple() and HeapFile.deleteTuple(), as well as the implementation of the iterator returned by HeapFile.iterator() should access pages using BufferPool.getPage(). Double check that these different uses of getPage() pass the correct permissions object (e.g., Permissions.READ_WRITE or Permissions.READ_ONLY). You may also wish to double check that your implementation of BufferPool.insertTuple() and BufferPool.deleteTupe() call markDirty() on any of the pages they access (you should have done this when you implemented this code in lab 2, but we did not test for this case.)</p>
<p>请注意，你对HeapFile.insertTuple()和HeapFile.deleteTuple()的实现，以及HeapFile.iterator()返回的迭代器的实现应该使用BufferPool.getPage()访问页面。仔细检查这些getPage()的不同用法是否传递了正确的权限对象（例如，Permissions.READ_WRITE 或 Permissions.READ_ONLY）。你也可以仔细检查你实现的BufferPool.insertTuple()和BufferPool.deleteTupe()是否在它们访问的任何页面上调用markDirty()（你在实验2中实现这段代码时应该这样做，但我们没有测试这种情况）。</p>
<p>After you have acquired locks, you will need to think about when to release them as well. It is clear that you should release all locks associated with a transaction after it has committed or aborted to ensure strict 2PL. However, it is possible for there to be other scenarios in which releasing a lock before a transaction ends might be useful. For instance, you may release a shared lock on a page after scanning it to find empty slots (as described below).</p>
<p>在你获得锁之后，你也需要考虑何时释放它们。很明显，你应该在一个事务提交或中止后释放所有与之相关的锁，以确保严格的2PL。然而，在其他情况下，在事务结束前释放锁可能是有用的。例如，你可以在扫描页面找到空槽后释放一个共享锁（如下所述）。</p>
<h2 id="exercise-2-3"><a class="header" href="#exercise-2-3">Exercise 2.</a></h2>
<p>Ensure that you acquire and release locks throughout SimpleDB. Some (but not necessarily all) actions that you should verify work properly:</p>
<p>确保你在整个SimpleDB获得和释放锁。一些（但不一定是全部）你应该验证的操作正常工作。</p>
<p>Reading tuples off of pages during a SeqScan (if you implemented locking in BufferPool.getPage(), this should work correctly as long as your HeapFile.iterator() uses BufferPool.getPage().)</p>
<p>在SeqScan过程中从页面上读取 tuple（如果你在BufferPool.getPage()中实现了锁定，只要你的HeapFile.iterator()使用BufferPool.getPage()，这应该可以正确工作。）</p>
<p>Inserting and deleting tuples through BufferPool and HeapFile methods (if you implemented locking in BufferPool.getPage(), this should work correctly as long as HeapFile.insertTuple() and HeapFile.deleteTuple() use BufferPool.getPage().)
You will also want to think especially hard about acquiring and releasing locks in the following situations:</p>
<p>通过BufferPool和HeapFile方法插入和删除图元（如果你在BufferPool.getPage()中实现了锁，只要HeapFile.insertTuple()和HeapFile.deleteTuple()使用BufferPool.getPage()，这应该能正确工作。）
你还需要特别考虑在以下情况下获取和释放锁的问题。</p>
<p>Adding a new page to a HeapFile. When do you physically write the page to disk? Are there race conditions with other transactions (on other threads) that might need special attention at the HeapFile level, regardless of page-level locking?</p>
<p>向HeapFile添加一个新的页面。你什么时候把这个页面写到磁盘上？是否存在与其他事务（在其他线程上）的竞赛条件，可能需要在HeapFile级别上特别注意，而不考虑页级锁定？</p>
<p>Looking for an empty slot into which you can insert tuples. Most implementations scan pages looking for an empty slot, and will need a READ_ONLY lock to do this. Surprisingly, however, if a transaction t finds no free slot on a page p, t may immediately release the lock on p. Although this apparently contradicts the rules of two-phase locking, it is ok because t did not use any data from the page, such that a concurrent transaction t' which updated p cannot possibly effect the answer or outcome of t.</p>
<p>寻找一个可以插入图元的空槽。大多数实现都会扫描页面，寻找一个空槽，并且需要一个READ_ONLY锁来完成这个工作。然而，令人惊讶的是，如果一个事务t发现页面p上没有空槽，t可以立即释放p上的锁。虽然这显然与两阶段锁的规则相矛盾，但它是可以的，因为t没有使用页面上的任何数据，这样，一个更新p的并发事务t'不可能影响t的答案或结果。</p>
<p>At this point, your code should pass the unit tests in LockingTest.</p>
<p>在这一点上，你的代码应该通过LockingTest中的单元测试。</p>
<h2 id="26-implementing-no-steal"><a class="header" href="#26-implementing-no-steal">2.6. Implementing NO STEAL</a></h2>
<p>Modifications from a transaction are written to disk only after it commits. This means we can abort a transaction by discarding the dirty pages and rereading them from disk. Thus, we must not evict dirty pages. This policy is called NO STEAL.</p>
<p>一个事务的修改只有在它提交之后才会被写入磁盘。这意味着我们可以通过丢弃脏页并从磁盘重读来中止一个事务。因此，我们必须不驱逐脏页。这个策略被称为NO STEAL。</p>
<p>You will need to modify the evictPage method in BufferPool. In particular, it must never evict a dirty page. If your eviction policy prefers a dirty page for eviction, you will have to find a way to evict an alternative page. In the case where all pages in the buffer pool are dirty, you should throw a DbException. If your eviction policy evicts a clean page, be mindful of any locks transactions may already hold to the evicted page and handle them appropriately in your implementation.</p>
<p>你将需要修改BufferPool中的evictPage方法。特别是，它必须永远不驱逐一个脏页。如果你的驱逐策略倾向于驱逐一个脏页，你将不得不找到一种方法来驱逐一个替代页。在缓冲池中的所有页面都是脏的情况下，你应该抛出一个DbException。如果你的驱逐策略驱逐了一个干净的页面，要注意事务可能已经持有被驱逐的页面的任何锁，并在你的实现中适当地处理它们。</p>
<h2 id="exercise-3-4"><a class="header" href="#exercise-3-4">Exercise 3.</a></h2>
<p>Implement the necessary logic for page eviction without evicting dirty pages in the evictPage method in BufferPool.</p>
<p>在BufferPool的evictPage方法中实现必要的页面驱逐逻辑，而不驱逐脏页。</p>
<h2 id="27-transactions"><a class="header" href="#27-transactions">2.7. Transactions</a></h2>
<p>In SimpleDB, a TransactionId object is created at the beginning of each query. This object is passed to each of the operators involved in the query. When the query is complete, the BufferPool method transactionComplete is called.</p>
<p>在SimpleDB中，每次查询开始时都会创建一个TransactionId对象。这个对象被传递给每个参与查询的操作者。当查询完成后，BufferPool方法 transactionComplete被调用。</p>
<p>Calling this method either commits or aborts the transaction, specified by the parameter flag commit. At any point during its execution, an operator may throw a TransactionAbortedException exception, which indicates an internal error or deadlock has occurred. The test cases we have provided you with create the appropriate TransactionId objects, pass them to your operators in the appropriate way, and invoke transactionComplete when a query is finished. We have also implemented TransactionId.</p>
<p>调用此方法可以提交或中止事务，由参数标志commit指定。在其执行过程中的任何时候，操作者都可以抛出一个TransactionAbortedException异常，这表明发生了内部错误或死锁。我们为你提供的测试案例创建了适当的TransactionId对象，以适当的方式将它们传递给你的操作者，并在查询完成后调用 transactionComplete。我们还实现了TransactionId。</p>
<h2 id="exercise-4-4"><a class="header" href="#exercise-4-4">Exercise 4.</a></h2>
<p>Implement the transactionComplete() method in BufferPool. Note that there are two versions of transactionComplete, one which accepts an additional boolean commit argument, and one which does not. The version without the additional argument should always commit and so can simply be implemented by calling transactionComplete(tid, true).</p>
<p>在BufferPool中实现transactionComplete()方法。请注意，transactionComplete有两个版本，一个是接受额外的布尔提交参数，另一个是不接受。没有额外参数的版本应该总是提交，所以可以简单地通过调用 transactionComplete(tid, true) 来实现。</p>
<p>When you commit, you should flush dirty pages associated to the transaction to disk. When you abort, you should revert any changes made by the transaction by restoring the page to its on-disk state.</p>
<p>当你提交时，你应该将与事务相关的脏页冲到磁盘上。当你放弃的时候，你应该通过恢复页面到磁盘上的状态来恢复事务所做的任何改变。</p>
<p>Whether the transaction commits or aborts, you should also release any state the BufferPool keeps regarding the transaction, including releasing any locks that the transaction held.</p>
<p>无论事务是提交还是中止，你都应该释放BufferPool保存的关于该事务的任何状态，包括释放该事务持有的任何锁。</p>
<p>At this point, your code should pass the TransactionTest unit test and the AbortEvictionTest system test. You may find the TransactionTest system test illustrative, but it will likely fail until you complete the next exercise.</p>
<p>在这一点上，你的代码应该通过TransactionTest单元测试和AbortEvictionTest系统测试。你可能会发现TransactionTest系统测试的说明性，但在你完成下一个练习之前，它可能会失败。</p>
<h2 id="28-deadlocks-and-aborts"><a class="header" href="#28-deadlocks-and-aborts">2.8. Deadlocks and Aborts</a></h2>
<p>It is possible for transactions in SimpleDB to deadlock (if you do not understand why, we recommend reading about deadlocks in Ramakrishnan &amp; Gehrke). You will need to detect this situation and throw a TransactionAbortedException.</p>
<p>SimpleDB中的事务有可能出现死锁（如果你不明白为什么，我们建议阅读Ramakrishnan &amp; Gehrke中关于死锁的内容）。你需要检测这种情况并抛出一个TransactionAbortedException。</p>
<p>There are many possible ways to detect deadlock. A strawman example would be to implement a simple timeout policy that aborts a transaction if it has not completed after a given period of time. For a real solution, you may implement cycle-detection in a dependency graph data structure as shown in lecture. In this scheme, you would check for cycles in a dependency graph periodically or whenever you attempt to grant a new lock, and abort something if a cycle exists. After you have detected that a deadlock exists, you must decide how to improve the situation. Assume you have detected a deadlock while transaction t is waiting for a lock. If you're feeling homicidal, you might abort all transactions that t is waiting for; this may result in a large amount of work being undone, but you can guarantee that t will make progress. Alternately, you may decide to abort t to give other transactions a chance to make progress. This means that the end-user will have to retry transaction t.</p>
<p>有许多可能的方法来检测死锁。一个草根的例子是实现一个简单的超时策略，如果一个事务在给定的时间内还没有完成，就中止它。对于一个真正的解决方案，你可以在一个依赖图数据结构中实现周期检测，如讲座中所示。在这个方案中，你将定期检查依赖图中的周期，或者每当你试图授予一个新的锁时，如果存在一个周期，就中止某事。在你检测到死锁存在后，你必须决定如何改善这种情况。假设你在事务t等待锁的时候检测到了一个死锁。如果你有杀人的冲动，你可以中止t正在等待的所有事务；这可能会导致大量的工作被撤销，但你可以保证t会取得进展。另外，你也可以决定中止t，给其他事务一个取得进展的机会。这意味着终端用户将不得不重试事务t。</p>
<p>Another approach is to use global orderings of transactions to avoid building the wait-for graph. This is sometimes preferred for performance reasons, but transactions that could have succeeded can be aborted by mistake under this scheme. Examples include the WAIT-DIE and WOUND-WAIT schemes.</p>
<p>另一种方法是使用事务的全局排序来避免建立等待图。出于性能方面的考虑，这有时是首选，但是在这种方案下，本来可以成功的事务可能会被错误地中止。例子包括WAIT-DIE和WOUND-WAIT方案。</p>
<h2 id="exercise-5-4"><a class="header" href="#exercise-5-4">Exercise 5.</a></h2>
<p>Implement deadlock detection or prevention in src/simpledb/BufferPool.java. You have many design decisions for your deadlock handling system, but it is not necessary to do something highly sophisticated. We expect you to do better than a simple timeout on each transaction. A good starting point will be to implement cycle-detection in a wait-for graph before every lock request, and you will receive full credit for such an implementation. Please describe your choices in the lab writeup and list the pros and cons of your choice compared to the alternatives.</p>
<p>在 src/simpledb/BufferPool.java 中实现死锁检测或预防。对于你的死锁处理系统，你有很多设计决定，但没有必要做一些非常复杂的事情。我们希望你能做得比每个事务的简单超时更好。一个好的起点是在每个锁请求前的等待图中实现周期检测，这样的实现将得到全额奖励。请在实验报告中描述你的选择，并列出你的选择与其他选择相比的优点和缺点。</p>
<p>You should ensure that your code aborts transactions properly when a deadlock occurs, by throwing a TransactionAbortedException exception. This exception will be caught by the code executing the transaction (e.g., TransactionTest.java), which should call transactionComplete() to cleanup after the transaction. You are not expected to automatically restart a transaction which fails due to a deadlock -- you can assume that higher level code will take care of this.</p>
<p>你应该通过抛出TransactionAbortedException异常来确保你的代码在发生死锁时正确中止事务。这个异常将被执行事务的代码所捕获（例如，TransactionTest.java），它应该调用 transactionComplete() 来清理事务。我们不期望你自动重启一个因死锁而失败的事务--你可以假设更高级别的代码会处理这个问题。</p>
<p>We have provided some (not-so-unit) tests in test/simpledb/DeadlockTest.java. They are actually a bit involved, so they may take more than a few seconds to run (depending on your policy). If they seem to hang indefinitely, then you probably have an unresolved deadlock. These tests construct simple deadlock situations that your code should be able to escape.</p>
<p>我们在test/simpledb/DeadlockTest.java中提供了一些（不是单元的）测试。它们实际上有点复杂，所以它们可能需要超过几秒钟的时间来运行（取决于你的策略）。如果它们似乎无限期地挂起，那么你可能有一个未解决的死锁。这些测试构建了简单的死锁情况，你的代码应该能够逃脱。</p>
<p>Note that there are two timing parameters near the top of DeadLockTest.java; these determine the frequency at which the test checks if locks have been acquired and the waiting time before an aborted transaction is restarted. You may observe different performance characteristics by tweaking these parameters if you use a timeout-based detection method. The tests will output TransactionAbortedExceptions corresponding to resolved deadlocks to the console.</p>
<p>注意，在DeadLockTest.java的顶部附近有两个计时参数；这些参数决定了测试检查是否已经获得锁的频率，以及中止的事务被重新启动前的等待时间。如果你使用基于超时的检测方法，你可以通过调整这些参数观察到不同的性能特征。测试将把解决死锁对应的TransactionAbortedExceptions输出到控制台。</p>
<p>Your code should now should pass the TransactionTest system test (which may also run for quite a long time depending on your implementation).</p>
<p>你的代码现在应该通过TransactionTest系统测试（根据你的实现，它也可能运行相当长的时间）。</p>
<p>At this point, you should have a recoverable database, in the sense that if the database system crashes (at a point other than transactionComplete()) or if the user explicitly aborts a transaction, the effects of any running transaction will not be visible after the system restarts (or the transaction aborts.) You may wish to verify this by running some transactions and explicitly killing the database server.</p>
<p>在这一点上，你应该有一个可恢复的数据库，也就是说，如果数据库系统崩溃（在 transactionComplete() 以外的地方），或者如果用户显式地中止一个事务，那么在系统重新启动（或者事务中止）之后，任何正在运行的事务的影响将不可见。 你可能希望通过运行一些事务和显式地杀死数据库服务器来验证这一点。</p>
<h2 id="29-design-alternatives"><a class="header" href="#29-design-alternatives">2.9. Design alternatives</a></h2>
<p>During the course of this lab, we have identified some substantial design choices that you have to make:</p>
<p>在这个实验的过程中，我们已经确定了一些你必须做出的实质性设计选择。</p>
<p>Locking granularity: page-level versus tuple-level
Deadlock handling: detection vs. prevention, aborting yourself vs. others.
Bonus Exercise 6. (20% extra credit)</p>
<p>锁定颗粒度：页级与元组级
死锁处理：检测与预防，终止自己与终止他人。
奖励练习6. (20%的额外学分)</p>
<p>For one or more of these choices, implement both alternatives and experimentally compare their performance charateristics. Include your benchmarking code and a brief evaluation (possibly with graphs) in your writeup.</p>
<p>对于这些选择中的一个或多个，实现两种选择，并通过实验比较它们的性能特征。在你的文章中包括你的基准代码和简短的评估（可能有图表）。</p>
<p>You have now completed this lab. Good work!</p>
<p>你现在已经完成了这个实验。干得好!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-5-翻译"><a class="header" href="#lab-5-翻译">Lab 5 翻译</a></h1>
<p>Assigned: Wednesday, April 21, 2021
Due: Tuesday, May 4, 2021 11:59 PM EDT</p>
<h2 id="0-introduction"><a class="header" href="#0-introduction">0. Introduction</a></h2>
<p>In this lab you will implement a B+ tree index for efficient lookups and range scans. We supply you with all of the low-level code you will need to implement the tree structure. You will implement searching, splitting pages, redistributing tuples between pages, and merging pages.</p>
<p>在这个实验中，你将实现一个B+树形索引，用于高效的查找和范围扫描。我们为你提供了实现树形结构所需的所有底层代码。你将实现搜索、拆分页面、在页面之间重新分配 tuple 以及合并页面。</p>
<p>You may find it helpful to review sections 10.3--10.7 in the textbook, which provide detailed information about the structure of B+ trees as well as pseudocode for searches, inserts and deletes.</p>
<p>你可能会发现复习教科书中的第10.3--10.7节很有帮助，这些章节提供了关于B+树结构的详细信息，以及搜索、插入和删除的伪代码。</p>
<p>As described by the textbook and discussed in class, the internal nodes in B+ trees contain multiple entries, each consisting of a key value and a left and a right child pointer. Adjacent keys share a child pointer, so internal nodes containing m keys have m+1 child pointers. Leaf nodes can either contain data entries or pointers to data entries in other database files. For simplicity, we will implement a B+tree in which the leaf pages actually contain the data entries. Adjacent leaf pages are linked together with right and left sibling pointers, so range scans only require one initial search through the root and internal nodes to find the first leaf page. Subsequent leaf pages are found by following right (or left) sibling pointers.</p>
<p>正如教科书所描述的和课堂上讨论的，B+树的内部节点包含多个条目，每个条目由一个键值和一个左、右子指针组成。相邻的键共享一个子指针，所以包含m个键的内部节点有m+1个子指针。叶子节点可以包含数据条目或指向其他数据库文件的数据条目的指针。为了简单起见，我们将实现一个B+树，其中叶子页实际上包含数据条目。相邻的叶子页用左右的同级指针连接在一起，所以范围扫描只需要通过根节点和内部节点进行一次初始搜索就可以找到第一个叶子页。随后的叶子页是通过跟随右（或左）同级指针找到的。</p>
<h2 id="1-getting-started-4"><a class="header" href="#1-getting-started-4">1. Getting started</a></h2>
<p>You should begin with the code you submitted for Lab 4 (if you did not submit code for Lab 4, or your solution didn't work properly, contact us to discuss options). Additionally, we are providing extra source and test files for this lab that are not in the original code distribution you received.</p>
<p>你应该从你为实验4提交的代码开始（如果你没有为实验4提交代码，或者你的解决方案没有正常工作，请与我们联系，讨论各种方案）。此外，我们还为这个实验提供了额外的源文件和测试文件，这些文件不在你收到的原始代码分发中。</p>
<p>You will need to add these new files to your release and set up your lab4 branch. The easiest way to do this is to change to your project directory (probably called simple-db-hw), set up the branch, and pull from the master GitHub repository:</p>
<p>你需要把这些新文件添加到你的版本中，并建立你的lab4分支。最简单的方法是切换到你的项目目录（可能叫simple-db-hw），建立分支，然后从GitHub的主仓库拉取。</p>
<pre><code>$ cd simple-db-hw $ git pull upstream master
</code></pre>
<h2 id="2-search"><a class="header" href="#2-search">2. Search</a></h2>
<p>Take a look at index/ and BTreeFile.java. This is the core file for the implementation of the B+Tree and where you will write all your code for this lab. Unlike the HeapFile, the BTreeFile consists of four different kinds of pages. As you would expect, there are two different kinds of pages for the nodes of the tree: internal pages and leaf pages. Internal pages are implemented in BTreeInternalPage.java, and leaf pages are implemented in BTreeLeafPage.java. For convenience, we have created an abstract class in BTreePage.java which contains code that is common to both leaf and internal pages. In addition, header pages are implemented in BTreeHeaderPage.java and keep track of which pages in the file are in use. Lastly, there is one page at the beginning of every BTreeFile which points to the root page of the tree and the first header page. This singleton page is implemented in BTreeRootPtrPage.java. Familiarize yourself with the interfaces of these classes, especially BTreePage, BTreeInternalPage and BTreeLeafPage. You will need to use these classes in your implementation of the B+Tree.</p>
<p>看一下 index/ 和 BTreeFile.java 。这是实现B+Tree的核心文件，你将在这里编写本实验的所有代码。与HeapFile不同，BTreeFile由四种不同的页面组成。正如你所期望的，树的节点有两种不同的页：内部页和叶子页。内部页在BTreeInternalPage.java中实现，而叶子页在BTreeLeafPage.java中实现。为了方便起见，我们在BTreePage.java中创建了一个抽象类，其中包含了叶子页和内部页的共同代码。此外，标题页在BTreeHeaderPage.java中实现，并跟踪文件中哪些页正在使用。最后，在每个BTreeFile的开头都有一个页面，它指向树的根页和第一个标题页。这个单子页在BTreeRootPtrPage.java中实现。熟悉这些类的接口，特别是BTreePage、BTreeInternalPage和BTreeLeafPage。你将需要在你的B+Tree的实现中使用这些类。</p>
<p>Your first job is to implement the findLeafPage() function in BTreeFile.java. This function is used to find the appropriate leaf page given a particular key value, and is used for both searches and inserts. For example, suppose we have a B+Tree with two leaf pages (See Figure 1). The root node is an internal page with one entry containing one key (6, in this case) and two child pointers. Given a value of 1, this function should return the first leaf page. Likewise, given a value of 8, this function should return the second page. The less obvious case is if we are given a key value of 6. There may be duplicate keys, so there could be 6's on both leaf pages. In this case, the function should return the first (left) leaf page.</p>
<p>你的第一个工作是在BTreeFile.java中实现findLeafPage()函数。这个函数用于在给定一个特定的键值的情况下找到合适的叶子页，并且用于搜索和插入。例如，假设我们有一个有两个叶子页的B+Tree（见图1）。根节点是一个内部页面，有一个条目，包含一个键（本例中为6）和两个子指针。给定一个值为1，这个函数应该返回第一个叶子页。同样地，如果数值为8，这个函数应该返回第二个页面。不太明显的情况是，如果我们给定的键值是6，可能有重复的键，所以两个叶子页上可能都有6。在这种情况下，这个函数应该返回第一个（左边）叶子页。</p>
<p><img src="6.830/cn/image/6-lab5/1644485061911.png" alt="" />
Figure 1: A simple B+ Tree with duplicate keys</p>
<p>图1：一个简单的有重复 key 的 B+ 树</p>
<p>Your findLeafPage() function should recursively search through internal nodes until it reaches the leaf page corresponding to the provided key value. In order to find the appropriate child page at each step, you should iterate through the entries in the internal page and compare the entry value to the provided key value. BTreeInternalPage.iterator() provides access to the entries in the internal page using the interface defined in BTreeEntry.java. This iterator allows you to iterate through the key values in the internal page and access the left and right child page ids for each key. The base case of your recursion happens when the passed-in BTreePageId has pgcateg() equal to BTreePageId.LEAF, indicating that it is a leaf page. In this case, you should just fetch the page from the buffer pool and return it. You do not need to confirm that it actually contains the provided key value f.</p>
<p>你的findLeafPage()函数应该递归地搜索内部节点，直到到达与所提供的键值相对应的叶子页。为了在每一步找到合适的子页面，你应该遍历内部页面中的条目，并将条目值与提供的键值进行比较。BTreeInternalPage.iterator()使用BTreeEntry.java中定义的接口提供了对内部页面中条目的访问。这个迭代器允许你遍历内部页面中的键值，并访问每个键的左右子页面ID。当传入的BTreePageId的pgcateg()等于BTreePageId.LEAF时，你递归的基本情况就会发生，表明它是一个叶子页。在这种情况下，你应该只是从缓冲池中获取该页并返回它。你不需要确认它是否真的包含所提供的键值f。</p>
<p>Your findLeafPage() code must also handle the case when the provided key value f is null. If the provided value is null, recurse on the left-most child every time in order to find the left-most leaf page. Finding the left-most leaf page is useful for scanning the entire file. Once the correct leaf page is found, you should return it. As mentioned above, you can check the type of page using the pgcateg() function in BTreePageId.java. You can assume that only leaf and internal pages will be passed to this function.</p>
<p>你的findLeafPage()代码还必须处理所提供的键值f为空的情况。如果提供的值是空的，每次都在最左边的子页上递归，以便找到最左边的叶子页。找到最左边的叶子页对于扫描整个文件是很有用的。一旦找到正确的叶子页，你应该返回它。如上所述，你可以使用BTreePageId.java中的pgcateg()函数检查页面的类型。你可以假设只有叶子页和内部页会被传递给这个函数。</p>
<p>Instead of directly calling BufferPool.getPage() to get each internal page and leaf page, we recommend calling the wrapper function we have provided, BTreeFile.getPage(). It works exactly like BufferPool.getPage(), but takes an extra argument to track the list of dirty pages. This function will be important for the next two exercises in which you will actually update the data and therefore need to keep track of dirty pages.</p>
<p>与其直接调用BufferPool.getPage()来获取每个内部页面和叶子页面，我们建议调用我们提供的包装函数BTreeFile.getPage()。它的工作原理与BufferPool.getPage()完全一样，但需要一个额外的参数来跟踪脏页的列表。这个函数在接下来的两个练习中非常重要，你将实际更新数据，因此需要跟踪脏页。</p>
<p>Every internal (non-leaf) page your findLeafPage() implementation visits should be fetched with READ_ONLY permission, except the returned leaf page, which should be fetched with the permission provided as an argument to the function. These permission levels will not matter for this lab, but they will be important for the code to function correctly in future labs.</p>
<p>你的findLeafPage()实现访问的每一个内部（非叶子）页面都应该以READ_ONLY权限获取，除了返回的叶子页面，它应该以作为函数参数提供的权限获取。这些权限级别对本实验来说并不重要，但它们对代码在未来实验中的正常运行非常重要。</p>
<h2 id="exercise-1-btreefilefindleafpage-1"><a class="header" href="#exercise-1-btreefilefindleafpage-1">Exercise 1: BTreeFile.findLeafPage()</a></h2>
<p>Implement BTreeFile.findLeafPage().</p>
<p>After completing this exercise, you should be able to pass all the unit tests in BTreeFileReadTest.java and the system tests in BTreeScanTest.java.</p>
<p>完成这个练习后，你应该能够通过BTreeFileReadTest.java中的所有单元测试和BTreeScanTest.java中的系统测试。</p>
<h2 id="3-insert"><a class="header" href="#3-insert">3. Insert</a></h2>
<p>In order to keep the tuples of the B+Tree in sorted order and maintain the integrity of the tree, we must insert tuples into the leaf page with the enclosing key range. As was mentioned above, findLeafPage() can be used to find the correct leaf page into which we should insert the tuple. However, each page has a limited number of slots and we need to be able to insert tuples even if the corresponding leaf page is full.</p>
<p>为了使B+Tree的 tuple 保持排序，并保持树的完整性，我们必须将 tuple 插入到具有包围键范围的叶页中。如上所述，findLeafPage()可以用来找到我们应该插入 tuple 的正确叶子页。然而，每个页面都有有限的槽位，我们需要能够插入 tuple ，即使相应的叶子页面已经满了。</p>
<p>As described in the textbook, attempting to insert a tuple into a full leaf page should cause that page to split so that the tuples are evenly distributed between the two new pages. Each time a leaf page splits, a new entry corresponding to the first tuple in the second page will need to be added to the parent node. Occasionally, the internal node may also be full and unable to accept new entries. In that case, the parent should split and add a new entry to its parent. This may cause recursive splits and ultimately the creation of a new root node.</p>
<p>正如教科书中所描述的，试图在一个完整的叶子页中插入一个tuple应该导致该页分裂，以便tuple均匀地分布在两个新页中。每次叶子页分裂时，需要向父节点添加一个与第二页中第一个tuple对应的新条目。偶尔，内部节点也可能是满的，无法接受新条目。在这种情况下，父节点应该拆分并向其父节点添加一个新条目。这可能会导致递归分裂，最终创建一个新的根节点。</p>
<p>In this exercise you will implement splitLeafPage() and splitInternalPage() in BTreeFile.java. If the page being split is the root page, you will need to create a new internal node to become the new root page, and update the BTreeRootPtrPage. Otherwise, you will need to fetch the parent page with READ_WRITE permissions, recursively split it if necessary, and add a new entry. You will find the function getParentWithEmptySlots() extremely useful for handling these different cases. In splitLeafPage() you should &quot;copy&quot; the key up to the parent page, while in splitInternalPage() you should &quot;push&quot; the key up to the parent page. See Figure 2 and review section 10.5 in the text book if this is confusing. Remember to update the parent pointers of the new pages as needed (for simplicity, we do not show parent pointers in the figures). When an internal node is split, you will need to update the parent pointers of all the children that were moved. You may find the function updateParentPointers() useful for this task. Additionally, remember to update the sibling pointers of any leaf pages that were split. Finally, return the page into which the new tuple or entry should be inserted, as indicated by the provided key field. (Hint: You do not need to worry about the fact that the provided key may actually fall in the exact center of the tuples/entries to be split. You should ignore the key during the split, and only use it to determine which of the two pages to return.)</p>
<p>在这个练习中，你将在 BTreeFile.java 中实现 splitLeafPage() 和 splitInternalPage() 。如果被分割的页面是根页面，你将需要创建一个新的内部节点来成为新的根页面，并更新BTreeRootPtrPage。否则，你将需要以READ_WRITE权限获取父页，必要时递归分割，并添加一个新条目。你会发现函数getParentWithEmptySlots()对于处理这些不同的情况非常有用。在splitLeafPage()中，你应该将键 &quot;复制 &quot;到父页上，而在splitInternalPage()中，你应该将键 &quot;推 &quot;到父页上。如果这一点令人困惑，请参见图2，并回顾教科书中的10.5节。记住要根据需要更新新页面的父指针（为了简单起见，我们不在图中显示父指针）。当一个内部节点被分割时，你将需要更新所有被移动的子节点的父指针。你可能会发现函数updateParentPointers()对这项任务很有用。此外，记得要更新任何被拆分的叶子页面的兄弟姐妹指针。最后，返回新的tuple或条目应该被插入的页面，如所提供的键字段所示。(提示：你不需要担心所提供的键实际上可能正好落在要分割的tuple/条目的中心。在分割过程中，你应该忽略这个键，而只是用它来决定返回两个页面中的哪一个）。</p>
<p><img src="6.830/cn/image/6-lab5/1644501314066.png" alt="" />
Figure 2: Splitting pages</p>
<p>Whenever you create a new page, either because of splitting a page or creating a new root page, call getEmptyPage() to get the new page. This function is an abstraction which will allow us to reuse pages that have been deleted due to merging (covered in the next section).</p>
<p>每当你创建一个新的页面，无论是因为拆分一个页面还是创建一个新的根页面，都要调用getEmptyPage()来获取新的页面。这个函数是一个抽象，它将允许我们重新使用因合并而被删除的页面（在下一节涉及）。</p>
<p>We expect that you will interact with leaf and internal pages using BTreeLeafPage.iterator() and BTreeInternalPage.iterator() to iterate through the tuples/entries in each page. For convenience, we have also provided reverse iterators for both types of pages: BTreeLeafPage.reverseIterator() and BTreeInternalPage.reverseIterator(). These reverse iterators will be especially useful for moving a subset of tuples/entries from a page to its right sibling.</p>
<p>我们希望你能使用BTreeLeafPage.iterator()和BTreeInternalPage.iterator()与叶子页和内部页进行交互，以迭代每个页面中的 tuple /条目。为了方便，我们还为这两种类型的页面提供了反向迭代器。BTreeLeafPage.reverseIterator（）和BTreeInternalPage.reverseIterator（）。这些反向迭代器对于将一个页面中的 tuple /条目子集移动到其右边的同级页面中特别有用。</p>
<p>As mentioned above, the internal page iterators use the interface defined in BTreeEntry.java, which has one key and two child pointers. It also has a recordId, which identifies the location of the key and child pointers on the underlying page. We think working with one entry at a time is a natural way to interact with internal pages, but it is important to keep in mind that the underlying page does not actually store a list of entries, but stores ordered lists of m keys and m+1 child pointers. Since the BTreeEntry is just an interface and not an object actually stored on the page, updating the fields of BTreeEntry will not modify the underlying page. In order to change the data on the page, you need to call BTreeInternalPage.updateEntry(). Furthermore, deleting an entry actually deletes only a key and a single child pointer, so we provide the funtions BTreeInternalPage.deleteKeyAndLeftChild() and BTreeInternalPage.deleteKeyAndRightChild() to make this explicit. The entry's recordId is used to find the key and child pointer to be deleted. Inserting an entry also only inserts a key and single child pointer (unless it's the first entry), so BTreeInternalPage.insertEntry() checks that one of the child pointers in the provided entry overlaps an existing child pointer on the page, and that inserting the entry at that location will keep the keys in sorted order.</p>
<p>如上所述，内部页面迭代器使用BTreeEntry.java中定义的接口，它有一个key和两个child pointers。它还有一个recordId，用于识别底层页面上键和子指针的位置。我们认为一次处理一个条目是与内部页面交互的自然方式，但重要的是要记住，底层页面实际上并不存储一个条目列表，而是存储m个键和m+1个子指针的有序列表。由于BTreeEntry只是一个接口，而不是实际存储在页面上的对象，更新BTreeEntry的字段不会修改底层页面。为了改变页面上的数据，你需要调用BTreeInternalPage.updateEntry（）。此外，删除一个条目实际上只删除了一个键和一个子指针，所以我们提供了BTreeInternalPage.deleteKeyAndLeftChild()和BTreeInternalPage.deleteKeyAndRightChild()的功能来明确这一点。该条目的recordId被用来寻找要删除的key和child指针。插入一个条目也只插入一个键和单个子指针（除非它是第一个条目），所以BTreeInternalPage.insertEntry()检查所提供的条目中的一个子指针是否与页面上现有的一个子指针重叠，在该位置插入条目将保持键的排序顺序。</p>
<p>In both splitLeafPage() and splitInternalPage(), you will need to update the set of dirtypages with any newly created pages as well as any pages modified due to new pointers or new data. This is where BTreeFile.getPage() will come in handy. Each time you fetch a page, BTreeFile.getPage() will check to see if the page is already stored in the local cache (dirtypages), and if it can't find the requested page there, it fetches it from the buffer pool. BTreeFile.getPage() also adds pages to the dirtypages cache if they are fetched with read-write permission, since presumably they will soon be dirtied. One advantage of this approach is that it prevents loss of updates if the same pages are accessed multiple times during a single tuple insertion or deletion.</p>
<p>在 splitLeafPage() 和 splitInternalPage() 中，你需要用任何新创建的页面以及由于新指针或新数据而修改的页面来更新 dirtypages 的集合。这就是BTreeFile.getPage()的用武之地。每次你获取一个页面时，BTreeFile.getPage()都会检查该页面是否已经存储在本地缓存（dirtypages）中，如果它在那里找不到所请求的页面，它就会从缓冲池中获取它。BTreeFile.getPage()还将页面添加到dirtypages缓存中，如果它们是以读写权限获取的，因为据推测它们很快就会被弄脏。这种方法的一个优点是，如果在一次tuple插入或删除过程中多次访问相同的页面，它可以防止更新的损失。</p>
<p>Note that in a major departure from HeapFile.insertTuple(), BTreeFile.insertTuple() could return a large set of dirty pages, especially if any internal pages are split. As you may remember from previous labs, the set of dirty pages is returned to prevent the buffer pool from evicting dirty pages before they have been flushed.</p>
<p>请注意，与 HeapFile.insertTuple() 大相径庭的是，BTreeFile.insertTuple() 可能会返回一大组脏页，特别是在任何内部页面被分割的情况下。你可能还记得以前的实验，返回脏页集是为了防止缓冲池在脏页被刷新之前驱逐它们。</p>
<p>Warning: as the B+Tree is a complex data structure, it is helpful to understand the properties necessary of every legal B+Tree before modifying it. Here is an informal list:</p>
<p>警告：由于B+Tree是一个复杂的数据结构，在修改它之前，了解每个合法B+Tree的必要属性是很有帮助的。这里是一个非正式的列表。</p>
<p>If a parent node points to a child node, the child nodes must point back to those same parents.</p>
<p>如果一个父节点指向一个子节点，子节点必须指向那些相同的父节点。</p>
<p>If a leaf node points to a right sibling, then the right sibling points back to that leaf node as a left sibling.</p>
<p>如果一个叶子节点指向一个右边的兄弟姐妹，那么右边的兄弟姐妹就会作为左边的兄弟姐妹指向该叶子节点。</p>
<p>The first and last leaves must point to null left and right siblings respectively.
Record Id's must match the page they are actually in.
A key in a node with non-leaf children must be larger than any key in the left child, and smaller than any key in the right child.
A key in a node with leaf children must be larger or equal than any key in the left child, and smaller or equal than any key in the right child.
A node has either all non-leaf children, or all leaf children.
A non-root node cannot be less than half full.
We have implemented a mechanized check for all these properties in the file BTreeChecker.java. This method is also used to test your B+Tree implementation in the systemtest/BTreeFileDeleteTest.java. Feel free to add calls to this function to help debug your implementation, like we did in BTreeFileDeleteTest.java.</p>
<p>第一个和最后一个叶子必须分别指向空的左边和右边的兄弟姐妹。
记录的Id必须与它们实际所在的页面相匹配。
有非叶子的节点中的一个键必须大于左侧子节点中的任何键，并且小于右侧子节点中的任何键。
一个有叶子的节点中的键必须大于或等于左边子节点中的任何键，并且小于或等于右边子节点中的任何键。
一个节点要么有所有非叶子的孩子，要么有所有叶子的孩子。
一个非根节点不能少于一半。
我们已经在BTreeChecker.java文件中实现了对所有这些属性的机械化检查。在systemtest/BTreeFileDeleteTest.java中，这个方法也被用来测试你的B+Tree实现。请随意添加对该函数的调用，以帮助调试你的实现，就像我们在BTreeFileDeleteTest.java中做的那样。</p>
<p>N.B.</p>
<p>The checker method should always pass after initialization of the tree and before starting and after completing a full call to key insertion or deletion, but not necessarily within internal methods.</p>
<p>检查器方法应该总是在树的初始化之后，在开始和完成对键插入或删除的完整调用之前传递，但不一定在内部方法中传递。</p>
<p>A tree may be well formed (and therefore pass checkRep()) but still incorrect. For example, the empty tree will always pass checkRep(), but may not always be correct (if you just inserted a tuple, the tree should not be empty). ***</p>
<p>一个树可能形成得很好（因此通过了checkRep()），但是仍然不正确。例如，空的树总是能通过checkRep()，但不一定总是正确的（如果你刚刚插入了一个tuple，树不应该是空的）。***</p>
<h2 id="exercise-2-splitting-pages-1"><a class="header" href="#exercise-2-splitting-pages-1">Exercise 2: Splitting Pages</a></h2>
<p>Implement BTreeFile.splitLeafPage() and BTreeFile.splitInternalPage().</p>
<p>After completing this exercise, you should be able to pass the unit tests in BTreeFileInsertTest.java. You should also be able to pass the system tests in systemtest/BTreeFileInsertTest.java. Some of the system test cases may take a few seconds to complete. These files will test that your code inserts tuples and splits pages correcty, and also handles duplicate tuples.</p>
<p>完成这个练习后，你应该能够通过BTreeFileInsertTest.java中的单元测试。你也应该能够通过 systemtest/BTreeFileInsertTest.java 中的系统测试。一些系统测试案例可能需要几秒钟的时间来完成。这些文件将测试你的代码是否正确地插入 tuple 和分割页面，并处理重复的 tuple 。</p>
<h2 id="4-delete"><a class="header" href="#4-delete">4. Delete</a></h2>
<p>In order to keep the tree balanced and not waste unnecessary space, deletions in a B+Tree may cause pages to redistribute tuples (Figure 3) or, eventually, to merge (see Figure 4). You may find it useful to review section 10.6 in the textbook.</p>
<p>为了保持树的平衡，不浪费不必要的空间，B+树中的删除可能会导致页面重新分配 tuple （图3）或最终合并（见图4）。你可能会发现复习一下教科书中的第10.6节是很有用的。</p>
<p><img src="6.830/cn/image/6-lab5/1644564797612.png" alt="" />
Figure 3: Redistributing pages</p>
<p><img src="6.830/cn/image/6-lab5/1644564966538.png" alt="" />
Figure 4: Merging pages</p>
<p>As described in the textbook, attempting to delete a tuple from a leaf page that is less than half full should cause that page to either steal tuples from one of its siblings or merge with one of its siblings. If one of the page's siblings has tuples to spare, the tuples should be evenly distributed between the two pages, and the parent's entry should be updated accordingly (see Figure 3). However, if the sibling is also at minimum occupancy, then the two pages should merge and the entry deleted from the parent (Figure 4). In turn, deleting an entry from the parent may cause the parent to become less than half full. In this case, the parent should steal entries from its siblings or merge with a sibling. This may cause recursive merges or even deletion of the root node if the last entry is deleted from the root node.</p>
<p>正如教科书中所描述的那样，如果试图从一个不满一半的叶子页中删除一个 tuple ，应该会导致该页从它的一个兄弟姐妹那里偷取 tuple 或与它的一个兄弟姐妹合并。如果该页的一个兄弟姐妹有多余的 tuple ，这些 tuple 应该在两个页面之间平均分配，并且父页的条目应该相应地被更新（见图3）。然而，如果兄弟姐妹也处于最小的占用率，那么这两个页面就应该合并，并从父页面删除条目（图4）。反过来，从父本中删除一个条目可能会导致父本的入住率低于一半。在这种情况下，父本应该从其兄弟姐妹那里偷取条目，或者与兄弟姐妹合并。这可能会导致递归合并，甚至是删除根节点，如果最后一个条目从根节点上被删除。</p>
<p>In this exercise you will implement stealFromLeafPage(), stealFromLeftInternalPage(), stealFromRightInternalPage(), mergeLeafPages() and mergeInternalPages() in BTreeFile.java. In the first three functions you will implement code to evenly redistribute tuples/entries if the siblings have tuples/entries to spare. Remember to update the corresponding key field in the parent (look carefully at how this is done in Figure 3 - keys are effectively &quot;rotated&quot; through the parent). In stealFromLeftInternalPage()/stealFromRightInternalPage(), you will also need to update the parent pointers of the children that were moved. You should be able to reuse the function updateParentPointers() for this purpose.</p>
<p>在这个练习中，你将在BTreeFile.java中实现 stealFromLeafPage(), stealFromLeftInternalPage(), stealFromRightInternalPage(), mergeLeafPages() 和 mergeInternalPages() 。在前三个函数中，你将实现代码，在兄弟姐妹有 tuple /条目的情况下均匀地重新分配 tuple /条目。记住要更新父代中相应的键字段（仔细看看图3中是如何做到的--键字在父代中被有效地 &quot;旋转 &quot;了）。在stealFromLeftInternalPage()/stealFromRightInternalPage()中，你还需要更新被移动的子项的父项指针。你应该可以为这个目的重新使用函数 updateParentPointers()。</p>
<p>In mergeLeafPages() and mergeInternalPages() you will implement code to merge pages, effectively performing the inverse of splitLeafPage() and splitInternalPage(). You will find the function deleteParentEntry() extremely useful for handling all the different recursive cases. Be sure to call setEmptyPage() on deleted pages to make them available for reuse. As with the previous exercises, we recommend using BTreeFile.getPage() to encapsulate the process of fetching pages and keeping the list of dirty pages up to date.</p>
<p>在mergeLeafPages()和mergeInternalPages()中，你将实现合并页面的代码，有效地执行splitLeafPage()和splitInternalPage()的逆过程。你会发现函数deleteParentEntry()对于处理所有不同的递归情况非常有用。请确保在被删除的页面上调用setEmptyPage()，以使它们可以被重新使用。与之前的练习一样，我们建议使用BTreeFile.getPage()来封装获取页面的过程，并保持脏页面列表的更新。</p>
<h2 id="exercise-3-redistributing-pages-1"><a class="header" href="#exercise-3-redistributing-pages-1">Exercise 3: Redistributing pages</a></h2>
<p>Implement BTreeFile.stealFromLeafPage(), BTreeFile.stealFromLeftInternalPage(), BTreeFile.stealFromRightInternalPage().</p>
<p>After completing this exercise, you should be able to pass some of the unit tests in BTreeFileDeleteTest.java (such as testStealFromLeftLeafPage and testStealFromRightLeafPage). The system tests may take several seconds to complete since they create a large B+ tree in order to fully test the system.</p>
<p>完成这个练习后，你应该能够通过BTreeFileDeleteTest.java中的一些单元测试（如testStealFromLeftLeafPage和testStealFromRightLeafPage）。系统测试可能需要几秒钟才能完成，因为它们会创建一个大的B+树，以便全面测试系统。</p>
<p>Exercise 4: Merging pages</p>
<p>Implement BTreeFile.mergeLeafPages() and BTreeFile.mergeInternalPages().</p>
<p>实现BTreeFile.mergeLeafPages()和BTreeFile.mergeInternalPages()。</p>
<p>Now you should be able to pass all unit tests in BTreeFileDeleteTest.java and the system tests in systemtest/BTreeFileDeleteTest.java.</p>
<p>现在你应该能够通过BTreeFileDeleteTest.java中的所有单元测试和systemtest/BTreeFileDeleteTest.java中的系统测试。</p>
<h2 id="5-transactions"><a class="header" href="#5-transactions">5. Transactions</a></h2>
<p>You may remember that B+ trees can prevent phantom tuples from showing up between two consecutive range scans by using next-key locking. Since SimpleDB uses page-level, strict two-phase locking, protection against phantoms effectively comes for free if the B+ tree is implemented correctly. Thus, at this point you should also be able to pass BTreeNextKeyLockingTest.</p>
<p>你可能还记得，B+树可以通过使用下一个键锁定来防止幻影 tuple 在两个连续的范围扫描之间出现。由于SimpleDB使用了页级的、严格的两阶段锁定，如果B+树被正确实现，对幻影的保护实际上是免费的。因此，在这一点上，你也应该能够通过BTreeNextKeyLockingTest。</p>
<p>Additionally, you should be able to pass the tests in test/simpledb/BTreeDeadlockTest.java if you have implemented locking correctly inside of your B+ tree code.</p>
<p>此外，如果你在B+树代码中正确实现了锁定，你应该能够通过test/simpledb/BTreeDeadlockTest.java的测试。</p>
<p>If everything is implemented correctly, you should also be able to pass the BTreeTest system test. We expect many people to find BTreeTest difficult, so it's not required, but we'll give extra credit to anyone who can run it successfully. Please note that this test may take up to a minute to complete.</p>
<p>如果一切实施正确，你也应该能够通过BTreeTest系统测试。我们预计很多人会觉得BTreeTest很难，所以它不是必须的，但我们会给能够成功运行它的人加分。请注意，这个测试可能需要一分钟的时间来完成。</p>
<h2 id="6-extra-credit"><a class="header" href="#6-extra-credit">6. Extra Credit</a></h2>
<p>Bonus Exercise 5: (10% extra credit)</p>
<p>Create and implement a class called BTreeReverseScan which scans the BTreeFile in reverse, given an optional IndexPredicate.</p>
<p>创建并实现一个名为BTreeReverseScan的类，该类在给定一个可选的IndexPredicate后，反向扫描BTreeFile。</p>
<p>You can use BTreeScan as a starting point, but you will probably need to implement a reverse iterator in BTreeFile. You will also likely need to implement a separate version of BTreeFile.findLeafPage(). We have provided reverse iterators on BTreeLeafPage and BTreeInternalPage which you may find useful. You should also write code to test that your implementation works correctly. BTreeScanTest.java is a good place to look for ideas.</p>
<p>你可以使用BTreeScan作为起点，但你可能需要在BTreeFile中实现一个反向迭代器。你也可能需要实现一个单独的BTreeFile.findLeafPage()版本。我们已经在BTreeLeafPage和BTreeInternalPage上提供了反向迭代器，你可能会发现它很有用。你还应该编写代码来测试你的实现是否正常工作。BTreeScanTest.java是一个寻找思路的好地方。</p>
<h2 id="7-logistics"><a class="header" href="#7-logistics">7. Logistics</a></h2>
<p>You must submit your code (see below) as well as a short (1 page, maximum) writeup describing your approach. This writeup should:</p>
<p>你必须提交你的代码（见下文），以及描述你的方法的简短（最多1页）的文章。这篇报告应该</p>
<p>Describe any design decisions you made, including anything that was difficult or unexpected.</p>
<p>描述你所做的任何设计决定，包括任何困难或意外。</p>
<p>Discuss and justify any changes you made outside of BTreeFile.java.</p>
<p>讨论并论证你在BTreeFile.java之外所做的任何改动。</p>
<p>How long did this lab take you? Do you have any suggestions for ways to improve it?</p>
<p>这个实验花了你多长时间？你有什么建议可以改进它吗？</p>
<p>Optional: If you did the extra credit exercise, explain your implementation and show us that you thoroughly tested it.</p>
<p>可选：如果你做了加分练习，请解释你的实现，并向我们展示你彻底测试了它。</p>
<h2 id="71-collaboration"><a class="header" href="#71-collaboration">7.1. Collaboration</a></h2>
<p>This lab should be manageable for a single person, but if you prefer to work with a partner, this is also OK. Larger groups are not allowed. Please indicate clearly who you worked with, if anyone, on your writeup.</p>
<p>这个实验对一个人来说应该是可以应付的，但如果你喜欢和一个伙伴一起工作，这也是可以的。不允许有较大的团体。如果有的话，请在你的报告中明确指出你和谁一起工作。</p>
<h2 id="72-submitting-your-assignment"><a class="header" href="#72-submitting-your-assignment">7.2. Submitting your assignment</a></h2>
<p>We will be using gradescope to autograde all programming assignments. You should have all been invited to the class instance; if not, please let us know and we can help you set up. You may submit your code multiple times before the deadline; we will use the latest version as determined by gradescope. Place the write-up in a file called lab3-writeup.txt with your submission. You also need to explicitly add any other files you create, such as new *.java files.</p>
<p>我们将使用gradescope对所有编程作业进行自动评分。你们应该都被邀请到班级实例中；如果没有，请告诉我们，我们可以帮助你们设置。你可以在截止日期前多次提交你的代码；我们将使用由gradescope确定的最新版本。把写好的东西放在一个叫lab3-writeup.txt的文件里，和你的提交一起。你还需要明确地添加你创建的任何其他文件，如新的*.java文件。</p>
<p>The easiest way to submit to gradescope is with .zip files containing your code. On Linux/MacOS, you can do so by running the following command:</p>
<p>向 gradescope 提交的最简单方法是使用包含你的代码的 .zip 文件。在Linux/MacOS上，你可以通过运行以下命令来实现。</p>
<pre><code>$ zip -r submission.zip src/ lab5-writeup.txt
</code></pre>
<h2 id="73-submitting-a-bug"><a class="header" href="#73-submitting-a-bug">7.3. Submitting a bug</a></h2>
<p>SimpleDB is a relatively complex piece of code. It is very possible you are going to find bugs, inconsistencies, and bad, outdated, or incorrect documentation, etc.</p>
<p>SimpleDB是一个相对复杂的代码。你很可能会发现错误、不一致，以及糟糕的、过时的或不正确的文档等等。</p>
<p>We ask you, therefore, to do this lab with an adventurous mindset. Don't get mad if something is not clear, or even wrong; rather, try to figure it out yourself or send us a friendly email.</p>
<p>因此，我们要求你以一种冒险的心态来做这个实验。如果有不清楚的地方，甚至是错误的地方，不要生气；而是要自己尝试去弄清楚，或者给我们发一封友好的电子邮件。</p>
<p>Please submit (friendly!) bug reports to 6.830-staff@mit.edu. When you do, please try to include:</p>
<p>A description of the bug.
A .java file we can drop in the test/simpledb directory, compile, and run.
A .txt file with the data that reproduces the bug. We should be able to convert it to a .dat file using HeapFileEncoder.
You can also post on the class page on Piazza if you feel you have run into a bug.</p>
<p>请提交（友好的！）错误报告到6.830-staff@mit.edu。当你这样做时，请尽量包括。</p>
<p>对该错误的描述。
一个我们可以放在test/simpledb目录下的.java文件，并进行编译和运行。
一个包含再现该错误的数据的.txt文件。我们应该能够用HeapFileEncoder将其转换为.dat文件。
如果你觉得你遇到了一个bug，你也可以在Piazza的类页面上发帖。</p>
<h2 id="74-grading"><a class="header" href="#74-grading">7.4 Grading</a></h2>
<p>75% of your grade will be based on whether or not your code passes the system test suite we will run over it. These tests will be a superset of the tests we have provided. Before handing in your code, you should make sure it produces no errors (passes all of the tests) from both ant test and ant systemtest.</p>
<p>Important: before testing, gradescope will replace your build.xml, HeapFileEncoder.java and the entire contents of the test directory with our version of these files. This means you cannot change the format of .dat files! You should also be careful changing our APIs. You should test that your code compiles the unmodified tests.</p>
<p>You should get immediate feedback and error outputs for failed tests (if any) from gradescope after submission. The score given will be your grade for the autograded portion of the assignment. An additional 25% of your grade will be based on the quality of your writeup and our subjective evaluation of your code. This part will also be published on gradescope after we finish grading your assignment.</p>
<p>We had a lot of fun designing this assignment, and we hope you enjoy hacking on it!</p>
<p>你的成绩的75%将基于你的代码是否通过我们将对其进行的系统测试套件。这些测试将是我们提供的测试的一个超集。在交出你的代码之前，你应该确保它在ant test和ant systemtest中没有产生错误（通过所有的测试）。</p>
<p>重要的是：在测试之前，gradescope 会用我们的版本替换你的 build.xml、HeapFileEncoder.java 以及测试目录中的全部内容。这意味着你不能改变.dat文件的格式! 你也应该小心改变我们的API。你应该测试你的代码是否编译了未修改的测试。</p>
<p>在提交后，你应该从 gradescope 得到即时反馈和失败测试的错误输出（如果有的话）。给出的分数将是你在作业的自动评分部分的成绩。另外25%的分数将基于你的写作质量和我们对你代码的主观评价。在我们给你的作业评分后，这部分也将在 gradescope 上公布。</p>
<p>我们在设计这项作业时非常有趣，我们希望你能享受到黑客的乐趣!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-6-翻译"><a class="header" href="#lab-6-翻译">Lab 6 翻译</a></h1>
<p>Assigned: Monday, May 3, 2021
Due: Wednesday, May 19, 2021 11:59 PM EST</p>
<h2 id="0-introduction-1"><a class="header" href="#0-introduction-1">0. Introduction</a></h2>
<p>In this lab you will implement log-based rollback for aborts and log-based crash recovery. We supply you with the code that defines the log format and appends records to a log file at appropriate times during transactions. You will implement rollback and recovery using the contents of the log file.</p>
<p>在这个实验中，你将实现基于日志的中止回滚和基于日志的崩溃恢复。我们为你提供了定义日志格式的代码，并在交易过程中的适当时候将记录附加到日志文件中。你将使用日志文件的内容实现回滚和恢复。</p>
<p>The logging code we provide generates records intended for physical whole-page undo and redo. When a page is first read in, our code remembers the original content of the page as a before-image. When a transaction updates a page, the corresponding log record contains that remembered before-image as well as the content of the page after modification as an after-image. You'll use the before-image to roll back during aborts and to undo loser transactions during recovery, and the after-image to redo winners during recovery.</p>
<p>我们提供的日志代码产生的记录旨在用于物理的整页撤销和重做。当一个页面第一次被读入时，我们的代码会记住该页面的原始内容，作为一个之前的图像。当一个事务更新一个页面时，相应的日志记录包含记忆中的before-image以及修改后的页面内容作为after-image。你将使用before-image在中止过程中回滚，并在恢复过程中撤销失败的事务，而after-image则在恢复过程中重做胜利者。</p>
<p>We are able to get away with doing whole-page physical UNDO (while ARIES must do logical UNDO) because we are doing page level locking and because we have no indices which may have a different structure at UNDO time than when the log was initially written. The reason page-level locking simplifies things is that if a transaction modified a page, it must have had an exclusive lock on it, which means no other transaction was concurrently modifying it, so we can UNDO changes to it by just overwriting the whole page.</p>
<p>我们能够摆脱做整个页面的物理UNDO（而ARIES必须做逻辑UNDO），因为我们做的是页级锁，而且我们没有索引，在UNDO时的结构可能与最初写日志时不同。页级锁简化了事情的原因是，如果一个事务修改了一个页面，它一定有一个独占锁，这意味着没有其他事务在同时修改它，所以我们可以通过覆盖整个页面来UNDO对它的修改。</p>
<p>Your BufferPool already implements abort by deleting dirty pages, and pretends to implement atomic commit by forcing dirty pages to disk only at commit time. Logging allows more flexible buffer management (STEAL and NO-FORCE), and our test code calls BufferPool.flushAllPages() at certain points in order to exercise that flexibility.</p>
<p>你的BufferPool已经通过删除脏页实现了中止，并通过在提交时强制脏页到磁盘来假装实现原子提交。日志允许更灵活的缓冲区管理（STEAL和NO-FORCE），我们的测试代码在某些地方调用BufferPool.flushAllPages()，以行使这种灵活性。</p>
<h2 id="1-getting-started-5"><a class="header" href="#1-getting-started-5">1. Getting started</a></h2>
<p>You should begin with the code you submitted for Lab 5 (if you did not submit code for Lab 5, or your solution didn't work properly, contact us to discuss options.)</p>
<p>你应该从你为实验5提交的代码开始（如果你没有为实验5提交代码，或者你的解决方案没有正常工作，请与我们联系，讨论各种方案）。</p>
<p>You'll need to modify some of your existing source and add a few new files. Here's what to do:</p>
<p>你需要修改一些现有的源代码并添加一些新的文件。下面是要做的事情。</p>
<p>First change to your project directory (probably called simple-db-hw) and pull from the master GitHub repository:</p>
<p>首先切换到你的项目目录（可能叫simple-db-hw），并从GitHub主仓库拉取。</p>
<pre><code>$ cd simple-db-hw
$ git pull upstream master
</code></pre>
<p>Now make the following changes to your existing code:</p>
<p>现在对你现有的代码做如下修改。</p>
<p>Insert the following lines into BufferPool.flushPage() before your call to writePage(p), where p is a reference to the page being written:</p>
<p>在调用writePage(p)之前，在BufferPool.flushPage()中插入以下几行，其中p是对被写入页面的引用。</p>
<pre><code>// append an update record to the log, with 
// a before-image and after-image.
TransactionId dirtier = p.isDirty();
if (dirtier != null){
  Database.getLogFile().logWrite(dirtier, p.getBeforeImage(), p);
  Database.getLogFile().force();
}
</code></pre>
<p>This causes the logging system to write an update to the log.
We force the log to ensure the log record is on disk before the page is written to disk.</p>
<p>这将导致日志系统向日志写入更新。
我们强迫日志在页面被写入磁盘之前确保日志记录在磁盘上。</p>
<p>Your BufferPool.transactionComplete() calls flushPage() for each page that a committed transaction dirtied. For each such page, add a call to p.setBeforeImage() after you have flushed the page:</p>
<p>你的BufferPool.transactionComplete()为每一个被提交的事务搅乱的页面调用flushPage()。对于每一个这样的页面，在你刷新页面之后，添加一个对p.setBeforeImage()的调用。</p>
<pre><code>// use current page contents as the before-image
// for the next transaction that modifies this page.
p.setBeforeImage();
</code></pre>
<p>After an update is committed, a page's before-image needs to be updated so that later transactions that abort rollback to this committed version of the page. (Note: We can't just call setBeforeImage() in flushPage(), since flushPage() might be called even if a transaction isn't committing. Our test case actually does that! If you implemented transactionComplete() by calling flushPages() instead, you may need to pass an additional argument to flushPages() to tell it whether the flush is being done for a committing transaction or not. However, we strongly suggest
in this case you simply rewrite transactionComplete() to use flushPage().)
After you have made these changes, do a clean build (ant clean; ant from the command line, or a &quot;Clean&quot; from the &quot;Project&quot; menu in Eclipse.)</p>
<p>在一个更新被提交后，一个页面的before-image需要被更新，以便后来的事务中止时回滚到该页面的这个提交版本。(注意：我们不能在flushPage()中直接调用setBeforeImage()，因为即使事务没有提交，flushPage()也可能被调用。我们的测试案例实际上就是这样做的! 如果你通过调用flushPages()来实现transactionComplete()，你可能需要给flushPages()传递一个额外的参数，告诉它是否为一个正在提交的事务进行刷新。然而，我们强烈建议在这种情况下，我们强烈建议你简单地重写 transactionComplete() 以使用 flushPage()。 在你做了这些修改之后，做一个干净的构建（ant clean; ant from the command line, or a &quot;Clean&quot; from the &quot;Project&quot; menu in Eclipse.）</p>
<p>At this point your code should pass the first three sub-tests of the LogTest systemtest, and fail the rest:</p>
<p>在这一点上，你的代码应该通过LogTest系统测试的前三个子测试，而其余的则失败。</p>
<pre><code>% ant runsystest -Dtest=LogTest
...
[junit] Running simpledb.systemtest.LogTest
[junit] Testsuite: simpledb.systemtest.LogTest
[junit] Tests run: 10, Failures: 0, Errors: 7, Time elapsed: 0.42 sec
[junit] Tests run: 10, Failures: 0, Errors: 7, Time elapsed: 0.42 sec
[junit] 
[junit] Testcase: PatchTest took 0.057 sec
[junit] Testcase: TestFlushAll took 0.022 sec
[junit] Testcase: TestCommitCrash took 0.018 sec
[junit] Testcase: TestAbort took 0.03 sec
[junit]     Caused an ERROR
[junit] LogTest: tuple present but shouldn't be
...
</code></pre>
<p>If you don't see the above output from ant runsystest -Dtest=LogTest, something has gone wrong with pulling the new files, or the changes you made are somehow incompatible with your existing code. You should figure out and fix the problem before proceeding; ask us for help if necessary.</p>
<p>如果你在ant runsystest -Dtest=LogTest中没有看到上述输出，说明在拉取新文件时出了问题，或者你所做的修改与你现有的代码有某种不兼容。你应该在继续进行之前找出并解决这个问题；如果有必要，请向我们寻求帮助。</p>
<h2 id="2-rollback"><a class="header" href="#2-rollback">2. Rollback</a></h2>
<p>Read the comments in LogFile.java for a description of the log file format. You should see in LogFile.java a set of functions, such as logCommit(), that generate each kind of log record and append it to the log.</p>
<p>阅读LogFile.java中的注释，以了解对日志文件格式的描述。你应该在LogFile.java中看到一组函数，比如logCommit()，它们生成每一种日志记录并将其追加到日志中。</p>
<p>Your first job is to implement the rollback() function in LogFile.java. This function is called when a transaction aborts, before the transaction releases its locks. Its job is to un-do any changes the transaction may have made to the database.</p>
<p>你的第一项工作是实现LogFile.java中的rollback()函数。当一个事务中止时，在该事务释放其锁之前，这个函数被调用。它的工作是解除事务可能对数据库做出的任何改变。</p>
<p>Your rollback() should read the log file, find all update records associated with the aborting transaction, extract the before-image from each, and write the before-image to the table file. Use raf.seek() to move around in the log file, and raf.readInt() etc. to examine it. Use readPageData() to read each of the before- and after-images. You can use the map tidToFirstLogRecord (which maps from a transaction id to an offset in the heap file) to determine where to start reading the log file for a particular transaction. You will need to make sure that you discard any page from the buffer pool whose before-image you write back to the table file.</p>
<p>你的回滚()应该读取日志文件，找到所有与中止事务相关的更新记录，从每个记录中提取之前的图像，并将之前的图像写到表文件中。使用raf.seek()在日志文件中移动，使用raf.readInt()等来检查它。使用readPageData()来读取每张前后的图像。你可以使用map tidToFirstLogRecord（它从交易ID映射到堆文件中的偏移量）来确定从哪里开始读取特定交易的日志文件。你需要确保从缓冲池中丢弃任何你写回表文件的前图像的页面。</p>
<p>As you develop your code, you may find the Logfile.print() method useful for displaying the current contents of the log.</p>
<p>当你开发你的代码时，你可能会发现Logfile.print()方法对于显示日志的当前内容很有用。</p>
<h2 id="exercise-1-logfilerollback-1"><a class="header" href="#exercise-1-logfilerollback-1">Exercise 1: LogFile.rollback()</a></h2>
<p>Implement LogFile.rollback().</p>
<p>After completing this exercise, you should be able to pass the TestAbort and TestAbortCommitInterleaved sub-tests of the LogTest system test.</p>
<p>完成这个练习后，你应该能够通过LogTest系统测试的TestAbort和TestAbortCommitInterleaved子测试。</p>
<h2 id="3-recovery"><a class="header" href="#3-recovery">3. Recovery</a></h2>
<p>If the database crashes and then reboots, LogFile.recover() will be called before any new transactions start. Your implementation should:</p>
<p>如果数据库崩溃，然后重新启动，LogFile.recover()将在任何新事务开始之前被调用。你的实现应该。</p>
<p>Read the last checkpoint, if any.</p>
<p>读取最后一个检查点，如果有的话。</p>
<p>Scan forward from the checkpoint (or start of log file, if no checkpoint) to build the set of loser transactions. Re-do updates during this pass. You can safely start re-do at the checkpoint because LogFile.logCheckpoint() flushes all dirty buffers to disk.</p>
<p>从检查点（如果没有检查点，则从日志文件开始）向前扫描，以建立失败的事务集。在这个过程中进行重做更新。你可以安全地在检查点开始重做，因为LogFile.logCheckpoint()会将所有的脏缓冲区刷到磁盘上。</p>
<p>Un-do the updates of loser transactions.</p>
<p>取消对失败者交易的更新。</p>
<h2 id="exercise-2-logfilerecover-1"><a class="header" href="#exercise-2-logfilerecover-1">Exercise 2: LogFile.recover()</a></h2>
<p>Implement LogFile.recover().</p>
<p>After completing this exercise, you should be able to pass all of the LogTest system test.</p>
<p>完成这个练习后，你应该能够通过所有的LogTest系统测试。</p>
<h2 id="4-logistics"><a class="header" href="#4-logistics">4. Logistics</a></h2>
<p>You must submit your code (see below) as well as a short (1 page, maximum) writeup describing your approach. This writeup should:</p>
<p>你必须提交你的代码（见下文），以及描述你的方法的简短（最多1页）的文章。这篇报告应该</p>
<p>Describe any design decisions you made, including anything that was difficult or unexpected.</p>
<p>描述你所做的任何设计决定，包括任何困难或意外。</p>
<p>Discuss and justify any changes you made outside of LogFile.java.</p>
<p>讨论并论证你在LogFile.java之外所做的任何改动。</p>
<h2 id="41-collaboration"><a class="header" href="#41-collaboration">4.1. Collaboration</a></h2>
<p>This lab should be manageable for a single person, but if you prefer to work with a partner, this is also OK. Larger groups are not allowed. Please indicate clearly who you worked with, if anyone, on your writeup.</p>
<p>这个实验对一个人来说应该是可以应付的，但如果你喜欢和一个伙伴一起工作，这也是可以的。不允许有较大的团体。如果有的话，请在你的报告中明确指出你和谁一起工作。</p>
<h2 id="42-submitting-your-assignment"><a class="header" href="#42-submitting-your-assignment">4.2. Submitting your assignment</a></h2>
<p>We will be using gradescope to autograde all programming assignments. You should have all been invited to the class instance; if not, please let us know and we can help you set up. You may submit your code multiple times before the deadline; we will use the latest version as determined by gradescope. Place the write-up in a file called lab3-writeup.txt with your submission. You also need to explicitly add any other files you create, such as new *.java files.</p>
<p>我们将使用gradescope对所有编程作业进行自动评分。你们应该都被邀请到班级实例中；如果没有，请告诉我们，我们可以帮助你们设置。你可以在截止日期前多次提交你的代码；我们将使用由gradescope确定的最新版本。把写好的东西放在一个叫lab3-writeup.txt的文件里，和你的提交一起。你还需要明确地添加你创建的任何其他文件，如新的*.java文件。</p>
<p>The easiest way to submit to gradescope is with .zip files containing your code. On Linux/MacOS, you can do so by running the following command:</p>
<p>向 gradescope 提交的最简单方法是使用包含你的代码的 .zip 文件。在Linux/MacOS上，你可以通过运行以下命令来实现。</p>
<pre><code>$ zip -r submission.zip src/ lab6-writeup.txt
</code></pre>
<h2 id="43-submitting-a-bug"><a class="header" href="#43-submitting-a-bug">4.3. Submitting a bug</a></h2>
<p>SimpleDB is a relatively complex piece of code. It is very possible you are going to find bugs, inconsistencies, and bad, outdated, or incorrect documentation, etc.</p>
<p>SimpleDB是一个相对复杂的代码。你很可能会发现错误、不一致，以及糟糕的、过时的或不正确的文档等等。</p>
<p>We ask you, therefore, to do this lab with an adventurous mindset. Don't get mad if something is not clear, or even wrong; rather, try to figure it out yourself or send us a friendly email. Please submit (friendly!) bug reports to 6.830-staff@mit.edu. When you do, please try to include:</p>
<p>因此，我们要求你以一种冒险的心态来做这个实验。如果有不清楚的地方，甚至是错误的地方，不要生气；相反，可以自己试着去解决，或者给我们发一封友好的电子邮件。请提交（友好的！）错误报告到6.830-staff@mit.edu。当你这样做时，请尽量包括。</p>
<p>A description of the bug.</p>
<p>A .java file we can drop in the src/simpledb/test directory, compile, and run.</p>
<p>A .txt file with the data that reproduces the bug. We should be able to convert it to a .dat file using PageEncoder.</p>
<p>You can also post on the class page on Piazza if you feel you have run into a bug.</p>
<p>对该错误的描述。</p>
<p>一个.java文件，我们可以把它放到src/simpledb/test目录下，进行编译，然后运行。</p>
<p>一个包含再现该错误的数据的.txt文件。我们应该能够用PageEncoder将其转换为一个.dat文件。</p>
<p>如果你觉得你遇到了一个bug，你也可以在Piazza上的班级页面上发帖。</p>
<h2 id="44-grading"><a class="header" href="#44-grading">4.4 Grading</a></h2>
<p>75% of your grade will be based on whether or not your code passes the system test suite we will run over it. These tests will be a superset of the tests we have provided. Before handing in your code, you should make sure it produces no errors (passes all of the tests) from both ant test and ant systemtest.</p>
<p>你的成绩的75%将基于你的代码是否通过我们将对其进行的系统测试套件。这些测试将是我们提供的测试的一个超集。在交出你的代码之前，你应该确保它在ant test和ant systemtest中没有产生错误（通过所有的测试）。</p>
<p>Important: before testing, gradescope will replace your build.xml, HeapFileEncoder.java and the entire contents of the test directory with our version of these files. This means you cannot change the format of .dat files! You should also be careful changing our APIs. You should test that your code compiles the unmodified tests.</p>
<p>重要的是：在测试之前，gradescope 会用我们的版本替换你的 build.xml、HeapFileEncoder.java 以及测试目录中的全部内容。这意味着你不能改变.dat文件的格式! 你也应该小心改变我们的API。你应该测试你的代码是否编译了未修改的测试。</p>
<p>You should get immediate feedback and error outputs for failed tests (if any) from gradescope after submission. The score given will be your grade for the autograded portion of the assignment. An additional 25% of your grade will be based on the quality of your writeup and our subjective evaluation of your code. This part will also be published on gradescope after we finish grading your assignment.</p>
<p>在提交后，你应该从 gradescope 得到即时反馈和失败测试的错误输出（如果有的话）。给出的分数将是你在作业的自动评分部分的成绩。另外25%的分数将基于你的写作质量和我们对你代码的主观评价。在我们给你的作业评分后，这部分也将在 gradescope 上公布。</p>
<p>We had a lot of fun designing this assignment, and we hope you enjoy hacking on it!</p>
<p>我们在设计这项作业时非常有趣，我们希望你能享受到黑客的乐趣!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="6824-spring-2022"><a class="header" href="#6824-spring-2022">6.824 Spring 2022</a></h1>
<p>课程安排：<a href="https://pdos.csail.mit.edu/6.824/schedule.html">schedule</a></p>
<p>视频字幕中文翻译：https://shimo.im/docs/xwqvh3kGppJKvHvX/read</p>
<h1 id="lab"><a class="header" href="#lab">lab</a></h1>
<ol>
<li>第一次实验是一个简单的 MapReduce 实验。你们要根据你们在论文中读到的来实现你们版本的 MapReduce 。</li>
<li>第二个实验实现 Raft 算法，这是一个理论上通过复制来让系统容错的算法，具体是通过复制和出现故障时自动切换来实现。</li>
<li>第三个实验，你需要使用你的 Raft 算法实现来建立一个可以容错的 KV 服务。</li>
<li>第四个实验，你需要把你写的KV服务器分发到一系列的独立集群中，这样你会切分你的KV服务，并通过运行这些独立的副本集群进行加速。同时，你也要负责将不同的数据块在不同的服务器之间搬迁，并确保数据完整。这里我们通常称之为分片式KV服务。分片是指我们将数据在多个服务器上做了分区，来实现并行的加速。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220331220013.png" alt="20220331220013" /></p>
<h1 id="资源"><a class="header" href="#资源">资源</a></h1>
<ul>
<li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/">视频内容文字版中文翻译</a></li>
<li><a href="https://shimo.im/docs/xwqvh3kGppJKvHvX/read">6.824 视频公开翻译文档链接</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-1-mapreduce-翻译"><a class="header" href="#lab-1-mapreduce-翻译">Lab 1: MapReduce 翻译</a></h1>
<p>Due: Friday Feb 11 23:59ET (MIT Time)
Collaboration policy // Submit lab // Setup Go // Guidance // Piazza</p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>In this lab you'll build a MapReduce system. You'll implement a worker process that calls application Map and Reduce functions and handles reading and writing files, and a coordinator process that hands out tasks to workers and copes with failed workers. You'll be building something similar to the MapReduce paper. (Note: this lab uses &quot;coordinator&quot; instead of the paper's &quot;master&quot;.)</p>
<p>在这个实验中，您将构建一个MapReduce系统。您将实现一个调用应用程序Map和Reduce函数并处理读写文件的工作进程，以及一个将任务分配给工作人员并处理失败工作人员的协调进程。您将构建类似于MapReduce论文的东西。（注意：这个实验使用“协调者”而不是论文的“主人”。）</p>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting started</a></h2>
<p>You need to setup Go to do the labs.</p>
<p>你需要设置Go来做实验室。</p>
<p>Fetch the initial lab software with git (a version control system). To learn more about git, look at the Pro Git book or the git user's manual.</p>
<p>使用git（版本控制系统）获取初始实验室软件。要了解更多关于git的信息，请查看专业Git手册或git用户手册。</p>
<pre><code>$ git clone git://g.csail.mit.edu/6.824-golabs-2022 6.824
$ cd 6.824
$ ls
Makefile src
$
</code></pre>
<p>We supply you with a simple sequential mapreduce implementation in src/main/mrsequential.go. It runs the maps and reduces one at a time, in a single process. We also provide you with a couple of MapReduce applications: word-count in mrapps/wc.go, and a text indexer in mrapps/indexer.go. You can run word count sequentially as follows:</p>
<p>我们在src/main/mrsequential.go.中为您提供了一个简单的顺序mapReduce实现，它在单个进程中运行映射并一次减少一个。我们还为您提供了几个MapReduce应用程序：mrapps/wc.go中的字数计数和mrapps/indexer.go.中的文本索引器。您可以按以下顺序运行字数计数：</p>
<pre><code>$ cd ~/6.824
$ cd src/main
$ go build -race -buildmode=plugin ../mrapps/wc.go
$ rm mr-out*
$ go run -race mrsequential.go wc.so pg*.txt
$ more mr-out-0
A 509
ABOUT 2
ACT 8
...
...
</code></pre>
<p>(Note: the -race enables the Go race detector. We suggest you develop and test your 6.824 lab code with the race detector. When we grade your labs, we will not use the race detector. Nevertheless, if your code has races, there's a good chance it will fail when we test it even without the race detector.)
（注意：-races支持Go竞赛检测器。我们建议你用竞赛检测器开发和测试你的6.824实验室代码。当我们对你的实验室评分时，我们不会使用竞赛检测器。然而，如果你的代码有竞赛，即使没有竞赛检测器，当我们测试它时，它也很有可能失败。）</p>
<p>mrsequential.go leaves its output in the file mr-out-0. The input is from the text files named pg-xxx.txt.
mrsequential.go将其输出留在文件mr-out-0中。输入来自名为pg-xxx.txt.的文本文件</p>
<p>Feel free to borrow code from mrsequential.go. You should also have a look at mrapps/wc.go to see what MapReduce application code looks like.
请随意从mrsequential.go.借用代码。您还应该看看mrapps/wc.go，看看MapReduce应用程序代码是什么样子。</p>
<h2 id="your-job-moderatehard"><a class="header" href="#your-job-moderatehard">Your Job (moderate/hard)</a></h2>
<p>Your job is to implement a distributed MapReduce, consisting of two programs, the coordinator and the worker. There will be just one coordinator process, and one or more worker processes executing in parallel. In a real system the workers would run on a bunch of different machines, but for this lab you'll run them all on a single machine. The workers will talk to the coordinator via RPC. Each worker process will ask the coordinator for a task, read the task's input from one or more files, execute the task, and write the task's output to one or more files. The coordinator should notice if a worker hasn't completed its task in a reasonable amount of time (for this lab, use ten seconds), and give the same task to a different worker.
您的工作是实现一个分布式MapReduce，由两个程序组成，协调器和工作进程。只有一个协调器进程和一个或多个并行执行的工作进程。在一个真实的系统中，工作进程将在一堆不同的机器上运行，但是对于这个实验室，您将在一台机器上运行它们。工作进程将通过RPC与协调器对话。每个工作进程将向协调器询问任务，从一个或多个文件中读取任务的输入，执行任务，并将任务的输出写入一个或多个文件。协调人应该注意到一个工人是否在合理的时间内没有完成任务（对于这个实验室，用十秒钟），并把同样的任务交给另一个工人。</p>
<p>We have given you a little code to start you off. The &quot;main&quot; routines for the coordinator and worker are in main/mrcoordinator.go and main/mrworker.go; don't change these files. You should put your implementation in mr/coordinator.go, mr/worker.go, and mr/rpc.go.</p>
<p>我们已经给了你一个小代码来开始你。协调员和工作人员的“主要”例程在main/mrcoordinator.go和main/mrworker.go；不要改变这些文件。你应该把你的实现放在先生/coordinator.go、先生/worker.go和先生/rpc.go.</p>
<p>Here's how to run your code on the word-count MapReduce application. First, make sure the word-count plugin is freshly built:
以下是如何在字数MapReduce应用程序上运行代码。首先，确保字数插件是新构建的：</p>
<pre><code>$ go build -race -buildmode=plugin ../mrapps/wc.go
</code></pre>
<p>In the main directory, run the coordinator.
在主目录中，运行协调器。</p>
<pre><code>$ rm mr-out*
$rm mr-out*
$ go run -race mrcoordinator.go pg-*.txt
</code></pre>
<p>The pg-*.txt arguments to mrcoordinator.go are the input files; each file corresponds to one &quot;split&quot;, and is the input to one Map task. The -race flags runs go with its race detector.</p>
<p>mrcoordinator.go的pg-*. txt参数是输入文件；每个文件对应于一个“拆分”，是一个地图任务的输入。-种族标志运行与它的种族检测器一起运行。</p>
<p>In one or more other windows, run some workers:
在一个或多个其他窗口中，运行一些辅助角色：</p>
<pre><code>$ go run -race mrworker.go wc.so
</code></pre>
<p>When the workers and coordinator have finished, look at the output in mr-out-*. When you've completed the lab, the sorted union of the output files should match the sequential output, like this:
当工作人员和协调者完成后，查看mr-out-*中的输出。当您完成实验室时，输出文件的排序联合应该与顺序输出匹配，如下所示：</p>
<pre><code>$ cat mr-out-* | sort | more
A 509
ABOUT 2
ACT 8
...
...
</code></pre>
<p>We supply you with a test script in main/test-mr.sh. The tests check that the wc and indexer MapReduce applications produce the correct output when given the pg-xxx.txt files as input. The tests also check that your implementation runs the Map and Reduce tasks in parallel, and that your implementation recovers from workers that crash while running tasks.</p>
<p>我们在main/test-mr.sh.中为您提供了一个测试脚本。测试检查wc和索引器MapReduce应用程序在输入pg-xxx.txt文件时是否产生正确的输出。测试还检查您的实现是否并行运行地图和减少任务，以及您的实现是否从运行任务时崩溃的辅助角色中恢复。</p>
<p>If you run the test script now, it will hang because the coordinator never finishes:</p>
<p>如果您现在运行测试脚本，它将挂起，因为协调器永远不会完成：</p>
<pre><code>$ cd ~/6.824/src/main
$ bash test-mr.sh
*** Starting wc test.
</code></pre>
<p>You can change ret := false to true in the Done function in mr/coordinator.go so that the coordinator exits immediately. Then:</p>
<p>您可以在mr/coordinator.go中的Done函数中将ret：=false更改为true，以便协调器立即退出。然后：</p>
<pre><code>$ bash test-mr.sh
*** Starting wc test.
sort: No such file or directory
cmp: EOF on mr-wc-all
--- wc output is not the same as mr-correct-wc.txt
--- wc test: FAIL
$
</code></pre>
<p>The test script expects to see output in files named mr-out-X, one for each reduce task. The empty implementations of mr/coordinator.go and mr/worker.go don't produce those files (or do much of anything else), so the test fails.
测试脚本期望在名为mr-out-X的文件中看到输出，每个减少任务一个输出。mr/coordinator.go和mr/worker.go的空实现不生成这些文件（或做其他任何事情），因此测试失败。</p>
<p>When you've finished, the test script output should look like this:
完成后，测试脚本输出应该如下所示：</p>
<pre><code>$ bash test-mr.sh
*** Starting wc test.
--- wc test: PASS
*** Starting indexer test.
--- indexer test: PASS
*** Starting map parallelism test.
--- map parallelism test: PASS
*** Starting reduce parallelism test.
--- reduce parallelism test: PASS
*** Starting crash test.
--- crash test: PASS
*** PASSED ALL TESTS
$
</code></pre>
<p>You'll also see some errors from the Go RPC package that look like
您还将看到Go RPC包中的一些错误，看起来像</p>
<pre><code>2019/12/16 13:27:09 rpc.Register: method &quot;Done&quot; has 1 input parameters; needs exactly three
</code></pre>
<p>Ignore these messages; registering the coordinator as an RPC server checks if all its methods are suitable for RPCs (have 3 inputs); we know that Done is not called via RPC.
忽略这些消息；将协调器注册为RPC服务器检查其所有方法是否适合RPC（有3个输入）；我们知道Done不是通过RPC调用的。</p>
<h2 id="a-few-rules"><a class="header" href="#a-few-rules">A few rules:</a></h2>
<ul>
<li>The map phase should divide the intermediate keys into buckets for nReduce reduce tasks, where nReduce is the number of reduce tasks -- argument that main/mrcoordinator.go passes to MakeCoordinator(). So, each mapper needs to create nReduce intermediate files for consumption by the reduce tasks.</li>
</ul>
<p>映射阶段应该将nReduce减少任务的中间键分成桶，其中nReduce是减少任务的数量--主/mrcoordinator.go传递给Make协调员（）的参数。因此，每个映射器需要创建nReduce中间文件，供减少任务使用。</p>
<ul>
<li>The worker implementation should put the output of the X'th reduce task in the file mr-out-X.</li>
</ul>
<p>工作人员实现应该把第X个减少任务的输出放在mr-out-X文件中。</p>
<ul>
<li>A mr-out-X file should contain one line per Reduce function output. The line should be generated with the Go &quot;%v %v&quot; format, called with the key and value. Have a look in main/mrsequential.go for the line commented &quot;this is the correct format&quot;. The test script will fail if your implementation deviates too much from this format.</li>
</ul>
<p>mr-out-X文件应该包含每个Reduce函数输出的一行。该行应该用Go“%v%v”格式生成，用键和值调用。在main/mrsequential.go中查看注释为“这是正确的格式”的行。如果您的实现偏离这种格式太多，测试脚本将失败。</p>
<ul>
<li>You can modify mr/worker.go, mr/coordinator.go, and mr/rpc.go. You can temporarily modify other files for testing, but make sure your code works with the original versions; we'll test with the original versions.</li>
</ul>
<p>您可以修改mr/worker.go、mr/coordinator.go和mr/rpc.go.您可以临时修改其他文件进行测试，但请确保您的代码与原始版本一起工作；我们将使用原始版本进行测试。</p>
<ul>
<li>The worker should put intermediate Map output in files in the current directory, where your worker can later read them as input to Reduce tasks.</li>
</ul>
<p>辅助角色应该将中间映射输出放在当前目录中的文件中，您的辅助角色可以稍后将其作为减少任务的输入读取。</p>
<ul>
<li>main/mrcoordinator.go expects mr/coordinator.go to implement a Done() method that returns true when the MapReduce job is completely finished; at that point, mrcoordinator.go will exit.</li>
</ul>
<p>main/mrcoordinator.go期望mr/coordinator.go实现一个Done（）方法，该方法在MapReduce作业完全完成时返回true；此时，mrcoordinator.go将退出。</p>
<ul>
<li>When the job is completely finished, the worker processes should exit. A simple way to implement this is to use the return value from call(): if the worker fails to contact the coordinator, it can assume that the coordinator has exited because the job is done, and so the worker can terminate too. Depending on your design, you might also find it helpful to have a &quot;please exit&quot; pseudo-task that the coordinator can give to workers.</li>
</ul>
<p>当工作完全完成时，辅助进程应该退出。实现这一点的一个简单方法是使用call（）的返回值：如果辅助进程未能联系协调器，它可以假设协调器已经退出，因为工作已经完成，因此辅助进程也可以终止。根据您的设计，您可能会发现协调器可以给辅助进程一个“请退出”伪任务是有帮助的。</p>
<h2 id="hints"><a class="header" href="#hints">Hints</a></h2>
<ul>
<li>The Guidance page has some tips on developing and debugging.</li>
</ul>
<p>该指南页面提供了一些开发和调试提示。</p>
<ul>
<li>One way to get started is to modify mr/worker.go's Worker() to send an RPC to the coordinator asking for a task. Then modify the coordinator to respond with the file name of an as-yet-unstarted map task. Then modify the worker to read that file and call the application Map function, as in mrsequential.go.</li>
</ul>
<p>开始的一种方法是修改mr/worker.go's Worker（）以向请求任务的协调器发送RPC。然后修改协调器以用尚未启动的映射任务的文件名进行响应。然后修改工作器以读取该文件并调用应用程序Map函数，如mrsequential.go.</p>
<ul>
<li>The application Map and Reduce functions are loaded at run-time using the Go plugin package, from files whose names end in .so.</li>
</ul>
<p>应用程序Map和Reduce函数在运行时使用Go插件包从名称以. so结尾的文件中加载。</p>
<ul>
<li>If you change anything in the mr/ directory, you will probably have to re-build any MapReduce plugins you use, with something like go build -race -buildmode=plugin ../mrapps/wc.go</li>
</ul>
<p>如果您更改了mr/目录中的任何内容，您可能必须重新构建您使用的任何MapReduce插件，例如go build-race-BuildMode=plugin.../mrapps/wc.go</p>
<ul>
<li>This lab relies on the workers sharing a file system. That's straightforward when all workers run on the same machine, but would require a global filesystem like GFS if the workers ran on different machines.</li>
</ul>
<p>这个实验室依赖于工作人员共享一个文件系统。当所有工作人员在同一台机器上运行时，这很简单，但是如果工作人员在不同的机器上运行，就需要像GFS这样的全局文件系统。</p>
<ul>
<li>A reasonable naming convention for intermediate files is mr-X-Y, where X is the Map task number, and Y is the reduce task number.</li>
</ul>
<p>中间文件的合理命名约定是mr-X-Y，其中X是Map任务号，Y是减少任务号。</p>
<ul>
<li>The worker's map task code will need a way to store intermediate key/value pairs in files in a way that can be correctly read back during reduce tasks. One possibility is to use Go's encoding/json package. To write key/value pairs in JSON format to an open file:</li>
</ul>
<p>工作人员的映射任务代码将需要一种在文件中存储中间键/值对的方法，这种方法可以在减少任务期间正确地读回。一种可能性是使用Go的编码/json包。以JSON格式将键/值对写入打开的文件：</p>
<p>enc := json.NewEncoder(file)
for _, kv := ... {
err := enc.Encode(&amp;kv)</p>
<p>并读取这样的文件：dec：=json. NewDecoder（file）</p>
<p>dec := json.NewDecoder(file)
for {
var kv KeyValue
if err := dec.Decode(&amp;kv); err != nil {
break
}
kva = append(kva, kv)
}</p>
<ul>
<li>The map part of your worker can use the ihash(key) function (in worker.go) to pick the reduce task for a given key.</li>
</ul>
<p>您的辅助角色的map部分可以使用ihash（key）函数（worker.go）为给定的key选择减少任务。</p>
<ul>
<li>You can steal some code from mrsequential.go for reading Map input files, for sorting intermedate key/value pairs between the Map and Reduce, and for storing Reduce output in files.</li>
</ul>
<p>您可以从mrsequential.go中窃取一些代码，用于读取Map输入文件、对Map和Reduce之间的间隔键/值对进行排序以及将Reduce输出存储在文件中。</p>
<ul>
<li>The coordinator, as an RPC server, will be concurrent; don't forget to lock shared data.</li>
</ul>
<p>协调器作为RPC服务器将是并发的；不要忘记锁定共享数据。</p>
<ul>
<li>Use Go's race detector, with go build -race and go run -race. test-mr.sh by default runs the tests with the race detector.</li>
</ul>
<p>使用Go的竞赛检测器，包括go构建竞赛和go运行竞赛。默认情况下，test-mr.sh使用竞赛检测器运行测试。</p>
<ul>
<li>Workers will sometimes need to wait, e.g. reduces can't start until the last map has finished. One possibility is for workers to periodically ask the coordinator for work, sleeping with time.Sleep() between each request. Another possibility is for the relevant RPC handler in the coordinator to have a loop that waits, either with time.Sleep() or sync.Cond. Go runs the handler for each RPC in its own thread, so the fact that one handler is waiting won't prevent the coordinator from processing other RPCs.</li>
</ul>
<p>工作人员有时需要等待，例如，在最后一张地图完成之前，减少无法启动。一种可能性是工作人员定期向协调器询问工作，与时间一起睡觉。每个请求之间的睡眠（）。另一种可能性是协调器中相关的RPC处理程序有一个循环，随着时间的推移而等待。睡眠（）或同步。Cond。Go在自己的线程中运行每个RPC的处理程序，所以一个处理程序正在等待的事实不会阻止协调器处理其他RPC。</p>
<ul>
<li>The coordinator can't reliably distinguish between crashed workers, workers that are alive but have stalled for some reason, and workers that are executing but too slowly to be useful. The best you can do is have the coordinator wait for some amount of time, and then give up and re-issue the task to a different worker. For this lab, have the coordinator wait for ten seconds; after that the coordinator should assume the worker has died (of course, it might not have).</li>
</ul>
<p>协调者无法可靠地区分崩溃的工人、活着但由于某种原因停滞不前的工人和正在执行但执行速度太慢而不起作用的工人。你能做的最好的事情是让协调者等待一段时间，然后放弃并将任务重新分配给另一个工人。对于这个实验室，让协调者等待10秒钟；在那之后，协调者应该假设工人已经死了（当然，它可能没有死）。</p>
<ul>
<li>If you choose to implement Backup Tasks (Section 3.6), note that we test that your code doesn't schedule extraneous tasks when workers execute tasks without crashing. Backup tasks should only be scheduled after some relatively long period of time (e.g., 10s).</li>
</ul>
<p>如果您选择实现备份任务（第3.6节），请注意，我们测试了当工作者执行任务而不崩溃时，您的代码不会调度无关的任务。备份任务应该只在相对较长的时间（例如10秒）后进行调度。</p>
<ul>
<li>To test crash recovery, you can use the mrapps/crash.go application plugin. It randomly exits in the Map and Reduce functions.</li>
</ul>
<p>要测试崩溃恢复，您可以使用mrapps/crash.go应用程序插件。它在地图和减少功能中随机退出。</p>
<ul>
<li>To ensure that nobody observes partially written files in the presence of crashes, the MapReduce paper mentions the trick of using a temporary file and atomically renaming it once it is completely written. You can use ioutil.TempFile to create a temporary file and os.Rename to atomically rename it.</li>
</ul>
<p>为了确保没有人在崩溃的情况下观察到部分写入的文件，MapReduce论文提到了使用临时文件并在完全写入后自动重命名的技巧。您可以使用ioutil. TempFile来创建临时文件，也可以使用os. Rename来自动重命名它。</p>
<ul>
<li>test-mr.sh runs all its processes in the sub-directory mr-tmp, so if something goes wrong and you want to look at intermediate or output files, look there. You can temporarily modify test-mr.sh to exit after the failing test, so the script does not continue testing (and overwrite the output files).</li>
</ul>
<p>test-mr.sh在子目录mr-tmp中运行它的所有进程，所以如果出了问题，您想查看中间或输出文件，请查看那里。您可以暂时修改test-mr.sh以在测试失败后退出，这样脚本就不会继续测试（并覆盖输出文件）。</p>
<ul>
<li>test-mr-many.sh provides a bare-bones script for running test-mr.sh with a timeout (which is how we'll test your code). It takes as an argument the number of times to run the tests. You should not run several test-mr.sh instances in parallel because the coordinator will reuse the same socket, causing conflicts.</li>
</ul>
<p>test-mr-many.sh提供了一个简单的脚本来运行超时test-mr.sh（这就是我们测试代码的方式）。它以运行测试的次数为参数。您不应该并行运行多个test-mr.sh实例，因为协调器会重用同一个套接字，导致冲突。</p>
<ul>
<li>Go RPC sends only struct fields whose names start with capital letters. Sub-structures must also have capitalized field names.</li>
</ul>
<p>Go RPC只发送名称以大写字母开头的结构字段。子结构也必须有大写的字段名。</p>
<ul>
<li>When passing a pointer to a reply struct to the RPC system, the object that *reply points to should be zero-allocated. The code for RPC calls should always look like</li>
</ul>
<p>当将指向回复结构的指针传递给RPC系统时，*回复指向的对象应该是零分配的。RPC调用的代码应该总是这样</p>
<p>reply := SomeType{}
call(..., &amp;reply)</p>
<p>without setting any fields of reply before the call. If you don't follow this requirement, there will be a problem when you pre-initialize a reply field to the non-default value for that datatype, and the server on which the RPC executes sets that reply field to the default value; you will observe that the write doesnâ€™t appear to take effect, and that on the caller side, the non-default value remains.</p>
<p>如果您不遵循此要求，当您将回复字段预初始化为该数据类型的非默认值，并且RPC执行的服务器将该回复字段设置为默认值时，将出现问题；您将观察到写似乎™生效，并且在调用方，非默认值仍然存在。</p>
<h2 id="no-credit-challenge-exercises"><a class="header" href="#no-credit-challenge-exercises">No-credit challenge exercises</a></h2>
<p>Implement your own MapReduce application (see examples in mrapps/*), e.g., Distributed Grep (Section 2.3 of the MapReduce paper).
实现您自己的MapReduce应用程序（请参阅mrapps/*中的示例），例如，分布式Grep（MapReduce论文的第2.3节）。</p>
<p>Get your MapReduce coordinator and workers to run on separate machines, as they would in practice. You will need to set up your RPCs to communicate over TCP/IP instead of Unix sockets (see the commented out line in Coordinator.server()), and read/write files using a shared file system. For example, you can ssh into multiple Athena cluster machines at MIT, which use AFS to share files; or you could rent a couple AWS instances and use S3 for storage.
让您的MapReduce协调器和辅助角色在不同的机器上运行，就像他们在实践中一样。您需要将RPC设置为通过TCP/IP而不是Unix套接字进行通信（参见Coordinator.server（）中注释的输出行），并使用共享文件系统读取/写入文件。例如，您可以ssh到麻省理工学院的多个雅典娜集群机器中，这些机器使用AFS共享文件；或者您可以租用几个AWS实例，并使用S3进行存储。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-1-mapreduce-总结"><a class="header" href="#lab-1-mapreduce-总结">Lab 1: MapReduce 总结</a></h1>
<p>环境：WSL2 Ubuntu20.04 LTS </p>
<blockquote>
<p>前置信息：</p>
<ol>
<li>读一遍《MapReduce》论文。</li>
<li>看完 lec1 和 lec2 视频 （B站有中文翻译）</li>
<li>过一遍 https://go.dev/tour/welcome/1</li>
<li>阅读 lab1 </li>
<li>coordinator 就是 MapReduce 论文中的 master</li>
</ol>
</blockquote>
<blockquote>
<p>预计耗时：1h</p>
</blockquote>
<h1 id="go-环境配置"><a class="header" href="#go-环境配置">GO 环境配置</a></h1>
<p>阅读：https://pdos.csail.mit.edu/6.824/labs/go.html</p>
<p>第一个问题：</p>
<p>无法通过命令行下载：</p>
<p>直接访问：https://go.dev/dl/go1.17.6.linux-amd64.tar.gz 通过浏览器下载。</p>
<p>然后解压到指定位置 <code>sudo tar -C /usr/local -xzf go1.13.6.linux-amd64.tar.gz</code></p>
<p>将环境遍历 <code>/usr/local/go/bin</code> 添加到 PATH 中。</p>
<p>我用的是 zsh 所以将 <code>export PATH=$PATH:/usr/local/go/bin</code> 放到 .zshrc 中，然后 source 生效。接下来检查是否安装成功：</p>
<pre><code class="language-sh">$ go version
go version go1.17.6 linux/amd64
</code></pre>
<p>然后下载代码</p>
<pre><code class="language-sh">git clone git://g.csail.mit.edu/6.824-golabs-2022 6.824
</code></pre>
<p>接下来执行一个单机版词频统计的例子，首先进入目录，生成词频统计的插件(wc.so)：</p>
<pre><code>$ cd ~/6.824
$ cd src/main
$ go build -race -buildmode=plugin ../mrapps/wc.go
$ rm mr-out*
</code></pre>
<p>然后根据插件执行词频统计：</p>
<pre><code>$ go run -race mrsequential.go wc.so pg*.txt
</code></pre>
<p><code>pg-xxx.txt</code> 是输入文件。<code>mr-out-0</code> 是产生的输出文件，key 和 value 分别是单词和词频。</p>
<p>go build -reace 参数用于检测数据竞争状态。</p>
<p>-buildmode 则是设置了编译模式。</p>
<p>接下来跑另一个例子（当代码实现完成后就能跑通）</p>
<pre><code>$ rm mr-out*
</code></pre>
<p>首先启动 coordinator</p>
<pre><code>$ go run -race mrcoordinator.go pg-*.txt
</code></pre>
<p>在另一个窗口启动 mrworker 并塞入 wc.so 表示执行词频统计</p>
<pre><code>$ go run -race mrworker.go wc.so
</code></pre>
<p><code>src/main/mrsequential.go</code> 是一个单机单进程 MapReduce 的顺序实现，实验要求是实现一个单机多进程的 MapReduce ，可以参考这个文件。先读明白这个文件，其中代码后续是需要借鉴的。</p>
<p><code>mrapps/wc.go</code> 中提供了词频统计具体实现的 Map 和 Reduce 函数。</p>
<p><code>mrapps/indexer.go</code> 中是文本索引器具体实现的 Map 和 Reduce 函数。</p>
<p>接下来是实现一个分布式的 MapReduce，其中包含了一个 coordinator 和多个 worker 。在实际中 worker 是并行的，但在这个实验中都在一台机器上通过多进程来模拟并行。worker 通过 RPC 和 coordinator 进行通信。worker 进程向 coordinator 进程请求任务，从一个或多个文件中读取任务输入，执行并将其写入多个文件中。</p>
<p>如果一个 worker 在一段时间内（此 lab 中，这段时间是 10s）无法将这些任务执行完，那么 coordinator 将会把同样的任务发给别的 worker 。</p>
<p><code>mr/coordinator.go</code> <code>mr/worker.go</code> <code>mr/rpc.go</code> 三个是要实现的文件，其中已经提供了部分代码。</p>
<p>下面是运行单机多进程 MapReduce 的命令。首先重新构建 word-count MapReduce 应用程序：</p>
<p><code>pg-*.txt</code> 作为 <code>mrcoordinator.go</code> 的输入文件，每个文件对应于一个 &quot;split&quot;，是一个Map任务的输入。</p>
<h2 id="思考-1"><a class="header" href="#思考-1">思考</a></h2>
<ol>
<li>首先通过 mrcoordinator.go 创建 coordinator 。然后通过 mrworker.go 创建多个 worker 来实现并行处理。</li>
<li>接下来设计 Task 的数据结构：task 两种状态：等待或正在执行。以及区分 mr 。</li>
<li>然后是 Worker 如何申请一个到一个任务，也就是获取文件名称。这一点提供的研究 RPC 例子可以很容易的实现。
<ol>
<li>获取任务要区分当前状态，如果是 Map 就申请 map 任务，反之申请 reduce 任务。</li>
<li>coordinator 中维护了一个 map task 的数组，其中包含了待处理的文件名和一些任务状态的信息，例如 id ，启动时间，任务状态。</li>
<li>加锁，做一些状态信息的处理。然后返回一个 map 任务。reduce 同理。</li>
</ol>
</li>
<li>拿到任务之后开始执行，区分 map 和 reduce 。
<ol>
<li>执行 map 任务：读取文件内容经过 map 处理然后用 json 编码塞入 reduce 中。</li>
<li>处理 reduce 任务，读取生成的中间文件中的内容然后用 reducef 来处理。</li>
<li>Finish 遍历所有的 map 任务，处理已经 map 好的任务，然后判断是否所有的任务都已经被处理。如果都处理完了就转入 reduce 阶段。reduce 阶段同理，最后判断所有任务是否完成，然后 Done() 会最终终止整个流程。</li>
</ol>
</li>
<li>MakeCoordinator 主要是初始化 map 任务队列，将 filename 初始化为 map 任务。然后初始化 Reduce 任务队列。最后将状态改为 map 阶段等待 worker 来领任务。</li>
</ol>
<p>能通过 2020 版中的测试，但 wc 需要手动测试，而 2022 版的测试存在超时问题。</p>
<p><img src="https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220320232720.png" alt="20220320232720" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-2-raft-翻译"><a class="header" href="#lab-2-raft-翻译">Lab 2: Raft 翻译</a></h1>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>实现 Raft 协议并构建一个具备容错功能的 K/V 存储系统。</p>
<p>In this lab you'll implement Raft, a replicated state machine protocol. In the next lab you'll build a key/value service on top of Raft. Then you will “shard” your service over multiple replicated state machines for higher performance.</p>
<p>这是一系列实验室中的第一个，你将建立一个容错的键/值存储系统。在这个实验室中，你将实现Raft，一个复制的状态机协议。在下一个实验室中，你将在Raft的基础上建立一个键/值服务。然后你将在多个复制的状态机上 &quot;分片 &quot;你的服务，以获得更高的性能。</p>
<p>A replicated service achieves fault tolerance by storing complete copies of its state (i.e., data) on multiple replica servers. Replication allows the service to continue operating even if some of its servers experience failures (crashes or a broken or flaky network). The challenge is that failures may cause the replicas to hold differing copies of the data.</p>
<p>复制的服务通过在多个复制服务器上存储其状态（即数据）的完整副本来实现容错。复制允许服务继续运行，即使它的一些服务器出现故障（崩溃或网络故障或摇摆不定）。挑战在于，故障可能导致副本持有不同的数据副本。</p>
<p>Raft organizes client requests into a sequence, called the log, and ensures that all the replica servers see the same log. Each replica executes client requests in log order, applying them to its local copy of the service's state. Since all the live replicas see the same log contents, they all execute the same requests in the same order, and thus continue to have identical service state. If a server fails but later recovers, Raft takes care of bringing its log up to date. Raft will continue to operate as long as at least a majority of the servers are alive and can talk to each other. If there is no such majority, Raft will make no progress, but will pick up where it left off as soon as a majority can communicate again.</p>
<p>Raft将客户请求组织成一个序列，称为日志，并确保所有副本服务器看到相同的日志。每个副本按日志顺序执行客户请求，将它们应用于其本地的服务状态副本。由于所有的实时副本看到相同的日志内容，它们都以相同的顺序执行相同的请求，从而继续拥有相同的服务状态。如果一个服务器发生故障但后来恢复了，Raft会负责将其日志更新。只要至少有大多数的服务器还活着，并且能够相互交谈，Raft就会继续运行。如果没有这样的多数，Raft将不会取得任何进展，但一旦多数服务器能够再次通信，Raft将重新开始工作。</p>
<p>In this lab you'll implement Raft as a Go object type with associated methods, meant to be used as a module in a larger service. A set of Raft instances talk to each other with RPC to maintain replicated logs. Your Raft interface will support an indefinite sequence of numbered commands, also called log entries. The entries are numbered with index numbers. The log entry with a given index will eventually be committed. At that point, your Raft should send the log entry to the larger service for it to execute.</p>
<p>在这个实验室中，你将把Raft实现为一个带有相关方法的Go对象类型，旨在作为一个更大的服务中的模块使用。一组Raft实例通过RPC相互对话，以维护复制的日志。你的Raft接口将支持一连串不确定的编号命令，也称为日志条目。条目是用索引号来编号的。具有特定索引的日志条目最终将被提交。在这一点上，你的Raft应该将日志条目发送到更大的服务，让它执行。</p>
<p>You should follow the design in the <a href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf">extended Raft paper</a>, with particular attention to Figure 2. You'll implement most of what's in the paper, including saving persistent state and reading it after a node fails and then restarts. You will not implement cluster membership changes (Section 6).</p>
<p>你应该遵循<a href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf">扩展的Raft论文</a>中的设计，特别注意图2。你将实现论文中的大部分内容，包括保存持久性状态和在节点故障后重新启动后读取状态。你将不会实现集群成员的变化（第6节）。</p>
<p>You may find this <a href="https://thesquareplanet.com/blog/students-guide-to-raft/">guide</a> useful, as well as this advice about <a href="https://pdos.csail.mit.edu/6.824/labs/raft-locking.txt">locking</a> and <a href="https://pdos.csail.mit.edu/6.824/labs/raft-structure.txt">structure</a> for concurrency. For a wider perspective, have a look at Paxos, Chubby, Paxos Made Live, Spanner, Zookeeper, Harp, Viewstamped Replication, and <a href="http://static.usenix.org/event/nsdi11/tech/full_papers/Bolosky.pdf">Bolosky et al.</a> (Note: the student's guide was written several years ago, and part 2D in particular has since changed. Make sure you understand why a particular implementation strategy makes sense before blindly following it!)</p>
<p>你可能会发现这个<a href="https://thesquareplanet.com/blog/students-guide-to-raft/">指南</a>很有用，还有这个关于并发的锁和结构的建议。为了获得更广泛的视角，可以看看Paxos、Chubby、Paxos Made Live、Spanner、Zookeeper、Harp、Viewstamped Replication和Bolosky等（注意：学生指南是几年前写的，尤其是2D部分后来有了变化。请确保你在盲目追随某个特定的实施策略之前，了解它为什么有意义！)</p>
<p>Keep in mind that the most challenging part of this lab may not be implementing your solution, but debugging it. To help address this challenge, you may wish to spend time thinking about how to make your implementation more easily debuggable. You might refer to the <a href="https://pdos.csail.mit.edu/6.824/labs/guidance.html">Guidance</a> page and to this blog post about <a href="https://blog.josejg.com/debugging-pretty/">effective print statements</a>.</p>
<p>请记住，本实验中最具挑战性的部分可能不是实现你的解决方案，而是调试它。为了帮助应对这一挑战，你可能希望花时间考虑如何使你的实现更容易调试。你可以参考指导页和这篇关于有效打印语句的博文。</p>
<p>We also provide a <a href="https://pdos.csail.mit.edu/6.824/notes/raft_diagram.pdf">diagram of Raft interactions</a> that can help clarify how your Raft code interacts with the layers on top of it.</p>
<p>我们还提供了一个Raft互动图，可以帮助澄清你的Raft代码如何与上面的层互动。</p>
<p>This lab is due in four parts. You must submit each part on the corresponding due date.</p>
<p>本实验分四部分完成。你必须在相应的到期日提交每个部分。</p>
<h2 id="getting-started-入门"><a class="header" href="#getting-started-入门">Getting Started 入门</a></h2>
<p>If you have done Lab 1, you already have a copy of the lab source code. If not, you can find directions for obtaining the source via git in the Lab 1 instructions.</p>
<p>如果你做过实验1，你已经有一份实验源代码的副本。如果没有，你可以在实验1的说明中找到通过git获取源代码的方法。</p>
<p>We supply you with skeleton code src/raft/raft.go. We also supply a set of tests, which you should use to drive your implementation efforts, and which we'll use to grade your submitted lab. The tests are in src/raft/test_test.go.</p>
<p>我们为你提供了骨架代码 src/raft/raft.go。我们还提供了一套测试，你应该用它来推动你的实施工作，我们会用它来给你提交的实验室评分。这些测试在 src/raft/test_test.go 中。</p>
<p>When we grade your submissions, we will run the tests without the -race flag. However, you should make sure that your code does not have race conditions because race conditions can cause the tests to fail. So, it's highly recommended to also run the tests with the -race flag as you develop your solution.</p>
<p>当我们对你提交的文件进行评分时，我们将在没有-race标志的情况下运行测试。然而，你应该确保你的代码不存在竞赛条件，因为竞赛条件会导致测试失败。因此，强烈建议你在开发你的解决方案时，也用-race标志来运行测试。</p>
<p>To get up and running, execute the following commands. Don't forget the git pull to get the latest software.</p>
<p>要启动和运行，请执行以下命令。不要忘记使用git pull来获取最新的软件。</p>
<pre><code>$ cd ~/6.824
$ git pull
...
$ cd src/raft
$ go test
Test (2A): initial election ...
--- FAIL: TestInitialElection2A (5.04s)
        config.go:326: expected one leader, got none
Test (2A): election after network failure ...
--- FAIL: TestReElection2A (5.03s)
        config.go:326: expected one leader, got none
...
$
</code></pre>
<h2 id="the-code-准则"><a class="header" href="#the-code-准则">The code 准则</a></h2>
<p>Implement Raft by adding code to raft/raft.go. In that file you'll find skeleton code, plus examples of how to send and receive RPCs.</p>
<p>通过向raft/raft.go添加代码来实现Raft。在该文件中，你会发现骨架代码，以及如何发送和接收RPC的例子。</p>
<p>Your implementation must support the following interface, which the tester and (eventually) your key/value server will use. You'll find more details in comments in raft.go.</p>
<p>你的实现必须支持以下接口，测试者和（最终）你的键/值服务器将使用该接口。你可以在raft.go的注释中找到更多细节。</p>
<pre><code>// create a new Raft server instance:
// 创建一个新的Raft服务器实例。
rf := Make(peers, me, persister, applyCh)

// start agreement on a new log entry:
// 启动在一个新的日志条目的协议。
rf.Start(command interface{}) (index, term, isleader)

// ask a Raft for its current term, and whether it thinks it is leader
// 询问一个 Raft 的当前任期，以及它是否认为自己是领导者。
rf.GetState() (term, isLeader)

// each time a new entry is committed to the log, each Raft peer
// should send an ApplyMsg to the service (or tester).
// 每当一个新条目被提交到日志中时，每个 Raft 对等体
// 应该向服务（或测试者）发送一个ApplyMsg。
type ApplyMsg
</code></pre>
<p>A service calls Make(peers,me,…) to create a Raft peer. The peers argument is an array of network identifiers of the Raft peers (including this one), for use with RPC. The me argument is the index of this peer in the peers array. Start(command) asks Raft to start the processing to append the command to the replicated log. Start() should return immediately, without waiting for the log appends to complete. The service expects your implementation to send an ApplyMsg for each newly committed log entry to the applyCh channel argument to Make().</p>
<p>一个服务调用Make(peers,me,...)来创建一个Raft对等体。peers参数是一个Raft对等体（包括这个）的网络标识符数组，用于RPC。me参数是该对等体在对等体数组中的索引。Start(command)要求Raft开始处理，将该命令附加到复制的日志中。Start()应立即返回，而不需要等待日志追加完成。该服务希望你的实现为每个新提交的日志条目发送一个ApplyMsg到Make()的applyCh通道参数。</p>
<p>raft.go contains example code that sends an RPC (sendRequestVote()) and that handles an incoming RPC (RequestVote()). Your Raft peers should exchange RPCs using the labrpc Go package (source in src/labrpc). The tester can tell labrpc to delay RPCs, re-order them, and discard them to simulate various network failures. While you can temporarily modify labrpc, make sure your Raft works with the original labrpc, since that's what we'll use to test and grade your lab. Your Raft instances must interact only with RPC; for example, they are not allowed to communicate using shared Go variables or files.</p>
<p>raft.go包含发送RPC（sendRequestVote()）和处理传入RPC（RequestVote()）的示例代码。你的Raft对等体应该使用labrpc Go包（源代码在src/labrpc中）交换RPC。测试人员可以告诉labrpc延迟RPC，重新排序，并丢弃它们以模拟各种网络故障。虽然你可以临时修改labrpc，但要确保你的Raft与原始的labrpc一起工作，因为我们将用它来测试和评定你的实验室。你的Raft实例必须只与RPC互动；例如，它们不允许使用共享的Go变量或文件进行通信。</p>
<p>Subsequent labs build on this lab, so it is important to give yourself enough time to write solid code.</p>
<p>随后的实验是在这个实验的基础上进行的，所以给自己足够的时间来写出坚实的代码是很重要的。</p>
<h2 id="part-2a-leader-election-moderate"><a class="header" href="#part-2a-leader-election-moderate">Part 2A: leader election (moderate)</a></h2>
<p>Implement Raft leader election and heartbeats (AppendEntries RPCs with no log entries). The goal for Part 2A is for a single leader to be elected, for the leader to remain the leader if there are no failures, and for a new leader to take over if the old leader fails or if packets to/from the old leader are lost. Run go test -run 2A to test your 2A code.</p>
<p>实现Raft领导者选举和心跳（AppendEntries RPCs，没有日志条目）。第2A部分的目标是选出一个领导者，如果没有失败，该领导者将继续担任领导者，如果老领导者失败或与老领导者之间的数据包丢失，则由新领导者接管。运行go test -run 2A来测试你的2A代码。</p>
<ul>
<li>You can't easily run your Raft implementation directly; instead you should run it by way of the tester, i.e. go test -run 2A .</li>
</ul>
<p>你不能轻易地直接运行你的Raft实现；相反，你应该通过测试器来运行它，即go test -run 2A 。</p>
<ul>
<li>Follow the paper's Figure 2. At this point you care about sending and receiving RequestVote RPCs, the Rules for Servers that relate to elections, and the State related to leader election,</li>
</ul>
<p>按照论文中的图2。在这一点上，你关心的是发送和接收 RequestVote RPCs ，与选举有关的服务器规则，以及与领导选举有关的状态。</p>
<p>Add the Figure 2 state for leader election to the Raft struct in raft.go. You'll also need to define a struct to hold information about each log entry.</p>
<p>在raft.go中的Raft结构中添加图2中领导者选举的状态。你还需要定义一个结构来保存每个日志条目的信息。</p>
<p>Fill in the RequestVoteArgs and RequestVoteReply structs. Modify Make() to create a background goroutine that will kick off leader election periodically by sending out RequestVote RPCs when it hasn't heard from another peer for a while. This way a peer will learn who is the leader, if there is already a leader, or become the leader itself. Implement the RequestVote() RPC handler so that servers will vote for one another.</p>
<p>填入 RequestVoteArgs 和 RequestVoteReply 结构。修改Make()以创建一个后台goroutine，当它有一段时间没有收到另一个对等体的消息时，它将通过发送RequestVote RPCs定期启动领导者选举。这样，如果已经有了一个领导者，对等体将了解谁是领导者，或者自己成为领导者。实现RequestVote()RPC处理程序，这样服务器就可以互相投票了。</p>
<p>To implement heartbeats, define an AppendEntries RPC struct (though you may not need all the arguments yet), and have the leader send them out periodically. Write an AppendEntries RPC handler method that resets the election timeout so that other servers don't step forward as leaders when one has already been elected.</p>
<p>为了实现心跳，定义一个AppendEntries RPC结构（尽管你可能还不需要所有的参数），并让领导者定期发送它们。编写一个AppendEntries RPC处理方法，重设选举超时，这样当一个人已经当选时，其他服务器就不会站出来当领导者。</p>
<p>Make sure the election timeouts in different peers don't always fire at the same time, or else all peers will vote only for themselves and no one will become the leader.</p>
<p>确保不同对等体的选举超时不会总是在同一时间发生，否则所有对等体将只为自己投票，没有人会成为领导者。</p>
<p>The tester requires that the leader send heartbeat RPCs no more than ten times per second.</p>
<p>测试者要求领导者每秒发送心跳RPC的次数不超过10次。</p>
<p>The tester requires your Raft to elect a new leader within five seconds of the failure of the old leader (if a majority of peers can still communicate). Remember, however, that leader election may require multiple rounds in case of a split vote (which can happen if packets are lost or if candidates unluckily choose the same random backoff times). You must pick election timeouts (and thus heartbeat intervals) that are short enough that it's very likely that an election will complete in less than five seconds even if it requires multiple rounds.</p>
<p>测试员要求你的Raft在老领袖失败后的五秒钟内选出一个新的领袖（如果大多数对等体仍能通信）。然而，请记住，如果出现分裂投票，领袖选举可能需要多轮投票（如果数据包丢失或候选人不走运地选择相同的随机退避时间，就会发生这种情况）。你必须选择足够短的选举超时（以及心跳间隔），即使需要多轮选举，也很可能在5秒内完成。</p>
<p>The paper's Section 5.2 mentions election timeouts in the range of 150 to 300 milliseconds. Such a range only makes sense if the leader sends heartbeats considerably more often than once per 150 milliseconds. Because the tester limits you to 10 heartbeats per second, you will have to use an election timeout larger than the paper's 150 to 300 milliseconds, but not too large, because then you may fail to elect a leader within five seconds.</p>
<p>论文的第5.2节提到选举超时的范围是150到300毫秒。只有当领导者发送心跳的频率大大超过每150毫秒一次时，这样的范围才有意义。因为测试者把你限制在每秒10次心跳，所以你必须使用比文件中的150到300毫秒更大的选举超时，但不能太大，因为那样你可能无法在5秒内选出一个领导者。</p>
<p>You may find Go's rand useful.</p>
<p>你可能会发现Go的rand很有用。</p>
<p>You'll need to write code that takes actions periodically or after delays in time. The easiest way to do this is to create a goroutine with a loop that calls time.Sleep(); (see the ticker() goroutine that Make() creates for this purpose). Don't use Go's time.Timer or time.Ticker, which are difficult to use correctly.</p>
<p>你需要编写代码，定期或在时间延迟后采取行动。最简单的方法是创建一个带有循环的goroutine，调用time.Sleep();（参见Make()为此目的而创建的ticker()goroutine）。不要使用Go的time.Timer或time.Ticker，它们很难正确使用。</p>
<p>The <a href="https://pdos.csail.mit.edu/6.824/labs/guidance.html">Guidance page</a> has some tips on how to develop and debug your code.</p>
<p>指导页有一些关于如何开发和调试你的代码的提示。</p>
<p>If your code has trouble passing the tests, read the paper's Figure 2 again; the full logic for leader election is spread over multiple parts of the figure.</p>
<p>如果你的代码难以通过测试，请再次阅读该论文的图2；领导人选举的全部逻辑分布在图中的多个部分。</p>
<p>Don't forget to implement GetState().</p>
<p>不要忘记实现GetState()。</p>
<p>The tester calls your Raft's rf.Kill() when it is permanently shutting down an instance. You can check whether Kill() has been called using rf.killed(). You may want to do this in all loops, to avoid having dead Raft instances print confusing messages.</p>
<p>测试员在永久关闭一个实例时，会调用你的Raft的rf.Kill()。您可以使用rf.killed()检查Kill()是否被调用。您可能希望在所有的循环中都这样做，以避免死亡的Raft实例打印混乱的信息。</p>
<p>Go RPC sends only struct fields whose names start with capital letters. Sub-structures must also have capitalized field names (e.g. fields of log records in an array). The labgob package will warn you about this; don't ignore the warnings.</p>
<p>Go RPC只发送名称以大写字母开头的结构字段。子结构也必须有大写的字段名（例如，数组中的日志记录字段）。labgob包会对此发出警告；不要忽视这些警告。</p>
<p>Be sure you pass the 2A tests before submitting Part 2A, so that you see something like this:</p>
<p>在提交第2A部分之前，请确保你通过了2A测试，这样你就会看到这样的内容。</p>
<pre><code>$ go test -run 2A
Test (2A): initial election ...
... Passed --   3.5  3   58   16840    0
Test (2A): election after network failure ...
... Passed --   5.4  3  118   25269    0
Test (2A): multiple elections ...
... Passed --   7.3  7  624  138014    0
PASS
ok  	6.824/raft	16.265s
$
</code></pre>
<p>Each &quot;Passed&quot; line contains five numbers; these are the time that the test took in seconds, the number of Raft peers, the number of RPCs sent during the test, the total number of bytes in the RPC messages, and the number of log entries that Raft reports were committed. Your numbers will differ from those shown here. You can ignore the numbers if you like, but they may help you sanity-check the number of RPCs that your implementation sends. For all of labs 2, 3, and 4, the grading script will fail your solution if it takes more than 600 seconds for all of the tests (go test), or if any individual test takes more than 120 seconds.</p>
<p>每一行 &quot;通过 &quot;包含五个数字；它们是测试所花的时间（秒）、Raft对等体的数量、测试期间发送的RPC数量、RPC消息中的总字节数，以及Raft报告的提交的日志条目数量。您的数字将与这里显示的数字不同。如果你愿意，你可以忽略这些数字，但它们可以帮助你理智地检查你的实现所发送的RPC的数量。对于所有的实验2、3和4，如果你的解决方案在所有的测试中花费超过600秒（去测试），或者任何单独的测试花费超过120秒，评分脚本将会失败。</p>
<p>When we grade your submissions, we will run the tests without the -race flag but you should also make sure that your code consistently passes the tests with the -race flag.</p>
<p>当我们对你提交的文件进行评分时，我们会在没有-race标志的情况下运行测试，但你也应该确保你的代码在有-race标志的情况下能持续通过测试。</p>
<h2 id="part-2b-log-hard"><a class="header" href="#part-2b-log-hard">Part 2B: log (hard)</a></h2>
<p>Implement the leader and follower code to append new log entries, so that the go test -run 2B tests pass.</p>
<p>实现领导者和追随者代码，以追加新的日志条目，从而使go test -run 2B测试通过。</p>
<p>Run git pull to get the latest lab software.</p>
<p>运行git pull以获得最新的实验室软件。</p>
<p>Your first goal should be to pass TestBasicAgree2B(). Start by implementing Start(), then write the code to send and receive new log entries via AppendEntries RPCs, following Figure 2. Send each newly committed entry on applyCh on each peer.</p>
<p>你的第一个目标应该是通过TestBasicAgree2B（）。从实现Start()开始，然后编写代码，通过AppendEntries RPCs发送和接收新的日志条目，如下图2。在每个对等体的applyCh上发送每个新提交的条目。</p>
<p>You will need to implement the election restriction (section 5.4.1 in the paper).</p>
<p>你将需要实施选举限制（文件中的5.4.1节）。</p>
<p>One way to fail to reach agreement in the early Lab 2B tests is to hold repeated elections even though the leader is alive. Look for bugs in election timer management, or not sending out heartbeats immediately after winning an election.</p>
<p>在早期的Lab 2B测试中，无法达成协议的一个方法是，即使领导人还活着，也要重复举行选举。寻找选举定时器管理中的错误，或者在赢得选举后不立即发送心跳的问题。</p>
<p>Your code may have loops that repeatedly check for certain events. Don't have these loops execute continuously without pausing, since that will slow your implementation enough that it fails tests. Use Go's condition variables, or insert a time.Sleep(10 * time.Millisecond) in each loop iteration.</p>
<p>你的代码可能有重复检查某些事件的循环。不要让这些循环在没有暂停的情况下连续执行，因为这将使你的执行速度慢到无法通过测试。使用 Go 的条件变量，或者在每个循环迭代中插入 time.Sleep(10 * time.Millisecond) 。</p>
<p>Do yourself a favor for future labs and write (or re-write) code that's clean and clear. For ideas, re-visit our the <a href="https://pdos.csail.mit.edu/6.824/labs/guidance.html">Guidance page</a> with tips on how to develop and debug your code.</p>
<p>为你自己将来的实验帮个忙，写（或重写）干净清晰的代码。想了解更多信息，请重新访问我们的指导页面，了解如何开发和调试代码的技巧。</p>
<p>If you fail a test, look over the code for the test in config.go and test_test.go to get a better understanding what the test is testing. config.go also illustrates how the tester uses the Raft API.</p>
<p>如果你测试失败，请查看config.go和test_test.go中的测试代码，以更好地了解测试的内容。config.go还说明了测试人员如何使用Raft API。</p>
<p>The tests for upcoming labs may fail your code if it runs too slowly. You can check how much real time and CPU time your solution uses with the time command. Here's typical output:</p>
<p>如果你的代码运行太慢，即将进行的实验室测试可能会失败。你可以用时间命令检查你的解决方案使用了多少实时时间和CPU时间。下面是典型的输出。</p>
<pre><code>$ time go test -run 2B
Test (2B): basic agreement ...
... Passed --   0.9  3   16    4572    3
Test (2B): RPC byte count ...
... Passed --   1.7  3   48  114536   11
Test (2B): agreement after follower reconnects ...
... Passed --   3.6  3   78   22131    7
Test (2B): no agreement if too many followers disconnect ...
... Passed --   3.8  5  172   40935    3
Test (2B): concurrent Start()s ...
... Passed --   1.1  3   24    7379    6
Test (2B): rejoin of partitioned leader ...
... Passed --   5.1  3  152   37021    4
Test (2B): leader backs up quickly over incorrect follower logs ...
... Passed --  17.2  5 2080 1587388  102
Test (2B): RPC counts aren't too high ...
... Passed --   2.2  3   60   20119   12
PASS
ok  	6.824/raft	35.557s

real	0m35.899s
user	0m2.556s
sys	0m1.458s
$
</code></pre>
<p>The &quot;ok 6.824/raft 35.557s&quot; means that Go measured the time taken for the 2B tests to be 35.557 seconds of real (wall-clock) time. The &quot;user 0m2.556s&quot; means that the code consumed 2.556 seconds of CPU time, or time spent actually executing instructions (rather than waiting or sleeping). If your solution uses much more than a minute of real time for the 2B tests, or much more than 5 seconds of CPU time, you may run into trouble later on. Look for time spent sleeping or waiting for RPC timeouts, loops that run without sleeping or waiting for conditions or channel messages, or large numbers of RPCs sent.</p>
<p>ok 6.824/raft 35.557s &quot;意味着Go测量了2B测试所花费的时间是35.557秒的实际（挂钟）时间。user 0m2.556s &quot;意味着代码消耗了2.556秒的CPU时间，或实际执行指令的时间（而不是等待或睡眠）。如果你的解决方案在2B测试中使用的实际时间远远超过1分钟，或者远远超过5秒的CPU时间，你以后可能会遇到麻烦。寻找花费在睡眠或等待RPC超时上的时间，在没有睡眠或等待条件或通道消息的情况下运行的循环，或发送大量的RPC。</p>
<h2 id="part-2c-persistence-hard"><a class="header" href="#part-2c-persistence-hard">Part 2C: persistence (hard)</a></h2>
<p>If a Raft-based server reboots it should resume service where it left off. This requires that Raft keep persistent state that survives a reboot. The paper's Figure 2 mentions which state should be persistent.</p>
<p>如果基于Raft的服务器重新启动，它应该在其停止的地方恢复服务。这就要求Raft在重启后仍能保持持久的状态。该文件的图2提到了哪些状态应该是持久的。</p>
<p>A real implementation would write Raft's persistent state to disk each time it changed, and would read the state from disk when restarting after a reboot. Your implementation won't use the disk; instead, it will save and restore persistent state from a Persister object (see persister.go). Whoever calls Raft.Make() supplies a Persister that initially holds Raft's most recently persisted state (if any). Raft should initialize its state from that Persister, and should use it to save its persistent state each time the state changes. Use the Persister's ReadRaftState() and SaveRaftState() methods.</p>
<p>真正的实现会在每次Raft的持久化状态发生变化时将其写入磁盘，并在重启后重新启动时从磁盘读取状态。你的实现不会使用磁盘；相反，它将从Persister对象（见persister.go）保存和恢复持久化状态。调用Raft.Make()的人提供了一个Persister，它最初持有Raft最近的持久化状态（如果有的话）。Raft应该从该Persister初始化其状态，并在每次状态改变时使用它来保存其持久化状态。使用Persister的ReadRaftState（）和SaveRaftState（）方法。</p>
<p>Complete the functions persist() and readPersist() in raft.go by adding code to save and restore persistent state. You will need to encode (or &quot;serialize&quot;) the state as an array of bytes in order to pass it to the Persister. Use the labgob encoder; see the comments in persist() and readPersist(). labgob is like Go's gob encoder but prints error messages if you try to encode structures with lower-case field names. Insert calls to persist() at the points where your implementation changes persistent state. Once you've done this, and if the rest of your implementation is correct, you should pass all of the 2C tests.</p>
<p>通过添加保存和恢复持久化状态的代码，完成raft.go中的 persist() 和 readPersist() 函数。你将需要把状态编码（或 &quot;序列化&quot;）为一个字节数组，以便将其传递给持久化器。使用labgob编码器；参见persist()和readPersist()中的注释。labgob就像Go的gob编码器，但如果你试图用小写的字段名对结构进行编码，会打印出错误信息。在你的实现改变持久化状态的地方插入对persist()的调用。一旦你完成了这些，并且如果你的其他实现是正确的，你就应该通过所有的2C测试。</p>
<p>Run git pull to get the latest lab software.</p>
<p>运行git pull以获得最新的实验室软件。</p>
<p>The 2C tests are more demanding than those for 2A or 2B, and failures may be caused by problems in your code for 2A or 2B.</p>
<p>2C测试比2A或2B的测试要求更高，失败可能是由于你的2A或2B的代码有问题造成的。</p>
<p>You will probably need the optimization that backs up nextIndex by more than one entry at a time. Look at the extended Raft paper starting at the bottom of page 7 and top of page 8 (marked by a gray line). The paper is vague about the details; you will need to fill in the gaps, perhaps with the help of the 6.824 Raft lecture notes.</p>
<p>你可能会需要一次备份多个条目的NextIndex的优化。看看从第7页底部和第8页顶部开始的扩展Raft论文（用灰线标记）。论文中的细节很模糊，你需要填补这些空白，也许可以借助6.824 Raft的讲义。</p>
<p>Your code should pass all the 2C tests (as shown below), as well as the 2A and 2B tests.</p>
<p>你的代码应该通过所有2C测试（如下图所示），以及2A和2B测试。</p>
<pre><code>$ go test -run 2C
Test (2C): basic persistence ...
... Passed --   5.0  3   86   22849    6
Test (2C): more persistence ...
... Passed --  17.6  5  952  218854   16
Test (2C): partitioned leader and one follower crash, leader restarts ...
... Passed --   2.0  3   34    8937    4
Test (2C): Figure 8 ...
... Passed --  31.2  5  580  130675   32
Test (2C): unreliable agreement ...
... Passed --   1.7  5 1044  366392  246
Test (2C): Figure 8 (unreliable) ...
... Passed --  33.6  5 10700 33695245  308
Test (2C): churn ...
... Passed --  16.1  5 8864 44771259 1544
Test (2C): unreliable churn ...
... Passed --  16.5  5 4220 6414632  906
PASS
ok  	6.824/raft	123.564s
$
</code></pre>
<p>It is a good idea to run the tests multiple times before submitting and check that each run prints PASS.</p>
<p>在提交之前，最好多次运行测试，并检查每一次运行都打印出PASS。</p>
<pre><code>$ for i in {0..10}; do go test; done
</code></pre>
<h2 id="part-2d-log-compaction-hard"><a class="header" href="#part-2d-log-compaction-hard">Part 2D: log compaction (hard)</a></h2>
<p>As things stand now, a rebooting server replays the complete Raft log in order to restore its state. However, it's not practical for a long-running service to remember the complete Raft log forever. Instead, you'll modify Raft to cooperate with services that persistently store a &quot;snapshot&quot; of their state from time to time, at which point Raft discards log entries that precede the snapshot. The result is a smaller amount of persistent data and faster restart. However, it's now possible for a follower to fall so far behind that the leader has discarded the log entries it needs to catch up; the leader must then send a snapshot plus the log starting at the time of the snapshot. Section 7 of the extended Raft paper outlines the scheme; you will have to design the details.</p>
<p>按照目前的情况，重新启动的服务器会复制完整的Raft日志，以恢复其状态。然而，对于一个长期运行的服务来说，永远记住完整的Raft日志是不现实的。相反，你将修改Raft，使其与那些不时持久性地存储其状态的 &quot;快照 &quot;的服务合作，此时Raft会丢弃快照之前的日志条目。其结果是持久性数据量更小，重启速度更快。然而，现在追随者有可能落后太多，以至于领导者丢弃了它需要追赶的日志条目；然后领导者必须发送一个快照，加上快照时间开始的日志。扩展的Raft论文的第7节概述了该方案；你必须设计细节。</p>
<p>You may find it helpful to refer to the diagram of Raft interactions to understand how the replicated service and Raft communicate.</p>
<p>你可能会发现参考Raft的交互图对了解复制的服务和Raft的通信方式很有帮助。</p>
<p>Your Raft must provide the following function that the service can call with a serialized snapshot of its state:</p>
<p>你的Raft必须提供以下函数，服务可以用其状态的序列化快照来调用。</p>
<pre><code>Snapshot(index int, snapshot []byte)
</code></pre>
<p>In Lab 2D, the tester calls Snapshot() periodically. In Lab 3, you will write a key/value server that calls Snapshot(); the snapshot will contain the complete table of key/value pairs. The service layer calls Snapshot() on every peer (not just on the leader).</p>
<p>在Lab 2D中，测试者定期调用Snapshot()。在实验室3中，你将编写一个调用Snapshot()的键/值服务器；快照将包含键/值对的完整表格。服务层在每个对等体上调用Snapshot()（而不仅仅是在领导者上）。</p>
<p>The index argument indicates the highest log entry that's reflected in the snapshot. Raft should discard its log entries before that point. You'll need to revise your Raft code to operate while storing only the tail of the log.</p>
<p>index参数表示在快照中反映的最高日志条目。Raft 应该丢弃在该点之前的日志条目。你需要修改你的Raft代码，以便在操作时只存储日志的尾部。</p>
<p>You'll need to implement the InstallSnapshot RPC discussed in the paper that allows a Raft leader to tell a lagging Raft peer to replace its state with a snapshot. You will likely need to think through how InstallSnapshot should interact with the state and rules in Figure 2.</p>
<p>你需要实现论文中讨论的 InstallSnapshot RPC，它允许 Raft 领导告诉落后的 Raft 对等体用快照替换其状态。你可能需要考虑InstallSnapshot应该如何与图2中的状态和规则互动。</p>
<p>When a follower's Raft code receives an InstallSnapshot RPC, it can use the applyCh to send the snapshot to the service in an ApplyMsg. The ApplyMsg struct definition already contains the fields you will need (and which the tester expects). Take care that these snapshots only advance the service's state, and don't cause it to move backwards.</p>
<p>当跟随者的 Raft 代码收到 InstallSnapshot RPC 时，它可以使用 applyCh 在 ApplyMsg 中向服务发送快照。ApplyMsg 结构定义已经包含了您需要的字段（也是测试人员所期望的）。请注意，这些快照只能推进服务的状态，而不会导致它向后移动。</p>
<p>If a server crashes, it must restart from persisted data. Your Raft should persist both Raft state and the corresponding snapshot. Use persister.SaveStateAndSnapshot(), which takes separate arguments for the Raft state and the corresponding snapshot. If there's no snapshot, pass nil as the snapshot argument.</p>
<p>如果一个服务器崩溃了，它必须从持久化的数据中重新启动。你的Raft应该同时保存Raft状态和相应的快照。使用 persister.SaveStateAndSnapshot()，它为 Raft 状态和相应的快照接受单独的参数。如果没有快照，则传递nil作为快照参数。</p>
<p>When a server restarts, the application layer reads the persisted snapshot and restores its saved state.</p>
<p>当服务器重新启动时，应用层会读取持久化的快照并恢复其保存的状态。</p>
<p>Previously, this lab recommended that you implement a function called CondInstallSnapshot to avoid the requirement that snapshots and log entries sent on applyCh are coordinated. This vestigal API interface remains, but you are discouraged from implementing it: instead, we suggest that you simply have it return true.</p>
<p>以前，本实验室建议你实现一个叫做CondInstallSnapshot的函数，以避免在applyCh上发送的快照和日志条目被协调的要求。这个残存的API接口仍然存在，但我们不鼓励你去实现它：相反，我们建议你只需让它返回true。</p>
<p>Implement Snapshot() and the InstallSnapshot RPC, as well as the changes to Raft to support these (e.g, operation with a trimmed log). Your solution is complete when it passes the 2D tests (and all the previous Lab 2 tests).</p>
<p>实现Snapshot()和InstallSnapshot RPC，以及对Raft的修改以支持这些功能（例如，用修剪后的日志进行操作）。当你的解决方案通过2D测试（以及之前所有的Lab 2测试）时，就完成了。</p>
<p>git pull to make sure you have the latest software.</p>
<p>git pull以确保你有最新的软件。</p>
<p>A good place to start is to modify your code to so that it is able to store just the part of the log starting at some index X. Initially you can set X to zero and run the 2B/2C tests. Then make Snapshot(index) discard the log before index, and set X equal to index. If all goes well you should now pass the first 2D test.</p>
<p>一个好的开始是修改你的代码，使其能够只存储从某个索引X开始的日志部分。最初你可以将X设置为零，并运行2B/2C测试。然后让Snapshot(index)丢弃索引之前的日志，并将X设置为等于索引。如果一切顺利，你现在应该通过第一个2D测试。</p>
<p>You won't be able to store the log in a Go slice and use Go slice indices interchangeably with Raft log indices; you'll need to index the slice in a way that accounts for the discarded portion of the log.</p>
<p>你不能将日志存储在Go分片中，并将Go分片索引与Raft日志索引互换使用；你需要对分片进行索引，以说明日志中被丢弃的部分。</p>
<p>Next: have the leader send an InstallSnapshot RPC if it doesn't have the log entries required to bring a follower up to date.</p>
<p>下一步：如果领导者没有使追随者更新所需的日志条目，就让它发送InstallSnapshot RPC。</p>
<p>Send the entire snapshot in a single InstallSnapshot RPC. Don't implement Figure 13's offset mechanism for splitting up the snapshot.</p>
<p>在单个 InstallSnapshot RPC 中发送整个快照。不要实现图13的偏移机制来分割快照。</p>
<p>Raft must discard old log entries in a way that allows the Go garbage collector to free and re-use the memory; this requires that there be no reachable references (pointers) to the discarded log entries.</p>
<p>Raft必须以允许Go垃圾收集器释放和重新使用内存的方式丢弃旧的日志条目；这要求对被丢弃的日志条目没有可及的引用（指针）。</p>
<p>Even when the log is trimmed, your implemention still needs to properly send the term and index of the entry prior to new entries in AppendEntries RPCs; this may require saving and referencing the latest snapshot's lastIncludedTerm/lastIncludedIndex (consider whether this should be persisted).</p>
<p>即使日志被修剪，你的实现仍然需要在AppendEntries RPCs中的新条目之前正确发送条目的术语和索引；这可能需要保存和引用最新快照的lastIncludedTerm/lastIncludedIndex（考虑这是否应该被持续保存）。</p>
<p>A reasonable amount of time to consume for the full set of Lab 2 tests (2A+2B+2C+2D) without -race is 6 minutes of real time and one minute of CPU time. When running with -race, it is about 10 minutes of real time and two minutes of CPU time.</p>
<p>在没有-race的情况下，实验室2的全套测试（2A+2B+2C+2D）的合理耗时是6分钟的真实时间和1分钟的CPU时间。当用-race运行时，大约是10分钟的真实时间和2分钟的CPU时间。</p>
<p>Your code should pass all the 2D tests (as shown below), as well as the 2A, 2B, and 2C tests.</p>
<p>你的代码应该通过所有的2D测试（如下图所示），以及2A、2B和2C测试。</p>
<pre><code>$ go test -run 2D
Test (2D): snapshots basic ...
... Passed --  11.6  3  176   61716  192
Test (2D): install snapshots (disconnect) ...
... Passed --  64.2  3  878  320610  336
Test (2D): install snapshots (disconnect+unreliable) ...
... Passed --  81.1  3 1059  375850  341
Test (2D): install snapshots (crash) ...
... Passed --  53.5  3  601  256638  339
Test (2D): install snapshots (unreliable+crash) ...
... Passed --  63.5  3  687  288294  336
Test (2D): crash and restart all servers ...
... Passed --  19.5  3  268   81352   58
PASS
ok      6.824/raft      293.456s
</code></pre>
<p>Again, a reminder that when we grade your submissions, we will run the tests without the -race flag but you should also make sure that your code consistently passes the tests with the -race flag.</p>
<p>再次提醒您，当我们对您提交的文件进行评分时，我们将在没有-race标志的情况下运行测试，但您也应该确保您的代码在有-race标志的情况下始终通过测试。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-2-raft-总结"><a class="header" href="#lab-2-raft-总结">Lab 2: Raft 总结</a></h1>
<ol>
<li>阅读实验手册：https://pdos.csail.mit.edu/6.824/labs/lab-raft.html</li>
<li>阅读：<a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-06-raft1">Lecture 06 - Raft1</a></li>
<li>阅读：<a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md">Raft一致性算法论文</a></li>
<li></li>
</ol>
<h2 id="part-2a-leader-election-moderate-1"><a class="header" href="#part-2a-leader-election-moderate-1">Part 2A: leader election (moderate)</a></h2>
<p>这部分是实现领导者<strong>选举</strong>和<strong>心跳</strong>。使用 <code>go test -run 2A</code> 来检测这部分代码的正确性。</p>
<p>直接运行的话会出现如下内容。因为没有实现相应功能，所以会失败。</p>
<pre><code>$ go test -run 2A
Test (2A): initial election ...
--- FAIL: TestInitialElection2A (5.00s)
    config.go:460: expected one leader, got none
Test (2A): election after network failure ...
--- FAIL: TestReElection2A (5.11s)
    config.go:460: expected one leader, got none
Test (2A): multiple elections ...
--- FAIL: TestManyElections2A (5.02s)
    config.go:460: expected one leader, got none
FAIL
exit status 1
FAIL    6.824/raft      15.126s
</code></pre>
<p>此外还要关注，如何收发 RequestVote RPCs ，与选举有关的规则，以及与领导选举有关的状态。</p>
<ol>
<li>在<code>raft.go</code>中的Raft结构中添加图2中领导者选举的状态。</li>
</ol>
<ul>
<li>当前节点的状态(Follower/Candidate/Leader)</li>
<li>服务器已知最新的任期（在服务器首次启动时初始化为0，单调递增）</li>
<li>当前任期内收到选票的 candidateId，如果没有投给任何候选人则为空。</li>
<li>存放日志。</li>
<li>上次收到心跳的时间。 </li>
<li>下次选举超时的时间。</li>
</ul>
<p>节点的状态分为三种类型：Follower，Candidate，Leader 。下面是三种状态需要负责的事情。</p>
<ul>
<li>
<p>Leader：处理客户端请求，复制请求到其他服务器上，并告诉什么其他服务器什么时候能用。</p>
<ul>
<li>接收来自客户端的请求，将日志附加到本地日志中，日志应用到状态机后响应客户端。</li>
<li>向其他的所有服务器发送 AppendEntries 附加日志，防止 Follower 超时。</li>
<li>如果 Follower 发送来的 log entries 索引值大于等于 nextIndex (lastLogIndex ≥ nextIndex)。
<ul>
<li>如果成功：更新相应跟随者的 nextIndex 和 matchIndex 。</li>
<li>如果因为日志不一致而失败，则 nextIndex 递减并重试。</li>
</ul>
</li>
<li>假设存在 N 满足N &gt; commitIndex，使得大多数的 matchIndex[i] ≥ N以及log[N].term == currentTerm 成立，则令 commitIndex = N（5.3 和 5.4 节）</li>
</ul>
</li>
<li>
<p>Follower：处理 Leader 和 Candidate 发来的请求。如果在规定时间内没有收到当前 Leader 发来的心跳则自动转为 Candidate 。</p>
</li>
<li>
<p>Candidate：选举，如果超时则重新选举，成为 Leader 或成为 Follower 。</p>
<ul>
<li>从 Leader 变为 Candidate 后立刻开始选举过程（自增当前任期号，投给自己，重置选取超时器，向其他服务器发送请求投票的 RPC）。</li>
<li>拿到超半数的投票后则变为 Leader 。</li>
<li>收到来自 Leader 的 AppendEntries 日志的 RPC 请求后成为 Follower 。</li>
<li>选举超时，重新投票。</li>
</ul>
</li>
</ul>
<p>Figure 2 中有介绍，由三部分组成，分别是状态机的命令和领导人接收到该条目时的任期（初始索引为1），此外还有当前日志的下标 index 。 </p>
<ol start="2">
<li>日志结构体如何定义？</li>
</ol>
<p>包含三个信息：收到该 log 的任期，当前日志的索引，需要执行的命令。</p>
<p>命令如何表示？参考已经定义的方法 <code>Start(command interface{})</code>，用 Interfaces 表示。</p>
<ol start="3">
<li>实现 RequestVoteArgs 和 RequestVoteReply 结构。</li>
</ol>
<ul>
<li>RequestVoteArgs，RequestVoteReply 是用来干什么的？</li>
</ul>
<p>投票的时候需要用到，通过 RequestVoteArgs 构造出一张选票发送出去。RequestVoteReply 则用来接收信息，所以需要“传引用”。</p>
<ul>
<li>投票的时候需要提供什么信息？</li>
</ul>
<p>需要提供当前的任期 term 和提供这张票人的 id ，也就是 raft 节点自己。</p>
<ul>
<li>需要返回什么样的信息？</li>
</ul>
<p>是否投给自己 voteGranted 以及当前的任期号 term 。</p>
<ol start="4">
<li>修改 <code>Make()</code> 以创建一个后台goroutine，当它有一段时间没有收到另一个对等体的消息时，它将通过发送RequestVote RPCs定期启动领导者选举。这样，如果已经有了一个领导者，对等体将了解谁是领导者，或者自己成为领导者。实现 RequestVote() RPC 处理程序，这样服务器就可以互相投票了。</li>
</ol>
<p>大致流程是首先<strong>初始化超时时间</strong>，然后进行<strong>选举</strong>，最后发送<strong>心跳包</strong>维持自己的地位。</p>
<p>Make() 输入参数含义：其中 peers[] 存储了所有的 Raft server ，当然也包括自己 peers[me] 。这也是第三个参数 me 的含义。peers[] 中有固定的顺序。第四个参数 persister 用于持久化。第五个参数 applyCh 是一个 channel ，Raft 向其中发送 ApplyMsg。</p>
<ul>
<li>如何初始化超时时间？</li>
</ul>
<p>超时时间使用一个随机数来生成一个固定区间(例如 150-300 毫秒)内的值，用当前时间作为随机种子。</p>
<p>随机数确保了不同对等体的选举超时不会总是在同一时间发生，否则所有对等体将只为自己投票，没有人会成为领导者。</p>
<p>论文的第5.2节提到选举超时的范围是150到300毫秒。只有当领导者发送心跳的频率大大超过每150毫秒一次时，这样的范围才有意义。因为测试者把你限制在每秒10次心跳，所以你必须使用比文件中的150到300毫秒更大的选举超时，但不能太大，因为那样你可能无法在5秒内选出一个领导者。</p>
<ul>
<li>如何进行选举？</li>
</ul>
<p>首先判断是否已经 killed ？ killed 用来判断是否已经调用 kill 终止整个程序了。</p>
<p>接下来判断是否已经是 Leader ？如果是就终止，不再执行。</p>
<p>然后确保真的超时了，当前时间减去上次收到心跳包的时间大于超时时间上限。</p>
<p>然后进行选举，首先重置状态，例如重置超时时间，任期加一，变为 Candidate ，给自己投票。</p>
<p>然后构造选票结构体，发给剩余的所有对等体。然后分析返回的信息。如果回复的任期大于当前任期，那么立刻转为 Follower 并重置当前任期。如果投给自己那么投票数累加，再判断票数是否过半，若过半则成为 Leader 。最后向所有节点广播并发送心跳包。</p>
<p>对等体如何处理投票的请求？也就是 RequestVote 的实现。</p>
<p>首先将当前节点的任期更新到返回值中。然后判断输入参数的任期是否小于当前节点的任期，若小于则不投，若大于当前节点转为 Follower ，若等于接下来判断当前节点是否已经投票了，没有的话再去投票。</p>
<ul>
<li>如何实现心跳。</li>
</ul>
<p>为了维持 Leader 的地位，需要在超时时间内向所有节点发送心跳包。</p>
<p>首先判断是否已经调用 kill，然后判断当前节点是否是 Leader 若是则进行广播心跳包。</p>
<p>广播心跳包的实现方式，首先初始化 AppendEntriesArgs 结构体，然后遍历所有对等体，将其发送出去。若根据返回参数判断出对方的任期大于当前节点的任期那么立刻转为 Follower 。</p>
<p>测试者要求领导者每秒发送心跳RPC的次数不超过10次。执行一次 RPC 沉睡一会，例如沉睡 0.2s 。</p>
<p>然而，请记住，如果出现分裂投票，领袖选举可能需要多轮投票（如果数据包丢失或候选人不走运地选择相同的随机退避时间，就会发生这种情况）。你必须选择足够短的选举超时（以及心跳间隔），即使需要多轮选举，也很可能在5秒内完成。</p>
<ol start="5">
<li>其他</li>
</ol>
<p>不要忘记实现 GetState()。返回当前任期并判断是否是 Leader 。</p>
<p>测试员在永久关闭一个实例时，会调用你的Raft的rf.Kill()。您可以使用rf.killed()检查Kill()是否被调用。您可能希望在所有的循环中都这样做，以避免死亡的Raft实例打印混乱的信息。</p>
<p>Go RPC只发送名称以大写字母开头的结构字段。子结构也必须有大写的字段名（例如，数组中的日志记录字段）。labgob包会对此发出警告；不要忽视这些警告。</p>
<p>在提交第2A部分之前，请确保你通过了2A测试，这样你就会看到这样的内容。</p>
<pre><code>$ go test -run 2A
Test (2A): initial election ...
... Passed --   3.5  3   58   16840    0
Test (2A): election after network failure ...
... Passed --   5.4  3  118   25269    0
Test (2A): multiple elections ...
... Passed --   7.3  7  624  138014    0
PASS
ok  	6.824/raft	16.265s
$
</code></pre>
<p>每一行 &quot;通过 &quot;包含五个数字；它们是测试所花的时间（秒）、Raft对等体的数量、测试期间发送的RPC数量、RPC消息中的总字节数，以及Raft报告的提交的日志条目数量。您的数字将与这里显示的数字不同。如果你愿意，你可以忽略这些数字，但它们可以帮助你理智地检查你的实现所发送的RPC的数量。对于所有的实验2、3和4，如果你的解决方案在所有的测试中花费超过600秒（去测试），或者任何单独的测试花费超过120秒，评分脚本将会失败。</p>
<h2 id="part-2b-log-hard-1"><a class="header" href="#part-2b-log-hard-1">Part 2B: log (hard)</a></h2>
<p>使用 <code>go test -run 2B</code> 来检测代码是否正确。</p>
<p>通过<code>TestBasicAgree2B()</code>。从实现<code>Start()</code>开始，然后编写代码，通过 AppendEntries RPCs 发送和接收新的日志条目，如下图2。在每个对等体的<code>applyCh</code>上发送每个新提交的条目。你将需要实施选举限制（文件中的5.4.1节）。</p>
<ol>
<li>实现 <code>Start()</code> 。该函数实现了什么样的功能？</li>
</ol>
<p>输入的是 command 将其追加到 log 中，如果当前节点不是 leader 则返回 false 。即便当前 Raft 实例被 kill 掉，该函数也应当返回。</p>
<p>输出的三个参数分别是输入命令对应的索引，当前周期，当前节点是否是 leader 。</p>
<ul>
<li>日志索引加一，追加日志。</li>
</ul>
<p>在早期的Lab 2B测试中，无法达成协议的一个方法是，即使领导人还活着，也要重复举行选举。寻找选举定时器管理中的错误，或者在赢得选举后不立即发送心跳的问题。</p>
<p>你的代码可能有重复检查某些事件的循环。不要让这些循环在没有暂停的情况下连续执行，因为这将使你的执行速度慢到无法通过测试。使用 Go 的条件变量，或者在每个循环迭代中插入 time.Sleep(10 * time.Millisecond) 。</p>
<p>如果测试失败，建议查看config.go和test_test.go中的测试代码，以更好地了解测试的内容。config.go 提供了测试人员如何使用Raft API。</p>
<p>如果代码运行太慢，即将进行的测试可能会失败。可以用 time 命令检查你的解决方案使用了多少实时时间和CPU时间。下面是典型的输出。</p>
<pre><code>$ time go test -run 2B
Test (2B): basic agreement ...
... Passed --   0.9  3   16    4572    3
Test (2B): RPC byte count ...
... Passed --   1.7  3   48  114536   11
Test (2B): agreement after follower reconnects ...
... Passed --   3.6  3   78   22131    7
Test (2B): no agreement if too many followers disconnect ...
... Passed --   3.8  5  172   40935    3
Test (2B): concurrent Start()s ...
... Passed --   1.1  3   24    7379    6
Test (2B): rejoin of partitioned leader ...
... Passed --   5.1  3  152   37021    4
Test (2B): leader backs up quickly over incorrect follower logs ...
... Passed --  17.2  5 2080 1587388  102
Test (2B): RPC counts aren't too high ...
... Passed --   2.2  3   60   20119   12
PASS
ok  	6.824/raft	35.557s

real	0m35.899s
user	0m2.556s
sys	0m1.458s
$
</code></pre>
<p><code>ok 6.824/raft 35.557s</code> 意味着Go测量了2B测试所花费的时间是35.557秒的实际（挂钟）时间。<code>user 0m2.556s</code> 意味着代码消耗了2.556 秒的CPU时间，或实际执行指令的时间（而不是等待或睡眠）。如果在2B测试中使用的实际时间远远超过1分钟，或者远远超过5秒的CPU时间，那么以后可能会遇到麻烦。寻找花费在睡眠或等待RPC超时上的时间，在没有睡眠或等待条件或通道消息的情况下运行的循环，或发送大量的RPC。</p>
<h2 id="part-2c-persistence-hard-1"><a class="header" href="#part-2c-persistence-hard-1">Part 2C: persistence (hard)</a></h2>
<p>如果基于Raft的服务器重新启动，它应该在其停止的地方恢复服务。这就要求Raft在重启后仍能保持持久的状态。该文件的图2提到了哪些状态应该是持久的。</p>
<p>真正的实现会在每次Raft的持久化状态发生变化时将其写入磁盘，并在重启后重新启动时从磁盘读取状态。你的实现不会使用磁盘；相反，它将从Persister对象（见persister.go）保存和恢复持久化状态。调用Raft.Make()的人提供了一个Persister，它最初持有Raft最近的持久化状态（如果有的话）。Raft应该从该Persister初始化其状态，并在每次状态改变时使用它来保存其持久化状态。使用Persister的ReadRaftState（）和SaveRaftState（）方法。</p>
<p>通过添加保存和恢复持久化状态的代码，完成raft.go中的 persist() 和 readPersist() 函数。你将需要把状态编码（或 &quot;序列化&quot;）为一个字节数组，以便将其传递给持久化器。使用labgob编码器；参见persist()和readPersist()中的注释。labgob就像Go的gob编码器，但如果你试图用小写的字段名对结构进行编码，会打印出错误信息。在你的实现改变持久化状态的地方插入对persist()的调用。一旦你完成了这些，并且如果你的其他实现是正确的，你就应该通过所有的2C测试。</p>
<p>运行git pull以获得最新的实验室软件。</p>
<p>2C测试比2A或2B的测试要求更高，失败可能是由于你的2A或2B的代码有问题造成的。</p>
<p>你可能会需要一次备份多个条目的NextIndex的优化。看看从第7页底部和第8页顶部开始的扩展Raft论文（用灰线标记）。论文中的细节很模糊，你需要填补这些空白，也许可以借助6.824 Raft的讲义。</p>
<p>你的代码应该通过所有2C测试（如下图所示），以及2A和2B测试。</p>
<pre><code>$ go test -run 2C
Test (2C): basic persistence ...
... Passed --   5.0  3   86   22849    6
Test (2C): more persistence ...
... Passed --  17.6  5  952  218854   16
Test (2C): partitioned leader and one follower crash, leader restarts ...
... Passed --   2.0  3   34    8937    4
Test (2C): Figure 8 ...
... Passed --  31.2  5  580  130675   32
Test (2C): unreliable agreement ...
... Passed --   1.7  5 1044  366392  246
Test (2C): Figure 8 (unreliable) ...
... Passed --  33.6  5 10700 33695245  308
Test (2C): churn ...
... Passed --  16.1  5 8864 44771259 1544
Test (2C): unreliable churn ...
... Passed --  16.5  5 4220 6414632  906
PASS
ok  	6.824/raft	123.564s
$
</code></pre>
<p>It is a good idea to run the tests multiple times before submitting and check that each run prints PASS.</p>
<p>在提交之前，最好多次运行测试，并检查每一次运行都打印出PASS。</p>
<pre><code>$ for i in {0..10}; do go test; done
</code></pre>

                    <div id="giscus-container"></div>
                </main>

                <nav class="nav-wrapper" aria-label="Page navigation">
                    <!-- Mobile navigation buttons -->


                    <div style="clear: both"></div>
                </nav>
            </div>
        </div>

        <nav class="nav-wide-wrapper" aria-label="Page navigation">

        </nav>

    </div>




    <script type="text/javascript">
        window.playground_copyable = true;
    </script>

    <script src="ace.js" type="text/javascript" charset="utf-8"></script>
    <script src="editor.js" type="text/javascript" charset="utf-8"></script>
    <script src="mode-rust.js" type="text/javascript" charset="utf-8"></script>
    <script src="theme-dawn.js" type="text/javascript" charset="utf-8"></script>
    <script src="theme-tomorrow_night.js" type="text/javascript" charset="utf-8"></script>

    <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

    <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
    <script src="book.js" type="text/javascript" charset="utf-8"></script>
    <script type="text/javascript" charset="utf-8">
        var pagePath = "print.md"
    </script>


    <!-- Custom JS scripts -->

    <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
    </script>

</body>
</html>