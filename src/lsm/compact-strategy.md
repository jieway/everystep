


LevelDB 的 Compaction 策略主要在 `db_impl.cc` 文件中的 `DBImpl::BackgroundCompaction` 函数中实现。这个函数负责在后台线程中执行 Compaction 操作。

在 LevelDB 中，Compaction 主要分为两种：Minor Compaction 和 Major Compaction。

Minor Compaction 主要发生在 MemTable 达到一定大小时，这个过程主要涉及到最新的 SST 文件，因此产生的额外磁盘 I/O 较少。具体的实现在 `db_impl.cc` 文件的 `DBImpl::CompactMemTable` 函数中。

```cpp
void DBImpl::CompactMemTable() {
  // 将 MemTable 转换为 SST 文件并刷新到磁盘
  // ...
}
```

Major Compaction 则涉及到所有的 SST 文件，它会读取所有的数据并重新写入磁盘，因此产生的额外磁盘 I/O 较多。具体的实现在 `db_impl.cc` 文件的 `DBImpl::DoCompactionWork` 函数中。

```cpp
void DBImpl::DoCompactionWork(CompactionState* compact) {
  // 执行实际的合并操作
  // ...
}
```

在 `DoCompactionWork` 函数中，它会创建一个 `CompactionState` 对象来保存合并操作的状态，然后通过循环调用 `Compaction::Next` 方法来逐步进行合并操作。在每次循环中，它会调用 `Compaction::Next` 方法来获取下一个要合并的键值对，然后调用 `CompactionState::Add` 方法将这个键值对添加到新的 SST 文件中。

在 `CompactionState::Add` 方法中，它会检查当前的键是否与上一个键相同，如果相同，则表示这是一个重复的键，它会被忽略。如果当前的键是一个删除标记，则表示这是一个过期的数据，它也会被忽略。只有当当前的键既不是重复的键，也不是删除标记时，它才会被添加到新的 SST 文件中。

在合并操作完成后，`DBImpl::DoCompactionWork` 方法会调用 `CompactionState::Finish` 方法来关闭新的 SST 文件，并将其添加到 SST 文件的列表中。然后，它会调用 `VersionSet::LogAndApply` 方法来更新元数据，并将新的 SST 文件添加到 LSM 树中。最后，它会删除旧的 SST 文件，并释放相关的资源。

以上就是 LevelDB 中 Compaction 策略的基本实现。具体的实现可能会因为 LevelDB 的版本和配置的不同而有所不同。








* 层次化合并的预计写放大是多少？
* 层次化合并的预计读放大是多少？
* 如果用户请求删除一个键，并且它已经在最底层进行了合并，那么这个键只会从 LSM 树中被清除，对吗？
* 定期对 LSM 树进行全面合并是一个好策略吗？为什么或者为什么不？
* 主动选择一些旧的文件/级别进行合并，即使它们没有违反级别放大器，这是一个好选择吗？（看看 [Lethe](https://disc-projects.bu.edu/lethe/) 论文！）
* 如果存储设备可以达到持续 1GB/s 的写入吞吐量，而 LSM 树的写放大是 10x，那么用户可以从 LSM 键值接口获得多少吞吐量？
* 如果 L2 中有 SST 文件，你可以直接合并 L1 和 L3 吗？它是否仍然能产生正确的结果？
* 到目前为止，我们假设我们的 SST 文件使用单调递增的 id 作为文件名。使用 `<level>_<begin_key>_<end_key>.sst` 作为 SST 文件名是否可以？可能存在的问题是什么？（在第三周你可以问自己同样的问题...）



* 层次化合并的预计写放大是多少？（好吧，这很难估计... 但是如果没有最后的*减少排序运行*触发器呢？）
* 层次化合并的预计读放大是多少？
* 与简单的层次化/分层合并相比，通用合并的优点/缺点是什么？
* 运行通用合并需要多少存储空间（与用户数据大小相比）？
* 我们可以合并 LSM 状态中不相邻的两个层次吗？
* 如果合并速度跟不上 SST 的刷新，会发生什么？
* 如果系统并行调度多个合并任务，可能需要考虑什么？
* SSD 也写入它自己的日志（基本上它是一个日志结构化存储）。如果 SSD 的写放大是 2x，那么整个系统的端到端写放大是多少？相关：[ZNS：避免对基于闪存的 SSD 的块接口税](https://www.usenix.org/conference/atc21/presentation/bjorling)。
* 考虑用户选择保留大量的排序运行（即，300）进行分层合并的情况。为了使读取路径更快，保留一些帮助减少查找每个层次中某些键范围需要读取的 SST 的时间复杂度（即，到 `O(log n)`）的数据结构是一个好主意吗？注意，通常，你需要在每个排序运行中进行二分查找，以找到你需要读取的键范围。（查看 Neon 的 [层映射](https://neon.tech/blog/persistent-structures-in-neons-wal-indexing) 实现！）




* 层次化合并的预计写放大是多少？
* 层次化合并的预计读放大是多少？
* 找到一个好的合并键分割点可能会降低写放大，还是根本无所谓？（考虑用户写入以一些前缀 `00` 和 `01` 开头的键的情况。这两个前缀下的键的数量不同，它们的写模式也不同。如果我们总是可以将 `00` 和 `01` 分割到不同的 SST 中...）
* 想象一下，一个用户之前使用的是分层（通用）合并，现在想迁移到层次化合并。这种迁移可能面临什么挑战？如何进行迁移？
* 如果反过来，用户想从层次化合并迁移到分层合并会怎样？
* 如果合并速度跟不上 SST 的刷新，会发生什么？
* 如果系统并行调度多个合并任务，可能需要考虑什么？
* 层次化合并的峰值存储使用是多少？与通用合并相比呢？
* 使用较低的 `level_size_multiplier`，你总是可以得到较低的写放大，对吗？
* 如果一个用户没有使用合并，决定迁移到层次化合并，需要做什么？
* 有人提议在将它们推到较低层之前做内部 L0 合并（合并 L0 表并仍将它们放在 L0）。这样做可能有什么好处？（可能相关：[PebblesDB SOSP'17](https://www.cs.utexas.edu/~rak/papers/sosp17-pebblesdb.pdf)）
* 考虑上层有两个表 `[100, 200], [201, 300]`，下层有 `[50, 150], [151, 250], [251, 350]` 的情况。在这种情况下，你是否仍然希望一次合并上层的一个文件？为什么？


