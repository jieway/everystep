# Part 4 删除逻辑和 Compact 

## 实现删除逻辑

删除逻辑也分为两部分，一部分是内存中，一部分是磁盘上。如果只是删除内存中，这个叫做逻辑删除，将磁盘上的也删掉才真正的物理删除。

删除采用的时逻辑删除，可以简单粗暴的在内存中把 key 对应的 value 抹掉，这样无法从磁盘中查数据了。但是磁盘中依旧有需要被删除的数据该怎么办？接下来是合并操作，通常称为 compaction ，在 LSM Tree 中也有这个东西。首先从头开始读取磁盘文件，根据拿到的数据去哈希表中查找，判断是否被逻辑删除，若被删了则跳过，若没有则创建一张新的哈希表建立新的索引，并把数据写入新的文件中。这样把所有的旧数据都遍历一遍，该删的数据就都删干净了。

这是一个逻辑删除的实现，并没有实现物理删除 [[feat] add delete and test.](https://github.com/weijiew/abyssdb/commit/243d884c45d5eae3eb1d8fd9bbf573b6f4e85703) 

实现物理删除要进一步研究 Compact 机制，这个也很简单。

## Compact 机制

因为删除导致文件中存在旧数据，所以该如何处理呢？什么时候处理呢？重新构建索引时应该要略过吧？以上种种问题都是需要考虑的，而下面是一些常见的 Compact 策略。

`Compact` 机制是指在存储过程中对数据进行整理和清理的操作。Bitcask 的 `Compact` 目标是减少存储文件的碎片化，提高读取性能，并释放未使用的磁盘空间。以下是 Bitcask 的 `Compact` 机制的一般概述：

1. **合并段文件（Merge Segment Files）**：Bitcask 使用段（segment）文件来存储键值对数据。每个段文件包含一组键值对，按照键的顺序排列。在 `Compact` 期间，Bitcask 可能会合并多个段文件，将它们的数据整合到一个或多个新的段文件中。这有助于减少碎片化，提高读取效率，并优化存储。

2. **过期数据删除（Expiration-based Deletion）**：Bitcask 存储引擎通常会设置键值对的过期时间。在 `Compact` 过程中，过期的键值对会被检测并删除，以释放存储空间。

3. **数据合并和排序**：合并过程中，Bitcask 会将多个段文件中的键值对合并到新的段文件中。这有助于减少查找和读取操作时的磁盘访问，从而提高性能。同时，合并也可以使数据按照键的顺序排列，加速范围查询操作。

4. **标记删除（Tombstone）**：Bitcask 在合并过程中，可能会遇到已被删除的键。为了保持一致性，Bitcask 使用 "tombstone" 记录来标记已被删除的键。这些 "tombstone" 记录指示某个键已被删除，从而确保在合并过程中不会错误地复制已删除的数据。

5. **资源回收**：合并过程中，Bitcask 可能会删除不再需要的段文件，从而释放磁盘空间。这可以帮助减少存储系统占用的磁盘空间。

需要注意的是，Bitcask 的 `Compact` 机制是为了优化性能和存储空间使用，但也会增加一定的系统开销。合并操作可能需要较长的时间，可能会占用一定的 CPU 和磁盘资源。因此，在执行 `Compact` 操作时，需要权衡操作的频率和性能开销。

总之，Bitcask 的 `Compact` 机制旨在通过合并、清理和整理操作，优化存储引擎的性能和存储空间利用。这有助于维持存储系统的高效性能，并减少存储资源的浪费。

## 其他

下面是一些简单且容易实现任务，并且可以加深代码理解。后续有时间的话会挨个实现并讲解。

1. 如何支持 TTL ？
2. 文件如何拆分为多个？
3. hint file 加快启动速度如何实现？





### 级别 1：
- 崩溃安全性：Bitcask 论文中在每行存储了 CRC，并在获取数据时验证数据的完整性。
- 键删除：CaskDB 没有删除 API。请阅读论文并实现这一功能。
- 使用类似红黑树的数据结构代替哈希表来支持范围扫描。
- 只接受字符串作为键和值。使其泛化，可以接受像整型或字节等其他数据结构。

### 级别 2：
- 提示文件来改进启动时间。论文中有更多细节。
- 实现一个内部缓存来存储一些键值对。你可以探索和实验不同的缓存淘汰策略，如 LRU（最近最少使用）、LFU（最不常用）、FIFO（先进先出）等。
- 当文件达到特定容量时，将数据分割到多个文件中。

### 级别 3：
- 支持多进程。
- 垃圾回收：更新和删除的键仍然留在文件中占用空间。编写一个垃圾回收器来移除这类陈旧数据。
- 添加 SQL 查询引擎层。
- 在值中存储 JSON，并探索使 CaskDB 成为类似于 MongoDB 的文档数据库。
- 通过探索 Raft、Paxos 或一致性哈希等算法，使 CaskDB 分布式化。